{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a35427d-df7f-4607-a7d5-47c142952e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import triton\n",
    "from torch import nn\n",
    "\n",
    "# ==== ИМПОРТЫ ОБЁРТОК INT8 ==== \n",
    "# правь пути под свой проект, но идея такая:\n",
    "from img2col_int8_kernel import img2col_int8\n",
    "from gemm_int8_kernel    import gemm_int8_tc\n",
    "from col2img_int8_kernel import col2img_int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fb9922-a70a-471b-a2a6-ff2f42596c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _force_strict_fp32():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "_force_strict_fp32()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48d798e-4e91-4d79-ac42-424714026049",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2801c2-ac50-469c-a685-4b97096c7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "_force_strict_fp32()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1282fb3-57f0-499b-880b-60c813e451c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync():\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def bench(fn, warmup=50, iters=300):\n",
    "    \"\"\"Среднее время вызова fn() в секундах.\"\"\"\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    sync()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    sync()\n",
    "    return (time.perf_counter() - t0) / iters\n",
    "\n",
    "\n",
    "def out_hw(H, W, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw):\n",
    "    Ho = (H + 2 * Ph - Dh * (Kh - 1) - 1) // Sh + 1\n",
    "    Wo = (W + 2 * Pw - Dw * (Kw - 1) - 1) // Sw + 1\n",
    "    return Ho, Wo\n",
    "\n",
    "\n",
    "def row(name, items):\n",
    "    print(\"| \" + name + \" | \" + \" | \".join(items) + \" |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7ae89e-40f4-46fa-acd6-567b1ca2b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_per_tensor_symmetric(x: torch.Tensor, num_bits: int = 8):\n",
    "    \"\"\"\n",
    "    Простой симметричный per-tensor квантайзер:\n",
    "      x ≈ scale * q, q ∈ [-128, 127].\n",
    "    Возвращает (q:int8, scale:float)\n",
    "    \"\"\"\n",
    "    assert x.is_floating_point()\n",
    "    qmax = 2 ** (num_bits - 1) - 1  # 127\n",
    "    max_abs = x.abs().max().item()\n",
    "    if max_abs == 0.0:\n",
    "        scale = 1.0\n",
    "    else:\n",
    "        scale = max_abs / qmax\n",
    "    q = torch.clamp((x / scale).round(), -128, 127).to(torch.int8)\n",
    "    return q, float(scale)\n",
    "\n",
    "\n",
    "def quantize_to_int32(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Используем для col2img_int32: x ≈ scale * q_int32 (где q = round(x/scale)).\n",
    "    По сути то же, что выше, только тип int32.\n",
    "    \"\"\"\n",
    "    assert x.is_floating_point()\n",
    "    max_abs = x.abs().max().item()\n",
    "    if max_abs == 0.0:\n",
    "        scale = 1.0\n",
    "    else:\n",
    "        # можно взять чуть грубее, чтобы не плодить огромные значения\n",
    "        scale = max_abs / (2 ** 20)  # условно 20 бит под полезный сигнал\n",
    "    q = torch.round(x / scale).to(torch.int32)\n",
    "    return q, float(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f5d60b-cac7-473b-ab65-01ebf54bc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int8_stage_img2col(\n",
    "    x_fp32: torch.Tensor,\n",
    "    Kh: int, Kw: int,\n",
    "    Sh: int, Sw: int,\n",
    "    Ph: int, Pw: int,\n",
    "    Dh: int, Dw: int,\n",
    "    BLOCK_M: int,\n",
    "    BLOCK_K: int,\n",
    "    NUM_WARPS: int,\n",
    "    NUM_STAGES: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    FWD: x_fp32 -> (Unfold-эталон, Triton-int8 img2col-dequant).\n",
    "    Возвращает (cols_ref_fp32, cols_tri_fp32).\n",
    "    \"\"\"\n",
    "    B, Cin, H, W = x_fp32.shape\n",
    "    Ho, Wo = out_hw(H, W, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw)\n",
    "    K = Cin * Kh * Kw\n",
    "\n",
    "    # Эталон: Unfold -> [B, K, L] -> [M, K]\n",
    "    unfold = nn.Unfold(\n",
    "        kernel_size=(Kh, Kw),\n",
    "        dilation=(Dh, Dw),\n",
    "        padding=(Ph, Pw),\n",
    "        stride=(Sh, Sw),\n",
    "    ).to(x_fp32.device)\n",
    "    with torch.no_grad():\n",
    "        cols_ref = (\n",
    "            unfold(x_fp32.float())\n",
    "            .transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(-1, K)\n",
    "            .float()\n",
    "        )  # [M,K]\n",
    "\n",
    "    # INT8-путь: квант x -> img2col_int8 -> dequant\n",
    "    x_q, s_x = quantize_per_tensor_symmetric(x_fp32)\n",
    "    cols_q, _ = img2col_int8(\n",
    "        x_q,\n",
    "        Kh, Kw,\n",
    "        Sh, Sw,\n",
    "        Ph, Pw,\n",
    "        Dh, Dw,\n",
    "        BLOCK_M=BLOCK_M,\n",
    "        BLOCK_K=BLOCK_K,\n",
    "        num_warps=NUM_WARPS,\n",
    "        num_stages=NUM_STAGES,\n",
    "    )  # [M,K] int8\n",
    "    cols_tri = cols_q.float() * s_x  # примитивный dequant\n",
    "\n",
    "    return cols_ref, cols_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12583557-ab34-4320-be09-414120b7dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int8_stage_col2img(\n",
    "    dcols_fp32: torch.Tensor,\n",
    "    B: int, Cin: int, H: int, W: int,\n",
    "    Kh: int, Kw: int,\n",
    "    Sh: int, Sw: int,\n",
    "    Ph: int, Pw: int,\n",
    "    Dh: int, Dw: int,\n",
    "    BLOCK_M: int,\n",
    "    BLOCK_K: int,\n",
    "    NUM_WARPS: int,\n",
    "    NUM_STAGES: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    BWD-эквивалент: dcols -> dx.\n",
    "    Torch: Fold(dcols) vs Triton: col2img_int32(q(dcols))*scale.\n",
    "    Возвращает (dx_ref_fp32, dx_tri_fp32).\n",
    "    \"\"\"\n",
    "    device = dcols_fp32.device\n",
    "    Ho, Wo = out_hw(H, W, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw)\n",
    "    K = Cin * Kh * Kw\n",
    "    M = B * Ho * Wo\n",
    "    assert dcols_fp32.shape == (M, K)\n",
    "\n",
    "    # Torch Fold: dcols [M,K] -> [B,K,L] -> Fold -> [B,Cin,H,W]\n",
    "    fold = nn.Fold(\n",
    "        output_size=(H, W),\n",
    "        kernel_size=(Kh, Kw),\n",
    "        dilation=(Dh, Dw),\n",
    "        padding=(Ph, Pw),\n",
    "        stride=(Sh, Sw),\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        cols_3d = (\n",
    "            dcols_fp32.view(B, Ho * Wo, K)\n",
    "            .transpose(1, 2)\n",
    "            .contiguous()\n",
    "        )  # [B,K,L]\n",
    "        dx_ref = fold(cols_3d).float()\n",
    "\n",
    "    # Triton col2img_int32: сначала квант в int32, потом col2img_int32, потом dequant\n",
    "    dcols_q, s_d = quantize_to_int32(dcols_fp32)\n",
    "    dx_tri = col2img_int32(\n",
    "        dcols_q,\n",
    "        B, Cin, H, W,\n",
    "        Kh, Kw,\n",
    "        Sh, Sw,\n",
    "        Ph, Pw,\n",
    "        Dh, Dw,\n",
    "        BLOCK_M=BLOCK_M,\n",
    "        BLOCK_K=BLOCK_K,\n",
    "        num_warps=NUM_WARPS,\n",
    "        num_stages=NUM_STAGES,\n",
    "    )  # [B,Cin,H,W] fp32, но это сумма int32, значит надо умножить на scale\n",
    "    dx_tri = dx_tri * s_d\n",
    "\n",
    "    return dx_ref, dx_tri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df19352d-e1dc-4436-aabb-bd71a50a23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_img2col_col2im_int8(cfg, tile_cfgs):\n",
    "    \"\"\"\n",
    "    Аналог твоей главы 1, но:\n",
    "      - FWD: Unfold vs img2col_int8\n",
    "      - BWD: Fold  vs col2img_int32\n",
    "    Всё с квант/деквант, считаем MAE/max и время.\n",
    "    \"\"\"\n",
    "    print(\"\\n# Глава 1 (INT8): ImageToColumn + ColumnToImage\")\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.empty_cache()          # сброс кэша\n",
    "    torch.cuda.reset_peak_memory_stats(device=device)\n",
    "\n",
    "    B, Cin, Cout, H, W, ks = cfg[\"B\"], cfg[\"Cin\"], cfg[\"Cout\"], cfg[\"H\"], cfg[\"W\"], cfg[\"ks\"]\n",
    "    stride, padding, dilation = cfg[\"stride\"], cfg[\"padding\"], cfg[\"dilation\"]\n",
    "    Sh, Sw = (stride, stride) if isinstance(stride, int) else stride\n",
    "    Ph, Pw = (padding, padding) if isinstance(padding, int) else padding\n",
    "    Dh, Dw = (dilation, dilation) if isinstance(dilation, int) else dilation\n",
    "    Kh = Kw = ks\n",
    "\n",
    "    Ho, Wo = out_hw(H, W, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw)\n",
    "    K = Cin * Kh * Kw\n",
    "    M = B * Ho * Wo\n",
    "\n",
    "    # один x/градиент на все конфиги, чтобы сравнение было честным\n",
    "    torch.manual_seed(0)\n",
    "    x = torch.randn(B, Cin, H, W, device=device, dtype=torch.float32)\n",
    "    dcols = torch.randn(M, K, device=device, dtype=torch.float32)\n",
    "\n",
    "    for tile in tile_cfgs:\n",
    "        BLOCK_M = tile[\"BLOCK_M\"]\n",
    "        BLOCK_K = tile[\"BLOCK_K\"]\n",
    "        NUM_WARPS = tile[\"NUM_WARPS\"]\n",
    "        NUM_STAGES = tile[\"NUM_STAGES\"]\n",
    "\n",
    "        print(f\"\\n[int8 img2col+col2im] cfg={tile}\")\n",
    "\n",
    "        # -------- FWD точность --------\n",
    "        with torch.no_grad():\n",
    "            cols_ref, cols_tri = int8_stage_img2col(\n",
    "                x, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                NUM_WARPS=NUM_WARPS,\n",
    "                NUM_STAGES=NUM_STAGES,\n",
    "            )\n",
    "            diff_f = (cols_ref - cols_tri).abs()\n",
    "            f_mae = diff_f.mean().item()\n",
    "            f_mx = diff_f.max().item()\n",
    "\n",
    "        # -------- BWD точность (dx) --------\n",
    "        with torch.no_grad():\n",
    "            dx_ref, dx_tri = int8_stage_col2img(\n",
    "                dcols, B, Cin, H, W,\n",
    "                Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                NUM_WARPS=NUM_WARPS,\n",
    "                NUM_STAGES=NUM_STAGES,\n",
    "            )\n",
    "            diff_b = (dx_ref - dx_tri).abs()\n",
    "            b_mae = diff_b.mean().item()\n",
    "            b_mx = diff_b.max().item()\n",
    "\n",
    "        # -------- Тайминги --------\n",
    "        unfold = nn.Unfold(\n",
    "            kernel_size=(Kh, Kw),\n",
    "            dilation=(Dh, Dw),\n",
    "            padding=(Ph, Pw),\n",
    "            stride=(Sh, Sw),\n",
    "        ).to(device)\n",
    "\n",
    "        def f_unfold():\n",
    "            unfold(x.float())\n",
    "\n",
    "        def f_i2c_int8():\n",
    "            cols_ref_, cols_tri_ = int8_stage_img2col(\n",
    "                x, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                NUM_WARPS=NUM_WARPS,\n",
    "                NUM_STAGES=NUM_STAGES,\n",
    "            )\n",
    "            return cols_tri_\n",
    "\n",
    "        fold = nn.Fold(\n",
    "            output_size=(H, W),\n",
    "            kernel_size=(Kh, Kw),\n",
    "            dilation=(Dh, Dw),\n",
    "            padding=(Ph, Pw),\n",
    "            stride=(Sh, Sw),\n",
    "        ).to(device)\n",
    "\n",
    "        def f_fold():\n",
    "            cols_3d = (\n",
    "                dcols.view(B, Ho * Wo, K)\n",
    "                .transpose(1, 2)\n",
    "                .contiguous()\n",
    "            )\n",
    "            fold(cols_3d)\n",
    "\n",
    "        def f_c2i_int8():\n",
    "            dx_ref_, dx_tri_ = int8_stage_col2img(\n",
    "                dcols, B, Cin, H, W,\n",
    "                Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                NUM_WARPS=NUM_WARPS,\n",
    "                NUM_STAGES=NUM_STAGES,\n",
    "            )\n",
    "            return dx_tri_\n",
    "\n",
    "        t_unfold = bench(f_unfold, warmup=30, iters=200)\n",
    "        t_i2c = bench(f_i2c_int8, warmup=30, iters=200)\n",
    "        t_fold = bench(f_fold, warmup=30, iters=200)\n",
    "        t_c2i = bench(f_c2i_int8, warmup=30, iters=200)\n",
    "\n",
    "        row(\n",
    "            \"Этап\",\n",
    "            [\n",
    "                \"FWD MAE(cols)\",\n",
    "                \"FWD max(cols)\",\n",
    "                \"BWD MAE(dx)\",\n",
    "                \"BWD max(dx)\",\n",
    "                \"Torch Unfold ms\",\n",
    "                \"Triton i2c ms\",\n",
    "                \"Torch Fold ms\",\n",
    "                \"Triton c2i ms\",\n",
    "            ],\n",
    "        )\n",
    "        row(\n",
    "            \"Знач\",\n",
    "            [\n",
    "                f\"{f_mae:.3e}\",\n",
    "                f\"{f_mx:.3e}\",\n",
    "                f\"{b_mae:.3e}\",\n",
    "                f\"{b_mx:.3e}\",\n",
    "                f\"{t_unfold * 1e3:.3f}\",\n",
    "                f\"{t_i2c * 1e3:.3f}\",\n",
    "                f\"{t_fold * 1e3:.3f}\",\n",
    "                f\"{t_c2i * 1e3:.3f}\",\n",
    "            ],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43b6185-4a78-4e6c-aaaf-3240e24ae21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_gemm_int8(cfg, tile_cfgs):\n",
    "    \"\"\"\n",
    "    Аналог главы GEMM:\n",
    "      Torch: fp32 @ fp32\n",
    "      Triton: int8×int8 -> fp32, с квант/деквант.\n",
    "    \"\"\"\n",
    "    print(\"\\n# Глава 2 (INT8): GEMM int8×int8 vs Torch mm\")\n",
    "\n",
    "    B, Cin, Cout, H, W, ks = cfg[\"B\"], cfg[\"Cin\"], cfg[\"Cout\"], cfg[\"H\"], cfg[\"W\"], cfg[\"ks\"]\n",
    "    stride, padding, dilation = cfg[\"stride\"], cfg[\"padding\"], cfg[\"dilation\"]\n",
    "    Sh, Sw = (stride, stride) if isinstance(stride, int) else stride\n",
    "    Ph, Pw = (padding, padding) if isinstance(padding, int) else padding\n",
    "    Dh, Dw = (dilation, dilation) if isinstance(dilation, int) else dilation\n",
    "    Kh = Kw = ks\n",
    "    Ho, Wo = out_hw(H, W, Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw)\n",
    "\n",
    "    M = B * Ho * Wo\n",
    "    K = Cin * Kh * Kw\n",
    "    N = Cout\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    A_fp32 = torch.randn(M, K, device=device, dtype=torch.float32)\n",
    "    B_fp32 = torch.randn(K, N, device=device, dtype=torch.float32)\n",
    "\n",
    "    # эталон\n",
    "    with torch.no_grad():\n",
    "        C_ref = (A_fp32 @ B_fp32).float()\n",
    "\n",
    "    for tile in tile_cfgs:\n",
    "        BLOCK_M = tile[\"BLOCK_M\"]\n",
    "        BLOCK_N = tile[\"BLOCK_N\"]\n",
    "        BLOCK_K = tile[\"BLOCK_K\"]\n",
    "        NUM_WARPS = tile[\"NUM_WARPS\"]\n",
    "        NUM_STAGES = tile[\"NUM_STAGES\"]\n",
    "\n",
    "        print(f\"\\n[int8 GEMM] cfg={tile}\")\n",
    "\n",
    "        # квант\n",
    "        A_q, s_A = quantize_per_tensor_symmetric(A_fp32)\n",
    "        B_q, s_B = quantize_per_tensor_symmetric(B_fp32)\n",
    "\n",
    "        # FWD\n",
    "        with torch.no_grad():\n",
    "            C_tri = gemm_int8_tc(\n",
    "                A_q,\n",
    "                B_q,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_N=BLOCK_N,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                num_warps=NUM_WARPS,\n",
    "                num_stages=NUM_STAGES,\n",
    "            )  # fp32 acc\n",
    "            C_tri = C_tri * (s_A * s_B)\n",
    "\n",
    "            diff = (C_ref - C_tri).abs()\n",
    "            f_mae = diff.mean().item()\n",
    "            f_mx = diff.max().item()\n",
    "\n",
    "        # Тайминги\n",
    "        def f_torch():\n",
    "            A_fp32 @ B_fp32\n",
    "\n",
    "        def f_tri():\n",
    "            C_ = gemm_int8_tc(\n",
    "                A_q,\n",
    "                B_q,\n",
    "                BLOCK_M=BLOCK_M,\n",
    "                BLOCK_N=BLOCK_N,\n",
    "                BLOCK_K=BLOCK_K,\n",
    "                num_warps=NUM_WARPS,\n",
    "                num_stages=NUM_STAGES,\n",
    "            )\n",
    "            _ = C_ * (s_A * s_B)\n",
    "\n",
    "        t_torch = bench(f_torch, warmup=30, iters=200)\n",
    "        t_tri = bench(f_tri, warmup=30, iters=200)\n",
    "\n",
    "        row(\n",
    "            \"Этап\",\n",
    "            [\"FWD MAE\", \"FWD max\", \"Torch mm ms\", \"Triton int8 GEMM ms\", \"Speedup\"],\n",
    "        )\n",
    "        row(\n",
    "            \"Знач\",\n",
    "            [\n",
    "                f\"{f_mae:.3e}\",\n",
    "                f\"{f_mx:.3e}\",\n",
    "                f\"{t_torch * 1e3:.3f}\",\n",
    "                f\"{t_tri * 1e3:.3f}\",\n",
    "                f\"{t_torch / max(t_tri, 1e-12):.2f}x\",\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc830f0d-b11c-4dec-acd7-7802d65f353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INT8 img2col/col2im & GEMM benchmarks ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chapter_img2col_col2im_int8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m      7\u001b[0m TILE_CONFIGS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mdict\u001b[39m(BLOCK_M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, BLOCK_N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, BLOCK_K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, NUM_WARPS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, NUM_STAGES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mdict\u001b[39m(BLOCK_M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, BLOCK_N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, BLOCK_K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, NUM_WARPS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, NUM_STAGES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mdict\u001b[39m(BLOCK_M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, BLOCK_N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, BLOCK_K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, NUM_WARPS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, NUM_STAGES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== INT8 img2col/col2im & GEMM benchmarks ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mchapter_img2col_col2im_int8\u001b[49m(cfg, TILE_CONFIGS)\n\u001b[1;32m     19\u001b[0m chapter_gemm_int8(cfg, TILE_CONFIGS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chapter_img2col_col2im_int8' is not defined"
     ]
    }
   ],
   "source": [
    "cfg = dict(\n",
    "    B=2, Cin=64, Cout=128, H=320, W=320, ks=3,\n",
    "    stride=1, padding=1, dilation=1,\n",
    "    # если у тебя там ещё dtype/use_bias и т.п. — оставь\n",
    ")\n",
    "    # Набор тайлов (как в твоих тестах) — сюда же потом подставишь \"лучшие\"\n",
    "TILE_CONFIGS = [\n",
    "        dict(BLOCK_M=64, BLOCK_N=64, BLOCK_K=32, NUM_WARPS=4, NUM_STAGES=2),\n",
    "        dict(BLOCK_M=64, BLOCK_N=32, BLOCK_K=32, NUM_WARPS=4, NUM_STAGES=2),\n",
    "        dict(BLOCK_M=32, BLOCK_N=64, BLOCK_K=32, NUM_WARPS=4, NUM_STAGES=2),\n",
    "\n",
    "        dict(BLOCK_M=64, BLOCK_N=64, BLOCK_K=32, NUM_WARPS=4, NUM_STAGES=1),\n",
    "\n",
    "        dict(BLOCK_M=64, BLOCK_N=64, BLOCK_K=32, NUM_WARPS=2, NUM_STAGES=2),\n",
    "    ]\n",
    "\n",
    "print(\"\\n=== INT8 img2col/col2im & GEMM benchmarks ===\")\n",
    "chapter_img2col_col2im_int8(cfg, TILE_CONFIGS)\n",
    "chapter_gemm_int8(cfg, TILE_CONFIGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78e3cc-26e6-45d2-882f-46f950ff02e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d503f8b-4dc9-4a8f-8661-6dbe41f5f170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849487c2-2fe7-4ffc-b21b-09d40fd71abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9ee2f-f2d2-4ce4-b494-a23c1a06ab40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "530d64b9-3d77-456b-be2e-b7ad654cc6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] gemm_int8 не найден или не загрузился, fallback на torch (медленно)\n",
      "[WARN] причина: OSError('/home/manzhura/ITMO/EDLM/venv/lib/python3.10/site-packages/gemm_int8/gemm_int8_CUDA.so: undefined symbol: _ZN5torch7LibraryC1ENS0_4KindESsN3c108optionalINS2_11DispatchKeyEEEPKcj')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- пробуем зацепить gemm_int8, если есть ---\n",
    "\n",
    "_USE_GEMM_INT8 = False\n",
    "try:\n",
    "    import gemm_int8\n",
    "    _USE_GEMM_INT8 = True\n",
    "    print(\"[INFO] gemm_int8 найден, буду использовать его для GEMM\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] gemm_int8 не найден или не загрузился, fallback на torch (медленно)\")\n",
    "    print(\"[WARN] причина:\", repr(e))\n",
    "\n",
    "\n",
    "def quantize_int8_per_tensor(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Очень простой per-tensor квант: x -> int8, возвращает (x_q, scale).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        max_abs = x.abs().max()\n",
    "        # чтобы не делить на 0\n",
    "        scale = (max_abs / 127.0).clamp(min=1e-8)\n",
    "        x_q = (x / scale).round().clamp(-128, 127).to(torch.int8)\n",
    "    return x_q, scale\n",
    "\n",
    "\n",
    "def int8_gemm(x_q: torch.Tensor, w_q: torch.Tensor, s_x: torch.Tensor, s_w: torch.Tensor):\n",
    "    \"\"\"\n",
    "    x_q: [M, K] int8\n",
    "    w_q: [N, K] int8   (как в gemm_int8: второй операнд будет транспонироваться внутри)\n",
    "    возвращает: [M, N] (bf16 или float32) уже со скейлингом.\n",
    "    \"\"\"\n",
    "    alpha = float(s_x * s_w)\n",
    "    if _USE_GEMM_INT8:\n",
    "        # gemm_int8.matmul(X, Y, alpha) считает (X @ Y.T) * alpha\n",
    "        return gemm_int8.matmul(x_q, w_q, alpha=alpha)\n",
    "    else:\n",
    "        # медленный, но корректный fallback: int8 -> float32\n",
    "        x_f = x_q.float()\n",
    "        w_f = w_q.float()\n",
    "        return (x_f @ w_f.t()) * alpha\n",
    "\n",
    "\n",
    "class Int8UnfoldConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Свёртка: Unfold (на float) -> quant -> GEMM_INT8 -> reshape, только forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size, stride=1, padding=0, dilation=1, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "        if isinstance(dilation, int):\n",
    "            dilation = (dilation, dilation)\n",
    "\n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.empty(out_channels, in_channels, *kernel_size)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.unfold = nn.Unfold(\n",
    "            kernel_size=self.kernel_size,\n",
    "            dilation=self.dilation,\n",
    "            padding=self.padding,\n",
    "            stride=self.stride,\n",
    "        )\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: [N, Cin, H, W] (fp32/bf16)\n",
    "        \"\"\"\n",
    "        N, Cin, H, W = x.shape\n",
    "        Kh, Kw = self.kernel_size\n",
    "\n",
    "        # ---- Unfold на float ----\n",
    "        # cols_f: [N, Cin*Kh*Kw, L], L = Ho*Wo\n",
    "        cols_f = self.unfold(x)          # float\n",
    "        N_, K, L = cols_f.shape\n",
    "        assert N_ == N\n",
    "\n",
    "        # ---- квант патчей и весов в int8 ----\n",
    "        cols_q, s_x = quantize_int8_per_tensor(cols_f)   # [N, K, L] int8\n",
    "        w_q,   s_w  = quantize_int8_per_tensor(self.weight)\n",
    "\n",
    "        # X_q: [M, K], где M = N*L\n",
    "        X_q = cols_q.transpose(1, 2).contiguous().view(N * L, K)\n",
    "\n",
    "        # W_q: [Cout, K]\n",
    "        W_q = w_q.view(self.out_channels, K)\n",
    "\n",
    "        # ---- GEMM int8 ----\n",
    "        Y = int8_gemm(X_q, W_q, s_x, s_w)  # [M, Cout]\n",
    "\n",
    "        # ---- reshape обратно в [N, Cout, Ho, Wo] ----\n",
    "        Ho = (H + 2 * self.padding[0]\n",
    "              - self.dilation[0] * (Kh - 1) - 1) // self.stride[0] + 1\n",
    "        Wo = (W + 2 * self.padding[1]\n",
    "              - self.dilation[1] * (Kw - 1) - 1) // self.stride[1] + 1\n",
    "\n",
    "        Y = Y.view(N, L, self.out_channels).transpose(1, 2).contiguous()\n",
    "        Y = Y.view(N, self.out_channels, Ho, Wo)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            Y = Y + self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "        return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50a1def9-1b14-4453-8673-76c5a4cfc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench(fn, warmup=10, iters=50):\n",
    "    # простой бенч с синхронизацией\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "    return (time.perf_counter() - t0) / iters\n",
    "\n",
    "\n",
    "def run_benchmark():\n",
    "    device = \"cuda\"\n",
    "\n",
    "    # какие-нибудь реалистичные размеры\n",
    "    N, Cin, Cout = 32, 64, 64\n",
    "    H, W = 56, 56\n",
    "    ks = 3\n",
    "    stride = 1\n",
    "    padding = 1\n",
    "    dilation = 1\n",
    "\n",
    "    x = torch.randn(N, Cin, H, W, device=device)\n",
    "\n",
    "    conv_ref = nn.Conv2d(\n",
    "        Cin, Cout, ks,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=True,\n",
    "    ).to(device)\n",
    "\n",
    "    conv_int8 = Int8UnfoldConv2d(\n",
    "        Cin, Cout, ks,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=True,\n",
    "    ).to(device)\n",
    "\n",
    "    # чтобы сравнивать честно, копируем веса и биасы\n",
    "    with torch.no_grad():\n",
    "        conv_int8.weight.copy_(conv_ref.weight)\n",
    "        if conv_ref.bias is not None and conv_int8.bias is not None:\n",
    "            conv_int8.bias.copy_(conv_ref.bias)\n",
    "\n",
    "    # прогрев\n",
    "    with torch.no_grad():\n",
    "        y_ref = conv_ref(x)\n",
    "        y_int8 = conv_int8(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # ошибка (из-за квантования будет заметная, но нам сейчас важна скорость)\n",
    "    max_err = (y_ref - y_int8.to(y_ref.dtype)).abs().max().item()\n",
    "    print(f\"max_err = {max_err:.6f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t_ref = bench(lambda: conv_ref(x))\n",
    "        t_int8 = bench(lambda: conv_int8(x))\n",
    "\n",
    "    print(f\"Conv2d (cuDNN, fp32):      {t_ref*1e3:.3f} ms\")\n",
    "    print(f\"Unfold+GEMM (int8 path):   {t_int8*1e3:.3f} ms\")\n",
    "    print(f\"speedup (int8 / conv2d) =  {t_ref / t_int8:.3f}x\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a68899-df67-4206-ad62-8515bb501db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3bd0c-303d-4d00-9de2-7ae5f355ab36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e68207-d64e-49a4-a793-f32c4a36c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c5223-3c5e-4f1c-9d04-3dde8a75ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c2dfd-02f4-41b3-84e0-841871f95dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f25dca-52e0-48f1-b2a8-2e0b7136d128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a5502-3c59-4729-8008-52c3e0c94dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b73c15-fc0a-4315-b7f7-41231d918c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e092a2b-e058-491b-a6ca-4b9964a160a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aacd33-0c8b-47a6-ad4c-2b057a988f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99781e-78b4-4b26-bdb7-275d1857046d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
