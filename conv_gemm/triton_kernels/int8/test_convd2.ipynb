{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fde46-a7b2-422b-a4f2-3ee63a853400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b8f5ab-310e-4767-ae48-544685cf8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd13dfe-1893-4db3-a13d-c374e4e122bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2col_int8_kernel import img2col_int8\n",
    "from gemm_int8_kernel    import gemm_int8_tc\n",
    "from col2img_int8_kernel import col2img_int32\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4c2003-8e55-4fd0-9d5c-03cb941ae6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "I2C_BLOCK_M = 128\n",
    "I2C_BLOCK_K = 32\n",
    "I2C_WARPS   = 2\n",
    "I2C_STAGES  = 3\n",
    "\n",
    "# GEMM INT8\n",
    "GEMM_BLOCK_M = 64\n",
    "GEMM_BLOCK_N = 128\n",
    "GEMM_BLOCK_K = 64\n",
    "GEMM_WARPS   = 4\n",
    "GEMM_STAGES  = 3\n",
    "\n",
    "# col2img INT32\n",
    "C2I_BLOCK_M = 32\n",
    "C2I_BLOCK_K = 32\n",
    "C2I_WARPS   = 4\n",
    "C2I_STAGES  = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7e5941-9236-4354-a001-9750adc6e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_mean(fn, iters=50, warmup=10):\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    return (time.perf_counter() - t0) / iters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa1b60e-9e99-46b9-aab2-60fc7925b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_int8_forward(\n",
    "    x, w, bias,\n",
    "    stride, padding, dilation\n",
    "):\n",
    "    # ======== ВСЕ КОНСТАНТЫ БЕРЕМ ИЗ JUPYTER =========\n",
    "    global I2C_BLOCK_M, I2C_BLOCK_K, I2C_WARPS, I2C_STAGES\n",
    "    global GEMM_BLOCK_M, GEMM_BLOCK_N, GEMM_BLOCK_K, GEMM_WARPS, GEMM_STAGES\n",
    "\n",
    "    # floats\n",
    "    x_f = x.float()\n",
    "    w_f = w.float()\n",
    "\n",
    "    N, Cin, H, W = x_f.shape\n",
    "    Cout, Cin2, Kh, Kw = w_f.shape\n",
    "    assert Cin == Cin2\n",
    "\n",
    "    Sh, Sw = stride\n",
    "    Ph, Pw = padding\n",
    "    Dh, Dw = dilation\n",
    "\n",
    "    Ho = (H + 2*Ph - Dh*(Kh-1) - 1)//Sh + 1\n",
    "    Wo = (W + 2*Pw - Dw*(Kw-1) - 1)//Sw + 1\n",
    "    M = N * Ho * Wo\n",
    "\n",
    "    # ====== K-padding ======\n",
    "    K_real = Cin * Kh * Kw\n",
    "    K4 = (K_real + 3) // 4 * 4\n",
    "    K_pad = (K4 + GEMM_BLOCK_K - 1)//GEMM_BLOCK_K * GEMM_BLOCK_K\n",
    "\n",
    "    # ====== quant ======\n",
    "    sx = max(x_f.abs().max().item()/127, 1e-8)\n",
    "    sw = max(w_f.abs().max().item()/127, 1e-8)\n",
    "\n",
    "    x_q = torch.clamp((x_f/sx).round(), -128, 127).to(torch.int8)\n",
    "    w_q = torch.clamp((w_f/sw).round(), -128, 127).to(torch.int8)\n",
    "\n",
    "    # ====== IMG2COL ======\n",
    "    cols_q, _ = img2col_int8(\n",
    "        x_q,\n",
    "        Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "        K_pad,\n",
    "        I2C_BLOCK_M, I2C_BLOCK_K, I2C_WARPS, I2C_STAGES\n",
    "    )\n",
    "\n",
    "    # ====== PREPARE WEIGHTS ======\n",
    "    Wq = w_q.view(Cout, K_real).t().contiguous()\n",
    "    if K_pad > K_real:\n",
    "        pad = torch.zeros((K_pad-K_real, Cout), dtype=torch.int8, device=Wq.device)\n",
    "        Wq = torch.cat([Wq, pad], dim=0)\n",
    "\n",
    "    # ====== GEMM ======\n",
    "    C_i32 = gemm_int8_tc(\n",
    "        cols_q, Wq,\n",
    "        GEMM_BLOCK_M, GEMM_BLOCK_N, GEMM_BLOCK_K,\n",
    "        GEMM_WARPS, GEMM_STAGES\n",
    "    )\n",
    "\n",
    "    # ====== DEQUANT ======\n",
    "    y = C_i32.float() * (sx * sw)\n",
    "    if bias is not None:\n",
    "        y += bias.float().reshape(1, Cout)\n",
    "\n",
    "    return y.reshape(N, Ho, Wo, Cout).permute(0,3,1,2).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f65517-a74a-4740-bd2e-375b511d1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import triton\n",
    "import triton.runtime\n",
    "import triton.runtime.jit as jit\n",
    "def run_int8_forward_bench(\n",
    "    image_sizes=[56,112,224],\n",
    "    batch_sizes=[1,2,4],\n",
    "    channels=[(1,1),(1,3),(3,8),(8,16),(16,32),(32,64)],\n",
    "    kernels=[1,3,7,9,11,13],\n",
    "    iters=50\n",
    "):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    total = len(image_sizes)*len(batch_sizes)*len(channels)*len(kernels)\n",
    "    step  = 0\n",
    "\n",
    "    for img in image_sizes:\n",
    "        H = W = img\n",
    "\n",
    "        for N in batch_sizes:\n",
    "            for Cin, Cout in channels:\n",
    "                for ks in kernels:\n",
    "\n",
    "                    step += 1\n",
    "                    print(f\"[{step}/{total}] img={img}  N={N}  Cin={Cin} Cout={Cout} K={ks}\")\n",
    "\n",
    "                    x = torch.randn(N, Cin, H, W, device='cuda', dtype=torch.float16)\n",
    "\n",
    "                    conv = nn.Conv2d(\n",
    "                        Cin, Cout, ks,\n",
    "                        stride=1,\n",
    "                        padding=ks//2,\n",
    "                        bias=True\n",
    "                    ).cuda().half()\n",
    "\n",
    "                    w = conv.weight\n",
    "                    b = conv.bias\n",
    "\n",
    "                    # === FP16 baseline ===\n",
    "                    t_fp16 = bench_mean(lambda: conv(x), iters)\n",
    "                    y_ref = conv(x).float()\n",
    "\n",
    "                    # === INT8 forward ===\n",
    "                    y_int = conv2d_int8_forward(\n",
    "                        x, w, b,\n",
    "                        stride=(1,1),\n",
    "                        padding=(ks//2, ks//2),\n",
    "                        dilation=(1,1)\n",
    "                    )\n",
    "\n",
    "                    if y_int is None:\n",
    "                        rows.append([img, N, Cin, Cout, ks,\n",
    "                                     t_fp16*1e3, None, None, None])\n",
    "\n",
    "                        # === CLEAR CACHE ===\n",
    "                        torch.cuda.synchronize()\n",
    "                        jit.specialize_impl_cache.clear()\n",
    "                        torch.cuda.empty_cache()\n",
    "                        continue\n",
    "\n",
    "                    # === INT8 benchmark ===\n",
    "                    t_int8 = bench_mean(\n",
    "                        lambda: conv2d_int8_forward(\n",
    "                            x, w, b,\n",
    "                            stride=(1,1),\n",
    "                            padding=(ks//2, ks//2),\n",
    "                            dilation=(1,1)\n",
    "                        ),\n",
    "                        iters\n",
    "                    )\n",
    "\n",
    "                    err = (y_ref - y_int.float()).abs().max().item()\n",
    "\n",
    "                    rows.append([\n",
    "                        img, N, Cin, Cout, ks,\n",
    "                        t_fp16*1e3,\n",
    "                        t_int8*1e3,\n",
    "                        t_fp16 / t_int8,\n",
    "                        err\n",
    "                    ])\n",
    "\n",
    "                    # ====================================\n",
    "                    #            CLEAR MT CACHE\n",
    "                    # ====================================\n",
    "                    torch.cuda.synchronize()\n",
    "                    \n",
    "                    jit.specialize_impl_cache.clear()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"img\",\"N\",\"Cin\",\"Cout\",\"K\",\n",
    "        \"Conv2D FP16 (ms)\",\"Int8 (ms)\",\n",
    "        \"speedup\",\"err_max\"\n",
    "    ])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5de397-437b-48f9-83df-e3a77402b0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/160] img=112  N=1  Cin=1 Cout=1 K=1\n",
      "[2/160] img=112  N=1  Cin=1 Cout=1 K=3\n",
      "[3/160] img=112  N=1  Cin=1 Cout=1 K=7\n",
      "[4/160] img=112  N=1  Cin=1 Cout=1 K=9\n",
      "[5/160] img=112  N=1  Cin=1 Cout=1 K=11\n",
      "[6/160] img=112  N=1  Cin=1 Cout=3 K=1\n",
      "[7/160] img=112  N=1  Cin=1 Cout=3 K=3\n",
      "[8/160] img=112  N=1  Cin=1 Cout=3 K=7\n",
      "[9/160] img=112  N=1  Cin=1 Cout=3 K=9\n",
      "[10/160] img=112  N=1  Cin=1 Cout=3 K=11\n",
      "[11/160] img=112  N=1  Cin=3 Cout=8 K=1\n",
      "[12/160] img=112  N=1  Cin=3 Cout=8 K=3\n",
      "[13/160] img=112  N=1  Cin=3 Cout=8 K=7\n",
      "[14/160] img=112  N=1  Cin=3 Cout=8 K=9\n",
      "[15/160] img=112  N=1  Cin=3 Cout=8 K=11\n",
      "[16/160] img=112  N=1  Cin=8 Cout=16 K=1\n",
      "[17/160] img=112  N=1  Cin=8 Cout=16 K=3\n",
      "[18/160] img=112  N=1  Cin=8 Cout=16 K=7\n",
      "[19/160] img=112  N=1  Cin=8 Cout=16 K=9\n",
      "[20/160] img=112  N=1  Cin=8 Cout=16 K=11\n",
      "[21/160] img=112  N=2  Cin=1 Cout=1 K=1\n",
      "[22/160] img=112  N=2  Cin=1 Cout=1 K=3\n",
      "[23/160] img=112  N=2  Cin=1 Cout=1 K=7\n",
      "[24/160] img=112  N=2  Cin=1 Cout=1 K=9\n",
      "[25/160] img=112  N=2  Cin=1 Cout=1 K=11\n",
      "[26/160] img=112  N=2  Cin=1 Cout=3 K=1\n",
      "[27/160] img=112  N=2  Cin=1 Cout=3 K=3\n",
      "[28/160] img=112  N=2  Cin=1 Cout=3 K=7\n",
      "[29/160] img=112  N=2  Cin=1 Cout=3 K=9\n",
      "[30/160] img=112  N=2  Cin=1 Cout=3 K=11\n",
      "[31/160] img=112  N=2  Cin=3 Cout=8 K=1\n",
      "[32/160] img=112  N=2  Cin=3 Cout=8 K=3\n",
      "[33/160] img=112  N=2  Cin=3 Cout=8 K=7\n",
      "[34/160] img=112  N=2  Cin=3 Cout=8 K=9\n",
      "[35/160] img=112  N=2  Cin=3 Cout=8 K=11\n",
      "[36/160] img=112  N=2  Cin=8 Cout=16 K=1\n",
      "[37/160] img=112  N=2  Cin=8 Cout=16 K=3\n",
      "[38/160] img=112  N=2  Cin=8 Cout=16 K=7\n",
      "[39/160] img=112  N=2  Cin=8 Cout=16 K=9\n",
      "[40/160] img=112  N=2  Cin=8 Cout=16 K=11\n",
      "[41/160] img=224  N=1  Cin=1 Cout=1 K=1\n",
      "[42/160] img=224  N=1  Cin=1 Cout=1 K=3\n",
      "[43/160] img=224  N=1  Cin=1 Cout=1 K=7\n",
      "[44/160] img=224  N=1  Cin=1 Cout=1 K=9\n",
      "[45/160] img=224  N=1  Cin=1 Cout=1 K=11\n",
      "[46/160] img=224  N=1  Cin=1 Cout=3 K=1\n",
      "[47/160] img=224  N=1  Cin=1 Cout=3 K=3\n",
      "[48/160] img=224  N=1  Cin=1 Cout=3 K=7\n",
      "[49/160] img=224  N=1  Cin=1 Cout=3 K=9\n",
      "[50/160] img=224  N=1  Cin=1 Cout=3 K=11\n",
      "[51/160] img=224  N=1  Cin=3 Cout=8 K=1\n",
      "[52/160] img=224  N=1  Cin=3 Cout=8 K=3\n",
      "[53/160] img=224  N=1  Cin=3 Cout=8 K=7\n",
      "[54/160] img=224  N=1  Cin=3 Cout=8 K=9\n",
      "[55/160] img=224  N=1  Cin=3 Cout=8 K=11\n",
      "[56/160] img=224  N=1  Cin=8 Cout=16 K=1\n",
      "[57/160] img=224  N=1  Cin=8 Cout=16 K=3\n",
      "[58/160] img=224  N=1  Cin=8 Cout=16 K=7\n",
      "[59/160] img=224  N=1  Cin=8 Cout=16 K=9\n",
      "[60/160] img=224  N=1  Cin=8 Cout=16 K=11\n",
      "[61/160] img=224  N=2  Cin=1 Cout=1 K=1\n",
      "[62/160] img=224  N=2  Cin=1 Cout=1 K=3\n",
      "[63/160] img=224  N=2  Cin=1 Cout=1 K=7\n",
      "[64/160] img=224  N=2  Cin=1 Cout=1 K=9\n",
      "[65/160] img=224  N=2  Cin=1 Cout=1 K=11\n",
      "[66/160] img=224  N=2  Cin=1 Cout=3 K=1\n",
      "[67/160] img=224  N=2  Cin=1 Cout=3 K=3\n",
      "[68/160] img=224  N=2  Cin=1 Cout=3 K=7\n",
      "[69/160] img=224  N=2  Cin=1 Cout=3 K=9\n",
      "[70/160] img=224  N=2  Cin=1 Cout=3 K=11\n",
      "[71/160] img=224  N=2  Cin=3 Cout=8 K=1\n",
      "[72/160] img=224  N=2  Cin=3 Cout=8 K=3\n",
      "[73/160] img=224  N=2  Cin=3 Cout=8 K=7\n",
      "[74/160] img=224  N=2  Cin=3 Cout=8 K=9\n",
      "[75/160] img=224  N=2  Cin=3 Cout=8 K=11\n",
      "[76/160] img=224  N=2  Cin=8 Cout=16 K=1\n",
      "[77/160] img=224  N=2  Cin=8 Cout=16 K=3\n",
      "[78/160] img=224  N=2  Cin=8 Cout=16 K=7\n",
      "[79/160] img=224  N=2  Cin=8 Cout=16 K=9\n",
      "[80/160] img=224  N=2  Cin=8 Cout=16 K=11\n",
      "[81/160] img=512  N=1  Cin=1 Cout=1 K=1\n",
      "[82/160] img=512  N=1  Cin=1 Cout=1 K=3\n",
      "[83/160] img=512  N=1  Cin=1 Cout=1 K=7\n",
      "[84/160] img=512  N=1  Cin=1 Cout=1 K=9\n",
      "[85/160] img=512  N=1  Cin=1 Cout=1 K=11\n",
      "[86/160] img=512  N=1  Cin=1 Cout=3 K=1\n",
      "[87/160] img=512  N=1  Cin=1 Cout=3 K=3\n",
      "[88/160] img=512  N=1  Cin=1 Cout=3 K=7\n",
      "[89/160] img=512  N=1  Cin=1 Cout=3 K=9\n",
      "[90/160] img=512  N=1  Cin=1 Cout=3 K=11\n",
      "[91/160] img=512  N=1  Cin=3 Cout=8 K=1\n",
      "[92/160] img=512  N=1  Cin=3 Cout=8 K=3\n",
      "[93/160] img=512  N=1  Cin=3 Cout=8 K=7\n",
      "[94/160] img=512  N=1  Cin=3 Cout=8 K=9\n",
      "[95/160] img=512  N=1  Cin=3 Cout=8 K=11\n",
      "[96/160] img=512  N=1  Cin=8 Cout=16 K=1\n",
      "[97/160] img=512  N=1  Cin=8 Cout=16 K=3\n",
      "[98/160] img=512  N=1  Cin=8 Cout=16 K=7\n",
      "[99/160] img=512  N=1  Cin=8 Cout=16 K=9\n",
      "[100/160] img=512  N=1  Cin=8 Cout=16 K=11\n",
      "[101/160] img=512  N=2  Cin=1 Cout=1 K=1\n",
      "[102/160] img=512  N=2  Cin=1 Cout=1 K=3\n",
      "[103/160] img=512  N=2  Cin=1 Cout=1 K=7\n",
      "[104/160] img=512  N=2  Cin=1 Cout=1 K=9\n",
      "[105/160] img=512  N=2  Cin=1 Cout=1 K=11\n",
      "[106/160] img=512  N=2  Cin=1 Cout=3 K=1\n",
      "[107/160] img=512  N=2  Cin=1 Cout=3 K=3\n",
      "[108/160] img=512  N=2  Cin=1 Cout=3 K=7\n",
      "[109/160] img=512  N=2  Cin=1 Cout=3 K=9\n",
      "[110/160] img=512  N=2  Cin=1 Cout=3 K=11\n",
      "[111/160] img=512  N=2  Cin=3 Cout=8 K=1\n",
      "[112/160] img=512  N=2  Cin=3 Cout=8 K=3\n",
      "[113/160] img=512  N=2  Cin=3 Cout=8 K=7\n",
      "[114/160] img=512  N=2  Cin=3 Cout=8 K=9\n",
      "[115/160] img=512  N=2  Cin=3 Cout=8 K=11\n",
      "[116/160] img=512  N=2  Cin=8 Cout=16 K=1\n",
      "[117/160] img=512  N=2  Cin=8 Cout=16 K=3\n",
      "[118/160] img=512  N=2  Cin=8 Cout=16 K=7\n",
      "[119/160] img=512  N=2  Cin=8 Cout=16 K=9\n",
      "[120/160] img=512  N=2  Cin=8 Cout=16 K=11\n",
      "[121/160] img=1024  N=1  Cin=1 Cout=1 K=1\n",
      "[122/160] img=1024  N=1  Cin=1 Cout=1 K=3\n",
      "[123/160] img=1024  N=1  Cin=1 Cout=1 K=7\n",
      "[124/160] img=1024  N=1  Cin=1 Cout=1 K=9\n",
      "[125/160] img=1024  N=1  Cin=1 Cout=1 K=11\n",
      "[126/160] img=1024  N=1  Cin=1 Cout=3 K=1\n",
      "[127/160] img=1024  N=1  Cin=1 Cout=3 K=3\n",
      "[128/160] img=1024  N=1  Cin=1 Cout=3 K=7\n",
      "[129/160] img=1024  N=1  Cin=1 Cout=3 K=9\n",
      "[130/160] img=1024  N=1  Cin=1 Cout=3 K=11\n",
      "[131/160] img=1024  N=1  Cin=3 Cout=8 K=1\n",
      "[132/160] img=1024  N=1  Cin=3 Cout=8 K=3\n",
      "[133/160] img=1024  N=1  Cin=3 Cout=8 K=7\n",
      "[134/160] img=1024  N=1  Cin=3 Cout=8 K=9\n",
      "[135/160] img=1024  N=1  Cin=3 Cout=8 K=11\n",
      "[136/160] img=1024  N=1  Cin=8 Cout=16 K=1\n",
      "[137/160] img=1024  N=1  Cin=8 Cout=16 K=3\n",
      "[138/160] img=1024  N=1  Cin=8 Cout=16 K=7\n",
      "[139/160] img=1024  N=1  Cin=8 Cout=16 K=9\n",
      "[140/160] img=1024  N=1  Cin=8 Cout=16 K=11\n",
      "[141/160] img=1024  N=2  Cin=1 Cout=1 K=1\n",
      "[142/160] img=1024  N=2  Cin=1 Cout=1 K=3\n",
      "[143/160] img=1024  N=2  Cin=1 Cout=1 K=7\n",
      "[144/160] img=1024  N=2  Cin=1 Cout=1 K=9\n",
      "[145/160] img=1024  N=2  Cin=1 Cout=1 K=11\n",
      "[146/160] img=1024  N=2  Cin=1 Cout=3 K=1\n",
      "[147/160] img=1024  N=2  Cin=1 Cout=3 K=3\n",
      "[148/160] img=1024  N=2  Cin=1 Cout=3 K=7\n",
      "[149/160] img=1024  N=2  Cin=1 Cout=3 K=9\n",
      "[150/160] img=1024  N=2  Cin=1 Cout=3 K=11\n",
      "[151/160] img=1024  N=2  Cin=3 Cout=8 K=1\n",
      "[152/160] img=1024  N=2  Cin=3 Cout=8 K=3\n",
      "[153/160] img=1024  N=2  Cin=3 Cout=8 K=7\n",
      "[154/160] img=1024  N=2  Cin=3 Cout=8 K=9\n",
      "[155/160] img=1024  N=2  Cin=3 Cout=8 K=11\n",
      "[156/160] img=1024  N=2  Cin=8 Cout=16 K=1\n",
      "[157/160] img=1024  N=2  Cin=8 Cout=16 K=3\n",
      "[158/160] img=1024  N=2  Cin=8 Cout=16 K=7\n",
      "[159/160] img=1024  N=2  Cin=8 Cout=16 K=9\n",
      "[160/160] img=1024  N=2  Cin=8 Cout=16 K=11\n"
     ]
    }
   ],
   "source": [
    "df = run_int8_forward_bench(\n",
    "    image_sizes=[112,224,512,1024],\n",
    "    batch_sizes=[1,2],\n",
    "    channels=[(1,1),(1,3),(3,8),(8,16)],\n",
    "    kernels=[1,3,7,9,11],\n",
    "    iters=50\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c6bd7b-b612-4597-9c88-635dab4d61fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>N</th>\n",
       "      <th>Cin</th>\n",
       "      <th>Cout</th>\n",
       "      <th>K</th>\n",
       "      <th>Conv2D FP16 (ms)</th>\n",
       "      <th>Int8 (ms)</th>\n",
       "      <th>speedup</th>\n",
       "      <th>err_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.378325</td>\n",
       "      <td>0.551725</td>\n",
       "      <td>0.685713</td>\n",
       "      <td>0.026297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257690</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.515376</td>\n",
       "      <td>0.008919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.489019</td>\n",
       "      <td>1.205028</td>\n",
       "      <td>0.405815</td>\n",
       "      <td>0.032138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.432030</td>\n",
       "      <td>1.175181</td>\n",
       "      <td>0.367628</td>\n",
       "      <td>0.028213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>1.355743</td>\n",
       "      <td>0.348255</td>\n",
       "      <td>0.030536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.564765</td>\n",
       "      <td>1.859998</td>\n",
       "      <td>0.303637</td>\n",
       "      <td>0.035408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278038</td>\n",
       "      <td>0.930263</td>\n",
       "      <td>0.298881</td>\n",
       "      <td>0.042226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.405824</td>\n",
       "      <td>1.525819</td>\n",
       "      <td>0.265971</td>\n",
       "      <td>0.029239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.274263</td>\n",
       "      <td>1.114813</td>\n",
       "      <td>0.246017</td>\n",
       "      <td>0.029469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.290742</td>\n",
       "      <td>1.182929</td>\n",
       "      <td>0.245781</td>\n",
       "      <td>0.032350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>3.729781</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>0.035958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.563203</td>\n",
       "      <td>2.374872</td>\n",
       "      <td>0.237151</td>\n",
       "      <td>0.034317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173349</td>\n",
       "      <td>0.743342</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.013394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.600158</td>\n",
       "      <td>2.697870</td>\n",
       "      <td>0.222456</td>\n",
       "      <td>0.038444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.435343</td>\n",
       "      <td>1.998196</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.034182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133287</td>\n",
       "      <td>0.614181</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.026713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825132</td>\n",
       "      <td>4.775814</td>\n",
       "      <td>0.172773</td>\n",
       "      <td>0.032225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>1.577130</td>\n",
       "      <td>0.159512</td>\n",
       "      <td>0.033651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452812</td>\n",
       "      <td>2.859687</td>\n",
       "      <td>0.158343</td>\n",
       "      <td>0.025478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2.910314</td>\n",
       "      <td>18.627431</td>\n",
       "      <td>0.156238</td>\n",
       "      <td>0.037101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1.217231</td>\n",
       "      <td>8.090482</td>\n",
       "      <td>0.150452</td>\n",
       "      <td>0.032730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3.906588</td>\n",
       "      <td>26.608987</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.039413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.636272</td>\n",
       "      <td>4.368831</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>0.034550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7.476878</td>\n",
       "      <td>51.875478</td>\n",
       "      <td>0.144131</td>\n",
       "      <td>0.039646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.937298</td>\n",
       "      <td>6.550630</td>\n",
       "      <td>0.143085</td>\n",
       "      <td>0.032395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5.097429</td>\n",
       "      <td>36.258169</td>\n",
       "      <td>0.140587</td>\n",
       "      <td>0.037988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2.010665</td>\n",
       "      <td>14.840837</td>\n",
       "      <td>0.135482</td>\n",
       "      <td>0.036460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1.969504</td>\n",
       "      <td>14.830846</td>\n",
       "      <td>0.132798</td>\n",
       "      <td>0.035020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>0.735755</td>\n",
       "      <td>0.131340</td>\n",
       "      <td>0.030334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.324173</td>\n",
       "      <td>10.132073</td>\n",
       "      <td>0.130691</td>\n",
       "      <td>0.034857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.138651</td>\n",
       "      <td>1.079285</td>\n",
       "      <td>0.128466</td>\n",
       "      <td>0.024707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3.680712</td>\n",
       "      <td>28.831657</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.042667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168818</td>\n",
       "      <td>1.327731</td>\n",
       "      <td>0.127147</td>\n",
       "      <td>0.030584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.364886</td>\n",
       "      <td>10.797707</td>\n",
       "      <td>0.126405</td>\n",
       "      <td>0.037168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480310</td>\n",
       "      <td>3.888354</td>\n",
       "      <td>0.123525</td>\n",
       "      <td>0.019360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>0.629329</td>\n",
       "      <td>0.120908</td>\n",
       "      <td>0.033059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.080284</td>\n",
       "      <td>0.673272</td>\n",
       "      <td>0.119245</td>\n",
       "      <td>0.028994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.076623</td>\n",
       "      <td>0.652403</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.378911</td>\n",
       "      <td>3.460921</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.032513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.524040</td>\n",
       "      <td>0.108583</td>\n",
       "      <td>0.022942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.092778</td>\n",
       "      <td>0.856388</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.031106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.095882</td>\n",
       "      <td>0.921516</td>\n",
       "      <td>0.104048</td>\n",
       "      <td>0.028377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634481</td>\n",
       "      <td>6.125952</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.032257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.092926</td>\n",
       "      <td>0.900620</td>\n",
       "      <td>0.103180</td>\n",
       "      <td>0.037548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702680</td>\n",
       "      <td>7.008261</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>0.041795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.082817</td>\n",
       "      <td>0.831946</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.026117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1.596932</td>\n",
       "      <td>16.182900</td>\n",
       "      <td>0.098680</td>\n",
       "      <td>0.039685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834026</td>\n",
       "      <td>8.592085</td>\n",
       "      <td>0.097069</td>\n",
       "      <td>0.038412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.127035</td>\n",
       "      <td>1.321480</td>\n",
       "      <td>0.096131</td>\n",
       "      <td>0.029131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.109061</td>\n",
       "      <td>1.136814</td>\n",
       "      <td>0.095936</td>\n",
       "      <td>0.029328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  N  Cin  Cout   K  Conv2D FP16 (ms)  Int8 (ms)   speedup   err_max\n",
       "4     112  1    1     1  11          0.378325   0.551725  0.685713  0.026297\n",
       "0     112  1    1     1   1          0.257690   0.500004  0.515376  0.008919\n",
       "53    224  1    3     8   9          0.489019   1.205028  0.405815  0.032138\n",
       "33    112  2    3     8   9          0.432030   1.175181  0.367628  0.028213\n",
       "38    112  2    8    16   9          0.472144   1.355743  0.348255  0.030536\n",
       "91    512  1    3     8   3          0.564765   1.859998  0.303637  0.035408\n",
       "75    224  2    8    16   1          0.278038   0.930263  0.298881  0.042226\n",
       "69    224  2    1     3  11          0.405824   1.525819  0.265971  0.029239\n",
       "32    112  2    3     8   7          0.274263   1.114813  0.246017  0.029469\n",
       "64    224  2    1     1  11          0.290742   1.182929  0.245781  0.032350\n",
       "59    224  1    8    16  11          0.914675   3.729781  0.245236  0.035958\n",
       "89    512  1    1     3  11          0.563203   2.374872  0.237151  0.034317\n",
       "60    224  2    1     1   1          0.173349   0.743342  0.233202  0.013394\n",
       "58    224  1    8    16   9          0.600158   2.697870  0.222456  0.038444\n",
       "102   512  2    1     1   7          0.435343   1.998196  0.217868  0.034182\n",
       "30    112  2    3     8   1          0.133287   0.614181  0.217015  0.026713\n",
       "93    512  1    3     8   9          0.825132   4.775814  0.172773  0.032225\n",
       "35    112  2    8    16   1          0.251572   1.577130  0.159512  0.033651\n",
       "110   512  2    3     8   1          0.452812   2.859687  0.158343  0.025478\n",
       "133  1024  1    3     8   9          2.910314  18.627431  0.156238  0.037101\n",
       "94    512  1    3     8  11          1.217231   8.090482  0.150452  0.032730\n",
       "134  1024  1    3     8  11          3.906588  26.608987  0.146815  0.039413\n",
       "92    512  1    3     8   7          0.636272   4.368831  0.145639  0.034550\n",
       "154  1024  2    3     8  11          7.476878  51.875478  0.144131  0.039646\n",
       "79    224  2    8    16  11          0.937298   6.550630  0.143085  0.032395\n",
       "153  1024  2    3     8   9          5.097429  36.258169  0.140587  0.037988\n",
       "132  1024  1    3     8   7          2.010665  14.840837  0.135482  0.036460\n",
       "114   512  2    3     8  11          1.969504  14.830846  0.132798  0.035020\n",
       "12    112  1    3     8   7          0.096634   0.735755  0.131340  0.030334\n",
       "113   512  2    3     8   9          1.324173  10.132073  0.130691  0.034857\n",
       "49    224  1    1     3  11          0.138651   1.079285  0.128466  0.024707\n",
       "152  1024  2    3     8   7          3.680712  28.831657  0.127662  0.042667\n",
       "86    512  1    1     3   3          0.168818   1.327731  0.127147  0.030584\n",
       "151  1024  2    3     8   3          1.364886  10.797707  0.126405  0.037168\n",
       "125  1024  1    1     3   1          0.480310   3.888354  0.123525  0.019360\n",
       "16    112  1    8    16   3          0.076091   0.629329  0.120908  0.033059\n",
       "36    112  2    8    16   3          0.080284   0.673272  0.119245  0.028994\n",
       "51    224  1    3     8   3          0.076623   0.652403  0.117447  0.029000\n",
       "74    224  2    3     8  11          0.378911   3.460921  0.109483  0.032513\n",
       "22    112  2    1     1   7          0.056902   0.524040  0.108583  0.022942\n",
       "71    224  2    3     8   3          0.092778   0.856388  0.108336  0.031106\n",
       "13    112  1    3     8   9          0.095882   0.921516  0.104048  0.028377\n",
       "130  1024  1    3     8   1          0.634481   6.125952  0.103573  0.032257\n",
       "56    224  1    8    16   3          0.092926   0.900620  0.103180  0.037548\n",
       "135  1024  1    8    16   1          0.702680   7.008261  0.100265  0.041795\n",
       "2     112  1    1     1   7          0.082817   0.831946  0.099546  0.026117\n",
       "117   512  2    8    16   7          1.596932  16.182900  0.098680  0.039685\n",
       "147  1024  2    1     3   7          0.834026   8.592085  0.097069  0.038412\n",
       "34    112  2    3     8  11          0.127035   1.321480  0.096131  0.029131\n",
       "19    112  1    8    16  11          0.109061   1.136814  0.095936  0.029328"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by=\"speedup\", ascending=False)\n",
    "df_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25547ef3-9c82-42fe-ba66-efbf5ad6a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855325a2-9202-4f20-9bda-87815862e6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429dc073-c1b8-48d2-b6c9-fa740444b407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1eb902-5f96-4907-88c0-23f3751326a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c628b57-0360-4da8-b821-90c9ec6d79e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3671b3-62ac-458c-aa96-7a7a5048e27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb46873-3f57-4fc9-8939-d4aa39312ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dcf2fa-918a-4cb5-a707-5eba1c0c514b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268a128-1460-407a-81e7-81e2557c6f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
