Обзор:
1) Исследовать классическую реализацию nn.Conv2d в PyTorch.
2) Реализовать преобразование свёртки в форму img2col, чтобы свести задачу к матричному умножению (GEMM).
3) Рассмотреть разные подходы к оптимизации:
          - спарсификация весов (ускорение за счёт разреженности)
          - квантование (fp16 → int8)

Экспериментальная часть:
1) Реализовать преобразование Conv2d → img2col → GEMM.
2) Добавить оптимизации:
          - спарсификация весов
          - квантование активаций/весов
3) Подключить данный блок в простую модель (например, LeNet или ResNet18) вместо стандартного nn.Conv2d.
4) Запустить обучение и сравнить:
           - forward и backward время
           - использование GPU памяти
5) Провести сравнение на разных размерах ядер (3×3, 5×5, 7×7) и разных batch size.

Критерии проекта
1) Реализовано преобразование Conv2d в img2col + GEMM.
2) Реализованы два типа оптимизации: спарсификация и квантование.
3) Получено ускорение ≥15% хотя бы на одном размере ядра или batch size.
4) Подготовлен отчёт с таблицами метрик (время, использование памяти).
5) Подготовлен целостный GitHub-репозиторий с кодом и инструкцией по воспроизведению.

P.S.Все эксперименты должны сопровождаться замером времени выполнения (с обязательным вызовом cuda.synchronize() для корректности измерений).