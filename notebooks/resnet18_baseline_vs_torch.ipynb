{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34dffa7c",
   "metadata": {},
   "source": [
    "# ResNet18 Baseline Conv2d Benchmark\n",
    "\n",
    "Сравнение nn.Conv2d и кастомной img2col→GEMM свёртки (Baseline TritonConv2d) на ResNet18 с разными batch size и сценариями спарсификации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319e97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4154eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from conv_gemm.baseline_layers.triton_conv2d import TritonConv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da3ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_root\": \"/home/manzhura/ITMO/EDLM/conv2d-img2col-gemm/data\",\n",
      "  \"num_classes\": 10,\n",
      "  \"batch_sizes\": [\n",
      "    32,\n",
      "    64,\n",
      "    96,\n",
      "    128,\n",
      "    160,\n",
      "    192,\n",
      "    256\n",
      "  ],\n",
      "  \"num_workers\": 4,\n",
      "  \"train_subset\": 8192,\n",
      "  \"lr\": 0.001,\n",
      "  \"momentum\": 0.9,\n",
      "  \"weight_decay\": 0.0005,\n",
      "  \"warmup_steps\": 5,\n",
      "  \"benchmark_steps\": 40,\n",
      "  \"baseline_conv\": {\n",
      "    \"BLOCK_M\": 64,\n",
      "    \"BLOCK_N\": 64,\n",
      "    \"BLOCK_K\": 64,\n",
      "    \"NUM_WARPS\": 4,\n",
      "    \"NUM_STAGES\": 2\n",
      "  },\n",
      "  \"sparsity_bench\": {\n",
      "    \"modes\": [\n",
      "      \"channel\",\n",
      "      \"block\",\n",
      "      \"input\"\n",
      "    ],\n",
      "    \"keep_ratios\": [\n",
      "      0.75,\n",
      "      0.6,\n",
      "      0.5,\n",
      "      0.25\n",
      "    ],\n",
      "    \"block_size\": 4,\n",
      "    \"batch_size\": 128\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type != \"cuda\":\n",
    "    raise RuntimeError(\"CUDA GPU is required for this benchmark\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "data_root = Path(\"../data\").resolve()\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"data_root\": str(data_root),\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_sizes\": [32, 64, 96, 128, 160, 192, 256],\n",
    "    \"num_workers\": 4,\n",
    "    \"train_subset\": 8192,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"warmup_steps\": 5,\n",
    "    \"benchmark_steps\": 40,\n",
    "    \"baseline_conv\": {\n",
    "        \"BLOCK_M\": 64,\n",
    "        \"BLOCK_N\": 64,\n",
    "        \"BLOCK_K\": 64,\n",
    "        \"NUM_WARPS\": 4,\n",
    "        \"NUM_STAGES\": 2,\n",
    "    },\n",
    "    \"sparsity_bench\": {\n",
    "        \"modes\": [\"channel\", \"block\", \"input\"],\n",
    "        \"keep_ratios\": [0.75, 0.6, 0.5, 0.25],\n",
    "        \"block_size\": 4,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "}\n",
    "print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e44fbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{32: 256, 64: 128, 96: 85, 128: 64, 160: 51, 192: 42, 256: 32}\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(\n",
    "    root=config[\"data_root\"], train=True, download=True, transform=transform_train\n",
    ")\n",
    "if config[\"train_subset\"] is not None and config[\"train_subset\"] < len(full_train):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    subset_idx = torch.randperm(len(full_train), generator=g)[: config[\"train_subset\"]]\n",
    "    train_dataset = torch.utils.data.Subset(full_train, subset_idx)\n",
    "else:\n",
    "    train_dataset = full_train\n",
    "\n",
    "\n",
    "def make_loader(batch_size: int) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "train_loaders: Dict[int, DataLoader] = {}\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    train_loaders[bs] = make_loader(bs)\n",
    "\n",
    "print({bs: len(loader) for bs, loader in train_loaders.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbd874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triton_conv(src: nn.Conv2d, cfg: dict) -> TritonConv2d:\n",
    "    if src.groups != 1:\n",
    "        raise ValueError(\"Baseline TritonConv2d currently supports groups=1 only\")\n",
    "    layer = TritonConv2d(\n",
    "        in_channels=src.in_channels,\n",
    "        out_channels=src.out_channels,\n",
    "        kernel_size=src.kernel_size,\n",
    "        stride=src.stride,\n",
    "        padding=src.padding,\n",
    "        dilation=src.dilation,\n",
    "        bias=(src.bias is not None),\n",
    "        # **cfg,\n",
    "    ).to(src.weight.device)\n",
    "    with torch.no_grad():\n",
    "        layer.weight.copy_(src.weight.detach().to(layer.weight.dtype))\n",
    "        if layer.bias is not None and src.bias is not None:\n",
    "            layer.bias.copy_(src.bias.detach().to(layer.bias.dtype))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def replace_convs_with_baseline(module: nn.Module, cfg: dict):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, make_triton_conv(child, cfg))\n",
    "        else:\n",
    "            replace_convs_with_baseline(child, cfg)\n",
    "\n",
    "\n",
    "def build_model_pair(config: dict):\n",
    "    reference = torchvision.models.resnet18(num_classes=config[\"num_classes\"])\n",
    "    baseline = copy.deepcopy(reference)\n",
    "    replace_convs_with_baseline(baseline, config[\"baseline_conv\"])\n",
    "    return reference, baseline\n",
    "\n",
    "\n",
    "def apply_sparsity_to_model(model: nn.Module, mode: str, keep_ratio: float, block_size: int = 4):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, TritonConv2d):\n",
    "            layer.clear_sparsity()\n",
    "            if keep_ratio >= 1.0:\n",
    "                continue\n",
    "            if mode == \"channel\":\n",
    "                layer.set_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_channel_sparsity(keep_ratio)\n",
    "            elif mode == \"block\":\n",
    "                layer.set_block_sparsity(keep_ratio, block_size=block_size)\n",
    "                layer.set_backward_block_sparsity(keep_ratio, block_size=block_size)\n",
    "            elif mode == \"input\":\n",
    "                layer.set_input_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_input_channel_sparsity(keep_ratio)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sparsity mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968c84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model: nn.Module, label: str, loader: DataLoader, config: dict):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    warmup = config[\"warmup_steps\"]\n",
    "    total_steps = config[\"benchmark_steps\"]\n",
    "    records = []\n",
    "    data_iter = iter(loader)\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            images, targets = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(loader)\n",
    "            images, targets = next(data_iter)\n",
    "\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        fwd_end = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        fwd_start.record()\n",
    "        outputs = model(images)\n",
    "        fwd_end.record()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        bwd_start.record()\n",
    "        loss.backward()\n",
    "        bwd_end.record()\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_ms = fwd_start.elapsed_time(fwd_end)\n",
    "        bwd_ms = bwd_start.elapsed_time(bwd_end)\n",
    "        step_ms = fwd_ms + bwd_ms\n",
    "        mem_alloc = torch.cuda.max_memory_allocated(device) / 1024 ** 2\n",
    "        mem_reserved = torch.cuda.max_memory_reserved(device) / 1024 ** 2\n",
    "\n",
    "        if step >= warmup:\n",
    "            records.append({\n",
    "                \"label\": label,\n",
    "                \"step\": step,\n",
    "                \"loss\": float(loss.item()),\n",
    "                \"fwd_ms\": fwd_ms,\n",
    "                \"bwd_ms\": bwd_ms,\n",
    "                \"step_ms\": step_ms,\n",
    "                \"throughput_sps\": images.size(0) / (step_ms / 1000.0),\n",
    "                \"max_mem_alloc_mb\": mem_alloc,\n",
    "                \"max_mem_reserved_mb\": mem_reserved,\n",
    "            })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No data recorded for benchmark\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    summary = {\n",
    "        \"label\": label,\n",
    "        \"avg_forward_ms\": df[\"fwd_ms\"].mean(),\n",
    "        \"avg_backward_ms\": df[\"bwd_ms\"].mean(),\n",
    "        \"avg_step_ms\": df[\"step_ms\"].mean(),\n",
    "        \"samples_per_s\": df[\"throughput_sps\"].mean(),\n",
    "        \"max_mem_alloc_mb\": df[\"max_mem_alloc_mb\"].max(),\n",
    "        \"max_mem_reserved_mb\": df[\"max_mem_reserved_mb\"].max(),\n",
    "    }\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037f8b1",
   "metadata": {},
   "source": [
    "Таблица `summary_df` показывает средние метрики по каждому batch size: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `samples_per_s`, а также пики памяти (`max_mem_alloc_mb`, `max_mem_reserved_mb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f25b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch size 32 ===\n",
      "=== Batch size 64 ===\n",
      "=== Batch size 96 ===\n",
      "=== Batch size 128 ===\n",
      "=== Batch size 160 ===\n",
      "=== Batch size 192 ===\n",
      "=== Batch size 256 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>nn.Conv2d (bs=32)</td>\n",
       "      <td>4.718899</td>\n",
       "      <td>4.217519</td>\n",
       "      <td>8.936418</td>\n",
       "      <td>3730.567146</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>Baseline TritonConv2d (bs=32)</td>\n",
       "      <td>19.836949</td>\n",
       "      <td>14.022024</td>\n",
       "      <td>33.858973</td>\n",
       "      <td>976.347011</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>nn.Conv2d (bs=64)</td>\n",
       "      <td>4.079050</td>\n",
       "      <td>3.708465</td>\n",
       "      <td>7.787515</td>\n",
       "      <td>8566.292460</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>Baseline TritonConv2d (bs=64)</td>\n",
       "      <td>17.765971</td>\n",
       "      <td>15.295524</td>\n",
       "      <td>33.061495</td>\n",
       "      <td>2087.275114</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>nn.Conv2d (bs=96)</td>\n",
       "      <td>2.895120</td>\n",
       "      <td>3.304866</td>\n",
       "      <td>6.199985</td>\n",
       "      <td>15602.282334</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>Baseline TritonConv2d (bs=96)</td>\n",
       "      <td>16.232723</td>\n",
       "      <td>14.990402</td>\n",
       "      <td>31.223125</td>\n",
       "      <td>3169.658079</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>nn.Conv2d (bs=128)</td>\n",
       "      <td>2.407906</td>\n",
       "      <td>3.489559</td>\n",
       "      <td>5.897465</td>\n",
       "      <td>21868.949079</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>Baseline TritonConv2d (bs=128)</td>\n",
       "      <td>13.662614</td>\n",
       "      <td>15.380720</td>\n",
       "      <td>29.043334</td>\n",
       "      <td>4512.833889</td>\n",
       "      <td>281.832520</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>nn.Conv2d (bs=160)</td>\n",
       "      <td>2.614747</td>\n",
       "      <td>3.974958</td>\n",
       "      <td>6.589705</td>\n",
       "      <td>24334.832347</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>Baseline TritonConv2d (bs=160)</td>\n",
       "      <td>11.562864</td>\n",
       "      <td>16.098852</td>\n",
       "      <td>27.661716</td>\n",
       "      <td>5791.891497</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>nn.Conv2d (bs=192)</td>\n",
       "      <td>2.697283</td>\n",
       "      <td>4.452401</td>\n",
       "      <td>7.149684</td>\n",
       "      <td>26948.687933</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>Baseline TritonConv2d (bs=192)</td>\n",
       "      <td>12.458638</td>\n",
       "      <td>18.886051</td>\n",
       "      <td>31.344689</td>\n",
       "      <td>6147.323264</td>\n",
       "      <td>335.710449</td>\n",
       "      <td>402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>nn.Conv2d (bs=256)</td>\n",
       "      <td>2.951425</td>\n",
       "      <td>5.560192</td>\n",
       "      <td>8.511617</td>\n",
       "      <td>30291.919684</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>Baseline TritonConv2d (bs=256)</td>\n",
       "      <td>12.359798</td>\n",
       "      <td>23.422233</td>\n",
       "      <td>35.782031</td>\n",
       "      <td>7177.305322</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           label  \\\n",
       "variant               batch_size                                   \n",
       "nn.Conv2d             32                       nn.Conv2d (bs=32)   \n",
       "Baseline TritonConv2d 32           Baseline TritonConv2d (bs=32)   \n",
       "nn.Conv2d             64                       nn.Conv2d (bs=64)   \n",
       "Baseline TritonConv2d 64           Baseline TritonConv2d (bs=64)   \n",
       "nn.Conv2d             96                       nn.Conv2d (bs=96)   \n",
       "Baseline TritonConv2d 96           Baseline TritonConv2d (bs=96)   \n",
       "nn.Conv2d             128                     nn.Conv2d (bs=128)   \n",
       "Baseline TritonConv2d 128         Baseline TritonConv2d (bs=128)   \n",
       "nn.Conv2d             160                     nn.Conv2d (bs=160)   \n",
       "Baseline TritonConv2d 160         Baseline TritonConv2d (bs=160)   \n",
       "nn.Conv2d             192                     nn.Conv2d (bs=192)   \n",
       "Baseline TritonConv2d 192         Baseline TritonConv2d (bs=192)   \n",
       "nn.Conv2d             256                     nn.Conv2d (bs=256)   \n",
       "Baseline TritonConv2d 256         Baseline TritonConv2d (bs=256)   \n",
       "\n",
       "                                  avg_forward_ms  avg_backward_ms  \\\n",
       "variant               batch_size                                    \n",
       "nn.Conv2d             32                4.718899         4.217519   \n",
       "Baseline TritonConv2d 32               19.836949        14.022024   \n",
       "nn.Conv2d             64                4.079050         3.708465   \n",
       "Baseline TritonConv2d 64               17.765971        15.295524   \n",
       "nn.Conv2d             96                2.895120         3.304866   \n",
       "Baseline TritonConv2d 96               16.232723        14.990402   \n",
       "nn.Conv2d             128               2.407906         3.489559   \n",
       "Baseline TritonConv2d 128              13.662614        15.380720   \n",
       "nn.Conv2d             160               2.614747         3.974958   \n",
       "Baseline TritonConv2d 160              11.562864        16.098852   \n",
       "nn.Conv2d             192               2.697283         4.452401   \n",
       "Baseline TritonConv2d 192              12.458638        18.886051   \n",
       "nn.Conv2d             256               2.951425         5.560192   \n",
       "Baseline TritonConv2d 256              12.359798        23.422233   \n",
       "\n",
       "                                  avg_step_ms  samples_per_s  \\\n",
       "variant               batch_size                               \n",
       "nn.Conv2d             32             8.936418    3730.567146   \n",
       "Baseline TritonConv2d 32            33.858973     976.347011   \n",
       "nn.Conv2d             64             7.787515    8566.292460   \n",
       "Baseline TritonConv2d 64            33.061495    2087.275114   \n",
       "nn.Conv2d             96             6.199985   15602.282334   \n",
       "Baseline TritonConv2d 96            31.223125    3169.658079   \n",
       "nn.Conv2d             128            5.897465   21868.949079   \n",
       "Baseline TritonConv2d 128           29.043334    4512.833889   \n",
       "nn.Conv2d             160            6.589705   24334.832347   \n",
       "Baseline TritonConv2d 160           27.661716    5791.891497   \n",
       "nn.Conv2d             192            7.149684   26948.687933   \n",
       "Baseline TritonConv2d 192           31.344689    6147.323264   \n",
       "nn.Conv2d             256            8.511617   30291.919684   \n",
       "Baseline TritonConv2d 256           35.782031    7177.305322   \n",
       "\n",
       "                                  max_mem_alloc_mb  max_mem_reserved_mb  \n",
       "variant               batch_size                                         \n",
       "nn.Conv2d             32                190.307129                220.0  \n",
       "Baseline TritonConv2d 32                207.492676                226.0  \n",
       "nn.Conv2d             64                190.058105                228.0  \n",
       "Baseline TritonConv2d 64                228.024902                256.0  \n",
       "nn.Conv2d             96                190.685059                222.0  \n",
       "Baseline TritonConv2d 96                252.019043                312.0  \n",
       "nn.Conv2d             128               204.617676                228.0  \n",
       "Baseline TritonConv2d 128               281.832520                340.0  \n",
       "nn.Conv2d             160               219.119629                252.0  \n",
       "Baseline TritonConv2d 160               306.271973                366.0  \n",
       "nn.Conv2d             192               230.495605                274.0  \n",
       "Baseline TritonConv2d 192               335.710449                402.0  \n",
       "nn.Conv2d             256               258.373535                306.0  \n",
       "Baseline TritonConv2d 256               383.338379                598.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_summaries = []\n",
    "batch_details = []\n",
    "\n",
    "for bs, loader in train_loaders.items():\n",
    "    print(f\"=== Batch size {bs} ===\")\n",
    "    torch_model, baseline_model = build_model_pair(config)\n",
    "\n",
    "    torch_df, torch_summary = run_benchmark(torch_model, f\"nn.Conv2d (bs={bs})\", loader, config)\n",
    "    torch_summary.update({\"variant\": \"nn.Conv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(torch_summary)\n",
    "    batch_details.append(torch_df.assign(variant=\"nn.Conv2d\", batch_size=bs))\n",
    "\n",
    "    baseline_df, baseline_summary = run_benchmark(baseline_model, f\"Baseline TritonConv2d (bs={bs})\", loader, config)\n",
    "    baseline_summary.update({\"variant\": \"Baseline TritonConv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(baseline_summary)\n",
    "    batch_details.append(baseline_df.assign(variant=\"Baseline TritonConv2d\", batch_size=bs))\n",
    "\n",
    "summary_df = pd.DataFrame(batch_summaries).set_index([\"variant\", \"batch_size\"])\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b90a09",
   "metadata": {},
   "source": [
    "Вывод `detail_df.groupby(...).describe()` содержит count/mean/std/min/25%/50%/75%/max для метрик `step_ms`, `fwd_ms`, `bwd_ms`, `max_mem_alloc_mb` отдельно по каждому `(variant, batch_size)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e564a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">step_ms</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fwd_ms</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bwd_ms</th>\n",
       "      <th colspan=\"8\" halign=\"left\">max_mem_alloc_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>33.858973</td>\n",
       "      <td>5.744641</td>\n",
       "      <td>22.376801</td>\n",
       "      <td>28.662608</td>\n",
       "      <td>37.607103</td>\n",
       "      <td>38.315744</td>\n",
       "      <td>40.636736</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.836949</td>\n",
       "      <td>...</td>\n",
       "      <td>16.020480</td>\n",
       "      <td>16.560127</td>\n",
       "      <td>35.0</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>207.492676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>33.061495</td>\n",
       "      <td>8.217262</td>\n",
       "      <td>20.058176</td>\n",
       "      <td>22.539360</td>\n",
       "      <td>38.267839</td>\n",
       "      <td>38.718416</td>\n",
       "      <td>42.518528</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.765971</td>\n",
       "      <td>...</td>\n",
       "      <td>17.565184</td>\n",
       "      <td>21.909248</td>\n",
       "      <td>35.0</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>228.024902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>31.223125</td>\n",
       "      <td>5.574035</td>\n",
       "      <td>23.408384</td>\n",
       "      <td>26.591424</td>\n",
       "      <td>30.303201</td>\n",
       "      <td>35.195487</td>\n",
       "      <td>41.889696</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.232723</td>\n",
       "      <td>...</td>\n",
       "      <td>17.261568</td>\n",
       "      <td>24.862720</td>\n",
       "      <td>35.0</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>252.019043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>29.043334</td>\n",
       "      <td>4.832932</td>\n",
       "      <td>23.702687</td>\n",
       "      <td>26.200144</td>\n",
       "      <td>27.248800</td>\n",
       "      <td>31.422801</td>\n",
       "      <td>41.012735</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.662614</td>\n",
       "      <td>...</td>\n",
       "      <td>17.470352</td>\n",
       "      <td>18.467840</td>\n",
       "      <td>35.0</td>\n",
       "      <td>281.125377</td>\n",
       "      <td>0.748738</td>\n",
       "      <td>280.082520</td>\n",
       "      <td>280.457520</td>\n",
       "      <td>280.832520</td>\n",
       "      <td>281.832520</td>\n",
       "      <td>281.832520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>27.661716</td>\n",
       "      <td>1.024540</td>\n",
       "      <td>25.974336</td>\n",
       "      <td>26.774592</td>\n",
       "      <td>27.709888</td>\n",
       "      <td>28.542384</td>\n",
       "      <td>29.760223</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.562864</td>\n",
       "      <td>...</td>\n",
       "      <td>16.915456</td>\n",
       "      <td>17.731585</td>\n",
       "      <td>35.0</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>306.271973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>31.344689</td>\n",
       "      <td>1.965179</td>\n",
       "      <td>28.798271</td>\n",
       "      <td>29.997295</td>\n",
       "      <td>30.671456</td>\n",
       "      <td>32.075392</td>\n",
       "      <td>37.516481</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.458638</td>\n",
       "      <td>...</td>\n",
       "      <td>19.495936</td>\n",
       "      <td>22.489088</td>\n",
       "      <td>35.0</td>\n",
       "      <td>334.874735</td>\n",
       "      <td>0.737501</td>\n",
       "      <td>333.960449</td>\n",
       "      <td>333.960449</td>\n",
       "      <td>334.960449</td>\n",
       "      <td>335.710449</td>\n",
       "      <td>335.710449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.782031</td>\n",
       "      <td>2.107488</td>\n",
       "      <td>32.995071</td>\n",
       "      <td>34.510256</td>\n",
       "      <td>35.054015</td>\n",
       "      <td>37.044016</td>\n",
       "      <td>41.610048</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.359798</td>\n",
       "      <td>...</td>\n",
       "      <td>24.132735</td>\n",
       "      <td>26.356735</td>\n",
       "      <td>35.0</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>383.338379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.936418</td>\n",
       "      <td>1.600873</td>\n",
       "      <td>4.734464</td>\n",
       "      <td>8.181216</td>\n",
       "      <td>9.590016</td>\n",
       "      <td>10.108624</td>\n",
       "      <td>10.567328</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.718899</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426512</td>\n",
       "      <td>4.614592</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>190.307129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7.787515</td>\n",
       "      <td>1.444092</td>\n",
       "      <td>4.973568</td>\n",
       "      <td>6.666848</td>\n",
       "      <td>8.325120</td>\n",
       "      <td>8.859728</td>\n",
       "      <td>9.406336</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.079050</td>\n",
       "      <td>...</td>\n",
       "      <td>4.124752</td>\n",
       "      <td>4.864096</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>190.058105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.199985</td>\n",
       "      <td>0.544631</td>\n",
       "      <td>5.111008</td>\n",
       "      <td>5.660896</td>\n",
       "      <td>6.205376</td>\n",
       "      <td>6.742352</td>\n",
       "      <td>7.021024</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.895120</td>\n",
       "      <td>...</td>\n",
       "      <td>3.536896</td>\n",
       "      <td>4.148224</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>190.685059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.897465</td>\n",
       "      <td>0.557908</td>\n",
       "      <td>5.520960</td>\n",
       "      <td>5.554608</td>\n",
       "      <td>5.665216</td>\n",
       "      <td>5.910816</td>\n",
       "      <td>7.329696</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.407906</td>\n",
       "      <td>...</td>\n",
       "      <td>3.501136</td>\n",
       "      <td>4.058112</td>\n",
       "      <td>35.0</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>204.617676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.589705</td>\n",
       "      <td>0.317653</td>\n",
       "      <td>6.035904</td>\n",
       "      <td>6.399824</td>\n",
       "      <td>6.538912</td>\n",
       "      <td>6.882416</td>\n",
       "      <td>7.142528</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.614747</td>\n",
       "      <td>...</td>\n",
       "      <td>4.104192</td>\n",
       "      <td>4.398080</td>\n",
       "      <td>35.0</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>219.119629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7.149684</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>6.500768</td>\n",
       "      <td>6.841856</td>\n",
       "      <td>6.995872</td>\n",
       "      <td>7.524272</td>\n",
       "      <td>8.236480</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.697283</td>\n",
       "      <td>...</td>\n",
       "      <td>4.584960</td>\n",
       "      <td>4.872192</td>\n",
       "      <td>35.0</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>230.495605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.511617</td>\n",
       "      <td>0.830785</td>\n",
       "      <td>7.677504</td>\n",
       "      <td>8.053712</td>\n",
       "      <td>8.311552</td>\n",
       "      <td>8.668080</td>\n",
       "      <td>12.584320</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.951425</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699696</td>\n",
       "      <td>6.207904</td>\n",
       "      <td>35.0</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>258.373535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 step_ms                                  \\\n",
       "                                   count       mean       std        min   \n",
       "variant               batch_size                                           \n",
       "Baseline TritonConv2d 32            35.0  33.858973  5.744641  22.376801   \n",
       "                      64            35.0  33.061495  8.217262  20.058176   \n",
       "                      96            35.0  31.223125  5.574035  23.408384   \n",
       "                      128           35.0  29.043334  4.832932  23.702687   \n",
       "                      160           35.0  27.661716  1.024540  25.974336   \n",
       "                      192           35.0  31.344689  1.965179  28.798271   \n",
       "                      256           35.0  35.782031  2.107488  32.995071   \n",
       "nn.Conv2d             32            35.0   8.936418  1.600873   4.734464   \n",
       "                      64            35.0   7.787515  1.444092   4.973568   \n",
       "                      96            35.0   6.199985  0.544631   5.111008   \n",
       "                      128           35.0   5.897465  0.557908   5.520960   \n",
       "                      160           35.0   6.589705  0.317653   6.035904   \n",
       "                      192           35.0   7.149684  0.435847   6.500768   \n",
       "                      256           35.0   8.511617  0.830785   7.677504   \n",
       "\n",
       "                                                                              \\\n",
       "                                        25%        50%        75%        max   \n",
       "variant               batch_size                                               \n",
       "Baseline TritonConv2d 32          28.662608  37.607103  38.315744  40.636736   \n",
       "                      64          22.539360  38.267839  38.718416  42.518528   \n",
       "                      96          26.591424  30.303201  35.195487  41.889696   \n",
       "                      128         26.200144  27.248800  31.422801  41.012735   \n",
       "                      160         26.774592  27.709888  28.542384  29.760223   \n",
       "                      192         29.997295  30.671456  32.075392  37.516481   \n",
       "                      256         34.510256  35.054015  37.044016  41.610048   \n",
       "nn.Conv2d             32           8.181216   9.590016  10.108624  10.567328   \n",
       "                      64           6.666848   8.325120   8.859728   9.406336   \n",
       "                      96           5.660896   6.205376   6.742352   7.021024   \n",
       "                      128          5.554608   5.665216   5.910816   7.329696   \n",
       "                      160          6.399824   6.538912   6.882416   7.142528   \n",
       "                      192          6.841856   6.995872   7.524272   8.236480   \n",
       "                      256          8.053712   8.311552   8.668080  12.584320   \n",
       "\n",
       "                                 fwd_ms             ...     bwd_ms             \\\n",
       "                                  count       mean  ...        75%        max   \n",
       "variant               batch_size                    ...                         \n",
       "Baseline TritonConv2d 32           35.0  19.836949  ...  16.020480  16.560127   \n",
       "                      64           35.0  17.765971  ...  17.565184  21.909248   \n",
       "                      96           35.0  16.232723  ...  17.261568  24.862720   \n",
       "                      128          35.0  13.662614  ...  17.470352  18.467840   \n",
       "                      160          35.0  11.562864  ...  16.915456  17.731585   \n",
       "                      192          35.0  12.458638  ...  19.495936  22.489088   \n",
       "                      256          35.0  12.359798  ...  24.132735  26.356735   \n",
       "nn.Conv2d             32           35.0   4.718899  ...   4.426512   4.614592   \n",
       "                      64           35.0   4.079050  ...   4.124752   4.864096   \n",
       "                      96           35.0   2.895120  ...   3.536896   4.148224   \n",
       "                      128          35.0   2.407906  ...   3.501136   4.058112   \n",
       "                      160          35.0   2.614747  ...   4.104192   4.398080   \n",
       "                      192          35.0   2.697283  ...   4.584960   4.872192   \n",
       "                      256          35.0   2.951425  ...   5.699696   6.207904   \n",
       "\n",
       "                                 max_mem_alloc_mb                        \\\n",
       "                                            count        mean       std   \n",
       "variant               batch_size                                          \n",
       "Baseline TritonConv2d 32                     35.0  207.492676  0.000000   \n",
       "                      64                     35.0  228.024902  0.000000   \n",
       "                      96                     35.0  252.019043  0.000000   \n",
       "                      128                    35.0  281.125377  0.748738   \n",
       "                      160                    35.0  306.271973  0.000000   \n",
       "                      192                    35.0  334.874735  0.737501   \n",
       "                      256                    35.0  383.338379  0.000000   \n",
       "nn.Conv2d             32                     35.0  190.307129  0.000000   \n",
       "                      64                     35.0  190.058105  0.000000   \n",
       "                      96                     35.0  190.685059  0.000000   \n",
       "                      128                    35.0  204.617676  0.000000   \n",
       "                      160                    35.0  219.119629  0.000000   \n",
       "                      192                    35.0  230.495605  0.000000   \n",
       "                      256                    35.0  258.373535  0.000000   \n",
       "\n",
       "                                                                      \\\n",
       "                                         min         25%         50%   \n",
       "variant               batch_size                                       \n",
       "Baseline TritonConv2d 32          207.492676  207.492676  207.492676   \n",
       "                      64          228.024902  228.024902  228.024902   \n",
       "                      96          252.019043  252.019043  252.019043   \n",
       "                      128         280.082520  280.457520  280.832520   \n",
       "                      160         306.271973  306.271973  306.271973   \n",
       "                      192         333.960449  333.960449  334.960449   \n",
       "                      256         383.338379  383.338379  383.338379   \n",
       "nn.Conv2d             32          190.307129  190.307129  190.307129   \n",
       "                      64          190.058105  190.058105  190.058105   \n",
       "                      96          190.685059  190.685059  190.685059   \n",
       "                      128         204.617676  204.617676  204.617676   \n",
       "                      160         219.119629  219.119629  219.119629   \n",
       "                      192         230.495605  230.495605  230.495605   \n",
       "                      256         258.373535  258.373535  258.373535   \n",
       "\n",
       "                                                          \n",
       "                                         75%         max  \n",
       "variant               batch_size                          \n",
       "Baseline TritonConv2d 32          207.492676  207.492676  \n",
       "                      64          228.024902  228.024902  \n",
       "                      96          252.019043  252.019043  \n",
       "                      128         281.832520  281.832520  \n",
       "                      160         306.271973  306.271973  \n",
       "                      192         335.710449  335.710449  \n",
       "                      256         383.338379  383.338379  \n",
       "nn.Conv2d             32          190.307129  190.307129  \n",
       "                      64          190.058105  190.058105  \n",
       "                      96          190.685059  190.685059  \n",
       "                      128         204.617676  204.617676  \n",
       "                      160         219.119629  219.119629  \n",
       "                      192         230.495605  230.495605  \n",
       "                      256         258.373535  258.373535  \n",
       "\n",
       "[14 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_df = pd.concat(batch_details, ignore_index=True)\n",
    "metrics = [\"step_ms\", \"fwd_ms\", \"bwd_ms\", \"max_mem_alloc_mb\"]\n",
    "detail_df.groupby([\"variant\", \"batch_size\"])[metrics].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd2b6d",
   "metadata": {},
   "source": [
    "`baseline_vs_torch_df` сравнивает nn.Conv2d и Baseline TritonConv2d: пары столбцов с абсолютными значениями (forward/backward/step время, throughput, память) и коэффициенты ускорения (`speedup_*`, `throughput_ratio`, `mem_*_ratio`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d81011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>torch_forward_ms</th>\n",
       "      <th>baseline_forward_ms</th>\n",
       "      <th>torch_backward_ms</th>\n",
       "      <th>baseline_backward_ms</th>\n",
       "      <th>torch_step_ms</th>\n",
       "      <th>baseline_step_ms</th>\n",
       "      <th>torch_samples_per_s</th>\n",
       "      <th>baseline_samples_per_s</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>torch_mem_alloc_mb</th>\n",
       "      <th>baseline_mem_alloc_mb</th>\n",
       "      <th>torch_mem_reserved_mb</th>\n",
       "      <th>baseline_mem_reserved_mb</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.718899</td>\n",
       "      <td>19.836949</td>\n",
       "      <td>4.217519</td>\n",
       "      <td>14.022024</td>\n",
       "      <td>8.936418</td>\n",
       "      <td>33.858973</td>\n",
       "      <td>3730.567146</td>\n",
       "      <td>976.347011</td>\n",
       "      <td>0.237884</td>\n",
       "      <td>0.300778</td>\n",
       "      <td>0.263931</td>\n",
       "      <td>0.261715</td>\n",
       "      <td>190.307129</td>\n",
       "      <td>207.492676</td>\n",
       "      <td>220.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.090304</td>\n",
       "      <td>1.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.079050</td>\n",
       "      <td>17.765971</td>\n",
       "      <td>3.708465</td>\n",
       "      <td>15.295524</td>\n",
       "      <td>7.787515</td>\n",
       "      <td>33.061495</td>\n",
       "      <td>8566.292460</td>\n",
       "      <td>2087.275114</td>\n",
       "      <td>0.229599</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>0.235546</td>\n",
       "      <td>0.243661</td>\n",
       "      <td>190.058105</td>\n",
       "      <td>228.024902</td>\n",
       "      <td>228.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.199764</td>\n",
       "      <td>1.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.895120</td>\n",
       "      <td>16.232723</td>\n",
       "      <td>3.304866</td>\n",
       "      <td>14.990402</td>\n",
       "      <td>6.199985</td>\n",
       "      <td>31.223125</td>\n",
       "      <td>15602.282334</td>\n",
       "      <td>3169.658079</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.220465</td>\n",
       "      <td>0.198570</td>\n",
       "      <td>0.203153</td>\n",
       "      <td>190.685059</td>\n",
       "      <td>252.019043</td>\n",
       "      <td>222.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1.321651</td>\n",
       "      <td>1.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.407906</td>\n",
       "      <td>13.662614</td>\n",
       "      <td>3.489559</td>\n",
       "      <td>15.380720</td>\n",
       "      <td>5.897465</td>\n",
       "      <td>29.043334</td>\n",
       "      <td>21868.949079</td>\n",
       "      <td>4512.833889</td>\n",
       "      <td>0.176240</td>\n",
       "      <td>0.226879</td>\n",
       "      <td>0.203057</td>\n",
       "      <td>0.206358</td>\n",
       "      <td>204.617676</td>\n",
       "      <td>281.832520</td>\n",
       "      <td>228.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1.377362</td>\n",
       "      <td>1.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2.614747</td>\n",
       "      <td>11.562864</td>\n",
       "      <td>3.974958</td>\n",
       "      <td>16.098852</td>\n",
       "      <td>6.589705</td>\n",
       "      <td>27.661716</td>\n",
       "      <td>24334.832347</td>\n",
       "      <td>5791.891497</td>\n",
       "      <td>0.226133</td>\n",
       "      <td>0.246909</td>\n",
       "      <td>0.238225</td>\n",
       "      <td>0.238008</td>\n",
       "      <td>219.119629</td>\n",
       "      <td>306.271973</td>\n",
       "      <td>252.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1.397739</td>\n",
       "      <td>1.452381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2.697283</td>\n",
       "      <td>12.458638</td>\n",
       "      <td>4.452401</td>\n",
       "      <td>18.886051</td>\n",
       "      <td>7.149684</td>\n",
       "      <td>31.344689</td>\n",
       "      <td>26948.687933</td>\n",
       "      <td>6147.323264</td>\n",
       "      <td>0.216499</td>\n",
       "      <td>0.235751</td>\n",
       "      <td>0.228099</td>\n",
       "      <td>0.228112</td>\n",
       "      <td>230.495605</td>\n",
       "      <td>335.710449</td>\n",
       "      <td>274.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>1.456472</td>\n",
       "      <td>1.467153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2.951425</td>\n",
       "      <td>12.359798</td>\n",
       "      <td>5.560192</td>\n",
       "      <td>23.422233</td>\n",
       "      <td>8.511617</td>\n",
       "      <td>35.782031</td>\n",
       "      <td>30291.919684</td>\n",
       "      <td>7177.305322</td>\n",
       "      <td>0.238792</td>\n",
       "      <td>0.237389</td>\n",
       "      <td>0.237874</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>258.373535</td>\n",
       "      <td>383.338379</td>\n",
       "      <td>306.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>1.483660</td>\n",
       "      <td>1.954248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            torch_forward_ms  baseline_forward_ms  torch_backward_ms  \\\n",
       "batch_size                                                             \n",
       "32                  4.718899            19.836949           4.217519   \n",
       "64                  4.079050            17.765971           3.708465   \n",
       "96                  2.895120            16.232723           3.304866   \n",
       "128                 2.407906            13.662614           3.489559   \n",
       "160                 2.614747            11.562864           3.974958   \n",
       "192                 2.697283            12.458638           4.452401   \n",
       "256                 2.951425            12.359798           5.560192   \n",
       "\n",
       "            baseline_backward_ms  torch_step_ms  baseline_step_ms  \\\n",
       "batch_size                                                          \n",
       "32                     14.022024       8.936418         33.858973   \n",
       "64                     15.295524       7.787515         33.061495   \n",
       "96                     14.990402       6.199985         31.223125   \n",
       "128                    15.380720       5.897465         29.043334   \n",
       "160                    16.098852       6.589705         27.661716   \n",
       "192                    18.886051       7.149684         31.344689   \n",
       "256                    23.422233       8.511617         35.782031   \n",
       "\n",
       "            torch_samples_per_s  baseline_samples_per_s  speedup_forward  \\\n",
       "batch_size                                                                 \n",
       "32                  3730.567146              976.347011         0.237884   \n",
       "64                  8566.292460             2087.275114         0.229599   \n",
       "96                 15602.282334             3169.658079         0.178351   \n",
       "128                21868.949079             4512.833889         0.176240   \n",
       "160                24334.832347             5791.891497         0.226133   \n",
       "192                26948.687933             6147.323264         0.216499   \n",
       "256                30291.919684             7177.305322         0.238792   \n",
       "\n",
       "            speedup_backward  speedup_step  throughput_ratio  \\\n",
       "batch_size                                                     \n",
       "32                  0.300778      0.263931          0.261715   \n",
       "64                  0.242454      0.235546          0.243661   \n",
       "96                  0.220465      0.198570          0.203153   \n",
       "128                 0.226879      0.203057          0.206358   \n",
       "160                 0.246909      0.238225          0.238008   \n",
       "192                 0.235751      0.228099          0.228112   \n",
       "256                 0.237389      0.237874          0.236938   \n",
       "\n",
       "            torch_mem_alloc_mb  baseline_mem_alloc_mb  torch_mem_reserved_mb  \\\n",
       "batch_size                                                                     \n",
       "32                  190.307129             207.492676                  220.0   \n",
       "64                  190.058105             228.024902                  228.0   \n",
       "96                  190.685059             252.019043                  222.0   \n",
       "128                 204.617676             281.832520                  228.0   \n",
       "160                 219.119629             306.271973                  252.0   \n",
       "192                 230.495605             335.710449                  274.0   \n",
       "256                 258.373535             383.338379                  306.0   \n",
       "\n",
       "            baseline_mem_reserved_mb  mem_alloc_ratio  mem_reserved_ratio  \n",
       "batch_size                                                                 \n",
       "32                             226.0         1.090304            1.027273  \n",
       "64                             256.0         1.199764            1.122807  \n",
       "96                             312.0         1.321651            1.405405  \n",
       "128                            340.0         1.377362            1.491228  \n",
       "160                            366.0         1.397739            1.452381  \n",
       "192                            402.0         1.456472            1.467153  \n",
       "256                            598.0         1.483660            1.954248  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_compare_rows = []\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    torch_row = summary_df.loc[(\"nn.Conv2d\", bs)]\n",
    "    baseline_row = summary_df.loc[(\"Baseline TritonConv2d\", bs)]\n",
    "    comparison = {\n",
    "        \"batch_size\": bs,\n",
    "        \"torch_forward_ms\": torch_row[\"avg_forward_ms\"],\n",
    "        \"baseline_forward_ms\": baseline_row[\"avg_forward_ms\"],\n",
    "        \"torch_backward_ms\": torch_row[\"avg_backward_ms\"],\n",
    "        \"baseline_backward_ms\": baseline_row[\"avg_backward_ms\"],\n",
    "        \"torch_step_ms\": torch_row[\"avg_step_ms\"],\n",
    "        \"baseline_step_ms\": baseline_row[\"avg_step_ms\"],\n",
    "        \"torch_samples_per_s\": torch_row[\"samples_per_s\"],\n",
    "        \"baseline_samples_per_s\": baseline_row[\"samples_per_s\"],\n",
    "        \"speedup_forward\": torch_row[\"avg_forward_ms\"] / baseline_row[\"avg_forward_ms\"],\n",
    "        \"speedup_backward\": torch_row[\"avg_backward_ms\"] / baseline_row[\"avg_backward_ms\"],\n",
    "        \"speedup_step\": torch_row[\"avg_step_ms\"] / baseline_row[\"avg_step_ms\"],\n",
    "        \"throughput_ratio\": baseline_row[\"samples_per_s\"] / torch_row[\"samples_per_s\"],\n",
    "        \"torch_mem_alloc_mb\": torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"baseline_mem_alloc_mb\": baseline_row[\"max_mem_alloc_mb\"],\n",
    "        \"torch_mem_reserved_mb\": torch_row[\"max_mem_reserved_mb\"],\n",
    "        \"baseline_mem_reserved_mb\": baseline_row[\"max_mem_reserved_mb\"],\n",
    "        \"mem_alloc_ratio\": baseline_row[\"max_mem_alloc_mb\"] / torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"mem_reserved_ratio\": baseline_row[\"max_mem_reserved_mb\"] / torch_row[\"max_mem_reserved_mb\"],\n",
    "    }\n",
    "    baseline_compare_rows.append(comparison)\n",
    "\n",
    "baseline_vs_torch_df = pd.DataFrame(baseline_compare_rows).set_index(\"batch_size\")\n",
    "baseline_vs_torch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91f8b1",
   "metadata": {},
   "source": [
    "Таблица `summary_df` показывает средние метрики по каждому batch size: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `samples_per_s`, а также пики памяти (`max_mem_alloc_mb`, `max_mem_reserved_mb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fee49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_cfg = config[\"sparsity_bench\"]\n",
    "sparsity_bs = sparsity_cfg[\"batch_size\"]\n",
    "if sparsity_bs not in train_loaders:\n",
    "    train_loaders[sparsity_bs] = make_loader(sparsity_bs)\n",
    "sparsity_loader = train_loaders[sparsity_bs]\n",
    "\n",
    "sparsity_summaries = []\n",
    "sparsity_details = []\n",
    "\n",
    "for mode in sparsity_cfg[\"modes\"]:\n",
    "    for ratio in sparsity_cfg[\"keep_ratios\"]:\n",
    "        _, baseline_model = build_model_pair(config)\n",
    "        apply_sparsity_to_model(\n",
    "            baseline_model,\n",
    "            mode,\n",
    "            keep_ratio=ratio,\n",
    "            block_size=sparsity_cfg.get(\"block_size\", 4),\n",
    "        )\n",
    "        label = f\"{mode.capitalize()} sparsity (keep={ratio:.2f}, bs={sparsity_bs})\"\n",
    "        bench_df, bench_summary = run_benchmark(baseline_model, label, sparsity_loader, config)\n",
    "        bench_summary.update({\n",
    "            \"variant\": f\"Sparsity::{mode}\",\n",
    "            \"mode\": mode,\n",
    "            \"keep_ratio\": ratio,\n",
    "            \"batch_size\": sparsity_bs,\n",
    "        })\n",
    "        sparsity_summaries.append(bench_summary)\n",
    "        sparsity_details.append(\n",
    "            bench_df.assign(variant=f\"Sparsity::{mode}\", mode=mode, keep_ratio=ratio, batch_size=sparsity_bs)\n",
    "        )\n",
    "\n",
    "sparsity_summary_df = pd.DataFrame(sparsity_summaries).sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d37f9",
   "metadata": {},
   "source": [
    "`sparsity_compare_df` добавляет к тем же сценариям относительные значения относительно эталонного nn.Conv2d (`speedup_*_vs_torch`, `throughput_ratio_vs_torch`, `mem_*_ratio_vs_torch`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7be95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_reference = summary_df.loc[(\"nn.Conv2d\", sparsity_bs)]\n",
    "\n",
    "sparsity_compare_df = sparsity_summary_df.copy()\n",
    "sparsity_compare_df[\"speedup_forward_vs_torch\"] = sparsity_reference[\"avg_forward_ms\"] / sparsity_compare_df[\"avg_forward_ms\"]\n",
    "sparsity_compare_df[\"speedup_backward_vs_torch\"] = sparsity_reference[\"avg_backward_ms\"] / sparsity_compare_df[\"avg_backward_ms\"]\n",
    "sparsity_compare_df[\"speedup_step_vs_torch\"] = sparsity_reference[\"avg_step_ms\"] / sparsity_compare_df[\"avg_step_ms\"]\n",
    "sparsity_compare_df[\"throughput_ratio_vs_torch\"] = sparsity_compare_df[\"samples_per_s\"] / sparsity_reference[\"samples_per_s\"]\n",
    "sparsity_compare_df[\"mem_alloc_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_alloc_mb\"] / sparsity_reference[\"max_mem_alloc_mb\"]\n",
    "sparsity_compare_df[\"mem_reserved_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_reserved_mb\"] / sparsity_reference[\"max_mem_reserved_mb\"]\n",
    "sparsity_compare_df = sparsity_compare_df.sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_compare_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c83ece",
   "metadata": {},
   "source": [
    "`ranking_df` — упорядоченный рейтинг сценариев спарсификации: показывает `mode`, `keep_ratio`, абсолютный throughput и его отношение к торчу, а также ускорения forward/backward/step и изменение памяти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba124c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = sparsity_compare_df[[\n",
    "    \"variant\",\n",
    "    \"mode\",\n",
    "    \"keep_ratio\",\n",
    "    \"samples_per_s\",\n",
    "    \"throughput_ratio_vs_torch\",\n",
    "    \"speedup_forward_vs_torch\",\n",
    "    \"speedup_backward_vs_torch\",\n",
    "    \"speedup_step_vs_torch\",\n",
    "    \"mem_alloc_ratio_vs_torch\",\n",
    "    \"mem_reserved_ratio_vs_torch\",\n",
    "]].copy()\n",
    "ranking_df = ranking_df.sort_values(\"throughput_ratio_vs_torch\", ascending=False).reset_index(drop=True)\n",
    "ranking_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f63e3a-c709-4b0b-99f3-d43879429496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
