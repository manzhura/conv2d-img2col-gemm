{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34dffa7c",
   "metadata": {},
   "source": [
    "# ResNet18: сравнение nn.Conv2d и Baseline TritonConv2d + sparsity\n",
    "\n",
    "Здесь строятся две модели ResNet18: референс на `nn.Conv2d` и baseline на `TritonConv2d` (img2col→GEMM→col2img). Бенчмарки включают: (1) тренировочную петлю с подсчётом времени forward/backward и памяти; (2) пер-слойные замеры свёрток; (3) эксперименты с разрежением (channel/block/input) в baseline-модели. Все замеры на CUDA с прогревом. Режимы sparsity влияют и на forward, и на backward (маски отдельных каналов/блоков/входных каналов).\n",
    "\n",
    "**Метрики, которые считаются и выводятся:**\n",
    "- В тренировочной петле (`run_benchmark`):\n",
    "  - `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms` — средние времена (мс) после warmup.\n",
    "  - `samples_per_s` — пропускная способность (batch_size / step_time).\n",
    "  - `max_mem_alloc_mb`, `max_mem_reserved_mb` — пиковое выделение и резервирование CUDA-памяти (MB).\n",
    "- В сравнении вариантов (`sparsity_compare_df`, `ranking_df`):\n",
    "  - `speedup_forward_vs_torch`, `speedup_backward_vs_torch`, `speedup_step_vs_torch` — отношение метрик к nn.Conv2d; >1 — быстрее Torch, <1 — медленнее.\n",
    "  - `throughput_ratio_vs_torch`, `mem_*_ratio_vs_torch` — отношение пропускной способности и памяти к Torch.\n",
    "- Пер-слойный бенч (`benchmark_conv_layers`):\n",
    "  - Для каждого слоя: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `throughput_sps`, `max_mem_alloc_mb`, `max_mem_reserved_mb`.\n",
    "  - Метаданные слоя: тип, параметры ядра/stride/padding, для TritonConv2d — `channel_keep_ratio`, `input_keep_ratio`, `block_size`, `grad_block_size` (когда применена sparsity).\n",
    "\n",
    "**Как читать результаты:**\n",
    "- Для тренировки: сравнивайте `avg_step_ms` и `samples_per_s` между вариантами; смотрите память, чтобы оценить влияние sparsity на аллокацию.\n",
    "- Для sparsity: строки с `mode` и `keep_ratio` показывают, сколько каналов осталось; скорость может расти, но учитывайте точность (forward/backward маски совпадают).\n",
    "- Для пер-слойных бенчей: `variant` (`nn.Conv2d` или `Baseline TritonConv2d`) и `batch_size` помогают понять, где Triton выигрывает/проигрывает в зависимости от размера входа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319e97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4154eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from conv_gemm.baseline_layers.triton_conv2d import TritonConv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da3ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_root\": \"/home/manzhura/ITMO/EDLM/conv2d-img2col-gemm/data\",\n",
      "  \"num_classes\": 10,\n",
      "  \"batch_sizes\": [\n",
      "    32,\n",
      "    64,\n",
      "    96,\n",
      "    128,\n",
      "    160,\n",
      "    192,\n",
      "    256\n",
      "  ],\n",
      "  \"num_workers\": 4,\n",
      "  \"train_subset\": 8192,\n",
      "  \"lr\": 0.001,\n",
      "  \"momentum\": 0.9,\n",
      "  \"weight_decay\": 0.0005,\n",
      "  \"warmup_steps\": 5,\n",
      "  \"model_warmup_steps\": 3,\n",
      "  \"benchmark_steps\": 40,\n",
      "  \"baseline_conv\": {\n",
      "    \"BLOCK_M\": 64,\n",
      "    \"BLOCK_N\": 64,\n",
      "    \"BLOCK_K\": 64,\n",
      "    \"NUM_WARPS\": 4,\n",
      "    \"NUM_STAGES\": 2\n",
      "  },\n",
      "  \"sparsity_bench\": {\n",
      "    \"modes\": [\n",
      "      \"channel\",\n",
      "      \"block\",\n",
      "      \"input\"\n",
      "    ],\n",
      "    \"keep_ratios\": [\n",
      "      0.75,\n",
      "      0.6,\n",
      "      0.5,\n",
      "      0.25\n",
      "    ],\n",
      "    \"block_size\": 4,\n",
      "    \"batch_size\": 128\n",
      "  },\n",
      "  \"conv_layer_bench\": {\n",
      "    \"warmup_steps\": 5,\n",
      "    \"bench_steps\": 20\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type != \"cuda\":\n",
    "    raise RuntimeError(\"CUDA GPU is required for this benchmark\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "data_root = Path(\"../data\").resolve()\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"data_root\": str(data_root),\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_sizes\": [32, 64, 96, 128, 160, 192, 256],\n",
    "    \"num_workers\": 4,\n",
    "    \"train_subset\": 8192,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"warmup_steps\": 5,\n",
    "    \"model_warmup_steps\": 3,\n",
    "    \"benchmark_steps\": 40,\n",
    "    \"baseline_conv\": {\n",
    "        \"BLOCK_M\": 64,\n",
    "        \"BLOCK_N\": 64,\n",
    "        \"BLOCK_K\": 64,\n",
    "        \"NUM_WARPS\": 4,\n",
    "        \"NUM_STAGES\": 2,\n",
    "    },\n",
    "    \"sparsity_bench\": {\n",
    "        \"modes\": [\"channel\", \"block\", \"input\"],\n",
    "        \"keep_ratios\": [0.75, 0.6, 0.5, 0.25],\n",
    "        \"block_size\": 4,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "    \"conv_layer_bench\": {\n",
    "        \"warmup_steps\": 5,\n",
    "        \"bench_steps\": 20,\n",
    "    },\n",
    "}\n",
    "print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e44fbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:12<00:00, 13.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{32: 256, 64: 128, 96: 85, 128: 64, 160: 51, 192: 42, 256: 32}\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(\n",
    "    root=config[\"data_root\"], train=True, download=True, transform=transform_train\n",
    ")\n",
    "if config[\"train_subset\"] is not None and config[\"train_subset\"] < len(full_train):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    subset_idx = torch.randperm(len(full_train), generator=g)[: config[\"train_subset\"]]\n",
    "    train_dataset = torch.utils.data.Subset(full_train, subset_idx)\n",
    "else:\n",
    "    train_dataset = full_train\n",
    "\n",
    "\n",
    "def make_loader(batch_size: int) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "train_loaders: Dict[int, DataLoader] = {}\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    train_loaders[bs] = make_loader(bs)\n",
    "\n",
    "print({bs: len(loader) for bs, loader in train_loaders.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbd874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triton_conv(src: nn.Conv2d, cfg: dict) -> TritonConv2d:\n",
    "    if src.groups != 1:\n",
    "        raise ValueError(\"Baseline TritonConv2d currently supports groups=1 only\")\n",
    "    layer = TritonConv2d(\n",
    "        in_channels=src.in_channels,\n",
    "        out_channels=src.out_channels,\n",
    "        kernel_size=src.kernel_size,\n",
    "        stride=src.stride,\n",
    "        padding=src.padding,\n",
    "        dilation=src.dilation,\n",
    "        bias=(src.bias is not None),\n",
    "        # **cfg,\n",
    "    ).to(src.weight.device)\n",
    "    with torch.no_grad():\n",
    "        layer.weight.copy_(src.weight.detach().to(layer.weight.dtype))\n",
    "        if layer.bias is not None and src.bias is not None:\n",
    "            layer.bias.copy_(src.bias.detach().to(layer.bias.dtype))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def replace_convs_with_baseline(module: nn.Module, cfg: dict):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, make_triton_conv(child, cfg))\n",
    "        else:\n",
    "            replace_convs_with_baseline(child, cfg)\n",
    "\n",
    "\n",
    "def build_model_pair(config: dict):\n",
    "    reference = torchvision.models.resnet18(num_classes=config[\"num_classes\"])\n",
    "    baseline = copy.deepcopy(reference)\n",
    "    replace_convs_with_baseline(baseline, config[\"baseline_conv\"])\n",
    "    return reference.half(), baseline.half()\n",
    "\n",
    "\n",
    "def apply_sparsity_to_model(model: nn.Module, mode: str, keep_ratio: float, block_size: int = 4):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, TritonConv2d):\n",
    "            layer.clear_sparsity()\n",
    "            if keep_ratio >= 1.0:\n",
    "                continue\n",
    "            if mode == \"channel\":\n",
    "                layer.set_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_channel_sparsity(keep_ratio)\n",
    "            elif mode == \"block\":\n",
    "                layer.set_block_sparsity(keep_ratio, block_size=block_size)\n",
    "                layer.set_backward_block_sparsity(keep_ratio, block_size=block_size)\n",
    "            elif mode == \"input\":\n",
    "                layer.set_input_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_input_channel_sparsity(keep_ratio)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sparsity mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968c84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model: nn.Module, label: str, loader: DataLoader, config: dict):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    warmup = config[\"warmup_steps\"]\n",
    "    total_steps = config[\"benchmark_steps\"]\n",
    "    model_warmup = config.get(\"model_warmup_steps\", 0)\n",
    "    records = []\n",
    "\n",
    "    if model_warmup > 0:\n",
    "        warmup_iter = iter(loader)\n",
    "        for _ in range(model_warmup):\n",
    "            try:\n",
    "                images, targets = next(warmup_iter)\n",
    "            except StopIteration:\n",
    "                warmup_iter = iter(loader)\n",
    "                images, targets = next(warmup_iter)\n",
    "\n",
    "            images = images.half().to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        # Extra GPU warmup to drop JIT/cudnn noise from timed iterations\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    data_iter = iter(loader)\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            images, targets = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(loader)\n",
    "            images, targets = next(data_iter)\n",
    "\n",
    "        images = images.half().to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        fwd_end = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        fwd_start.record()\n",
    "        outputs = model(images)\n",
    "        fwd_end.record()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        bwd_start.record()\n",
    "        loss.backward()\n",
    "        bwd_end.record()\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_ms = fwd_start.elapsed_time(fwd_end)\n",
    "        bwd_ms = bwd_start.elapsed_time(bwd_end)\n",
    "        step_ms = fwd_ms + bwd_ms\n",
    "        mem_alloc = torch.cuda.max_memory_allocated(device) / 1024 ** 2\n",
    "        mem_reserved = torch.cuda.max_memory_reserved(device) / 1024 ** 2\n",
    "\n",
    "        if step >= warmup:\n",
    "            records.append({\n",
    "                \"label\": label,\n",
    "                \"step\": step,\n",
    "                \"loss\": float(loss.item()),\n",
    "                \"fwd_ms\": fwd_ms,\n",
    "                \"bwd_ms\": bwd_ms,\n",
    "                \"step_ms\": step_ms,\n",
    "                \"throughput_sps\": images.size(0) / (step_ms / 1000.0),\n",
    "                \"max_mem_alloc_mb\": mem_alloc,\n",
    "                \"max_mem_reserved_mb\": mem_reserved,\n",
    "            })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No data recorded for benchmark\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    summary = {\n",
    "        \"label\": label,\n",
    "        \"avg_forward_ms\": df[\"fwd_ms\"].mean(),\n",
    "        \"avg_backward_ms\": df[\"bwd_ms\"].mean(),\n",
    "        \"avg_step_ms\": df[\"step_ms\"].mean(),\n",
    "        \"samples_per_s\": df[\"throughput_sps\"].mean(),\n",
    "        \"max_mem_alloc_mb\": df[\"max_mem_alloc_mb\"].max(),\n",
    "        \"max_mem_reserved_mb\": df[\"max_mem_reserved_mb\"].max(),\n",
    "    }\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e811c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conv_module(module: nn.Module) -> bool:\n",
    "    return isinstance(module, (nn.Conv2d, TritonConv2d))\n",
    "\n",
    "\n",
    "def collect_conv_input_shapes(model: nn.Module, sample: torch.Tensor) -> Dict[str, torch.Size]:\n",
    "    shapes: Dict[str, torch.Size] = {}\n",
    "    handles = []\n",
    "\n",
    "    def make_hook(layer_name: str):\n",
    "        def _hook(mod, inp):\n",
    "            shapes.setdefault(layer_name, inp[0].shape)\n",
    "            return None  # do not override inputs\n",
    "        return _hook\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if is_conv_module(module):\n",
    "            handles.append(module.register_forward_pre_hook(make_hook(name)))\n",
    "    with torch.no_grad():\n",
    "        model(sample)\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def conv_metadata(name: str, module: nn.Module) -> Dict[str, object]:\n",
    "    meta = {\n",
    "        \"layer\": name,\n",
    "        \"layer_type\": type(module).__name__,\n",
    "        \"in_channels\": getattr(module, \"in_channels\", None),\n",
    "        \"out_channels\": getattr(module, \"out_channels\", None),\n",
    "        \"kernel_size\": tuple(getattr(module, \"kernel_size\", [])) if hasattr(module, \"kernel_size\") else None,\n",
    "        \"stride\": tuple(getattr(module, \"stride\", [])) if hasattr(module, \"stride\") else None,\n",
    "        \"padding\": tuple(getattr(module, \"padding\", [])) if hasattr(module, \"padding\") else None,\n",
    "        \"dilation\": tuple(getattr(module, \"dilation\", [])) if hasattr(module, \"dilation\") else None,\n",
    "    }\n",
    "    if isinstance(module, TritonConv2d):\n",
    "        keep_out = float(module.channel_mask.float().mean().item()) if hasattr(module, \"channel_mask\") else 1.0\n",
    "        keep_in = float(module.input_channel_mask.float().mean().item()) if hasattr(module, \"input_channel_mask\") else 1.0\n",
    "        meta.update({\n",
    "            \"channel_keep_ratio\": keep_out,\n",
    "            \"input_keep_ratio\": keep_in,\n",
    "            \"block_size\": getattr(module, \"block_size\", None),\n",
    "            \"grad_block_size\": getattr(module, \"grad_block_size\", None),\n",
    "        })\n",
    "    return meta\n",
    "\n",
    "\n",
    "def benchmark_single_conv(module: nn.Module, input_shape: torch.Size, device: torch.device, warmup: int, steps: int) -> Dict[str, float]:\n",
    "    x = torch.randn(input_shape, device=device, dtype=torch.float16, requires_grad=True)\n",
    "    layer = copy.deepcopy(module).to(device)\n",
    "    layer.train()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    for _ in range(warmup):\n",
    "        layer.zero_grad(set_to_none=True)\n",
    "        out = layer(x)\n",
    "        loss = out.float().sum()\n",
    "        loss.backward()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    records: List[Dict[str, float]] = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        layer.zero_grad(set_to_none=True)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        fwd_end = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        fwd_start.record()\n",
    "        out = layer(x)\n",
    "        fwd_end.record()\n",
    "\n",
    "        loss = out.float().sum()\n",
    "\n",
    "        bwd_start.record()\n",
    "        loss.backward()\n",
    "        bwd_end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_ms = fwd_start.elapsed_time(fwd_end)\n",
    "        bwd_ms = bwd_start.elapsed_time(bwd_end)\n",
    "        step_ms = fwd_ms + bwd_ms\n",
    "        records.append({\n",
    "            \"avg_forward_ms\": fwd_ms,\n",
    "            \"avg_backward_ms\": bwd_ms,\n",
    "            \"avg_step_ms\": step_ms,\n",
    "            \"throughput_sps\": input_shape[0] / (step_ms / 1000.0),\n",
    "            \"max_mem_alloc_mb\": torch.cuda.max_memory_allocated(device) / 1024 ** 2,\n",
    "            \"max_mem_reserved_mb\": torch.cuda.max_memory_reserved(device) / 1024 ** 2,\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No data recorded for conv benchmark\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return {\n",
    "        \"avg_forward_ms\": df[\"avg_forward_ms\"].mean(),\n",
    "        \"avg_backward_ms\": df[\"avg_backward_ms\"].mean(),\n",
    "        \"avg_step_ms\": df[\"avg_step_ms\"].mean(),\n",
    "        \"throughput_sps\": df[\"throughput_sps\"].mean(),\n",
    "        \"max_mem_alloc_mb\": df[\"max_mem_alloc_mb\"].max(),\n",
    "        \"max_mem_reserved_mb\": df[\"max_mem_reserved_mb\"].max(),\n",
    "    }\n",
    "\n",
    "\n",
    "def benchmark_conv_layers(torch_model: nn.Module, baseline_model: nn.Module, batch_size: int, config: dict):\n",
    "    bench_cfg = config.get(\"conv_layer_bench\", {\"warmup_steps\": 3, \"bench_steps\": 10})\n",
    "    warmup = bench_cfg.get(\"warmup_steps\", 3)\n",
    "    steps = bench_cfg.get(\"bench_steps\", 10)\n",
    "\n",
    "    sample = torch.randn(batch_size, 3, 32, 32, device=device, dtype=torch.float16)\n",
    "    torch_model = torch_model.to(device).eval()\n",
    "    baseline_model = baseline_model.to(device).eval()\n",
    "\n",
    "    input_shapes = collect_conv_input_shapes(torch_model, sample)\n",
    "    torch_conv_map = dict(torch_model.named_modules())\n",
    "    baseline_conv_map = dict(baseline_model.named_modules())\n",
    "\n",
    "    rows: List[Dict[str, object]] = []\n",
    "    for name, inp_shape in input_shapes.items():\n",
    "        torch_layer = torch_conv_map.get(name)\n",
    "        baseline_layer = baseline_conv_map.get(name)\n",
    "        if not (is_conv_module(torch_layer) and is_conv_module(baseline_layer)):\n",
    "            continue\n",
    "\n",
    "        for variant, layer in [(\"nn.Conv2d\", torch_layer), (\"Baseline TritonConv2d\", baseline_layer)]:\n",
    "            summary = benchmark_single_conv(layer, inp_shape, device, warmup, steps)\n",
    "            meta = conv_metadata(name, layer)\n",
    "            meta.update({\n",
    "                \"variant\": variant,\n",
    "                \"batch_size\": batch_size,\n",
    "            })\n",
    "            meta.update(summary)\n",
    "            rows.append(meta)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037f8b1",
   "metadata": {},
   "source": [
    "### Тренировочный бенч (whole-model)\n",
    "\n",
    "Ниже — таблица с усреднёнными метриками для `nn.Conv2d` и Baseline `TritonConv2d` на полном ResNet18 при заданном `batch_size`:\n",
    "- Время: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`.\n",
    "- Скорость: `samples_per_s`.\n",
    "- Память: `max_mem_alloc_mb`, `max_mem_reserved_mb`.\n",
    "Используйте эти значения как базовый ориентир перед включением sparsity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f25b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch size 32 ===\n",
      "=== Batch size 64 ===\n",
      "=== Batch size 96 ===\n",
      "=== Batch size 128 ===\n",
      "=== Batch size 160 ===\n",
      "=== Batch size 192 ===\n",
      "=== Batch size 256 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>nn.Conv2d (bs=32)</td>\n",
       "      <td>3.129189</td>\n",
       "      <td>2.526213</td>\n",
       "      <td>5.655401</td>\n",
       "      <td>5713.794252</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>Baseline TritonConv2d (bs=32)</td>\n",
       "      <td>16.541553</td>\n",
       "      <td>11.801686</td>\n",
       "      <td>28.343239</td>\n",
       "      <td>1190.182559</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>nn.Conv2d (bs=64)</td>\n",
       "      <td>3.018501</td>\n",
       "      <td>2.577050</td>\n",
       "      <td>5.595550</td>\n",
       "      <td>11605.944033</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>Baseline TritonConv2d (bs=64)</td>\n",
       "      <td>19.343052</td>\n",
       "      <td>14.796444</td>\n",
       "      <td>34.139496</td>\n",
       "      <td>1961.792757</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>nn.Conv2d (bs=96)</td>\n",
       "      <td>2.984024</td>\n",
       "      <td>2.630002</td>\n",
       "      <td>5.614026</td>\n",
       "      <td>17245.318782</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>Baseline TritonConv2d (bs=96)</td>\n",
       "      <td>19.321949</td>\n",
       "      <td>14.905766</td>\n",
       "      <td>34.227716</td>\n",
       "      <td>2875.527380</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>nn.Conv2d (bs=128)</td>\n",
       "      <td>2.827016</td>\n",
       "      <td>2.964769</td>\n",
       "      <td>5.791785</td>\n",
       "      <td>22337.548931</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>Baseline TritonConv2d (bs=128)</td>\n",
       "      <td>19.316070</td>\n",
       "      <td>16.518956</td>\n",
       "      <td>35.835026</td>\n",
       "      <td>3619.624595</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>nn.Conv2d (bs=160)</td>\n",
       "      <td>3.682120</td>\n",
       "      <td>3.065725</td>\n",
       "      <td>6.747845</td>\n",
       "      <td>23804.115582</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>Baseline TritonConv2d (bs=160)</td>\n",
       "      <td>11.315238</td>\n",
       "      <td>14.260141</td>\n",
       "      <td>25.575379</td>\n",
       "      <td>6273.461936</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>nn.Conv2d (bs=192)</td>\n",
       "      <td>3.461543</td>\n",
       "      <td>3.442064</td>\n",
       "      <td>6.903607</td>\n",
       "      <td>28129.045602</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>Baseline TritonConv2d (bs=192)</td>\n",
       "      <td>15.010317</td>\n",
       "      <td>16.961555</td>\n",
       "      <td>31.971872</td>\n",
       "      <td>6554.576549</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>nn.Conv2d (bs=256)</td>\n",
       "      <td>3.392876</td>\n",
       "      <td>3.734885</td>\n",
       "      <td>7.127761</td>\n",
       "      <td>36395.475281</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>Baseline TritonConv2d (bs=256)</td>\n",
       "      <td>11.928773</td>\n",
       "      <td>21.347773</td>\n",
       "      <td>33.276546</td>\n",
       "      <td>7787.248553</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>488.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           label  \\\n",
       "variant               batch_size                                   \n",
       "nn.Conv2d             32                       nn.Conv2d (bs=32)   \n",
       "Baseline TritonConv2d 32           Baseline TritonConv2d (bs=32)   \n",
       "nn.Conv2d             64                       nn.Conv2d (bs=64)   \n",
       "Baseline TritonConv2d 64           Baseline TritonConv2d (bs=64)   \n",
       "nn.Conv2d             96                       nn.Conv2d (bs=96)   \n",
       "Baseline TritonConv2d 96           Baseline TritonConv2d (bs=96)   \n",
       "nn.Conv2d             128                     nn.Conv2d (bs=128)   \n",
       "Baseline TritonConv2d 128         Baseline TritonConv2d (bs=128)   \n",
       "nn.Conv2d             160                     nn.Conv2d (bs=160)   \n",
       "Baseline TritonConv2d 160         Baseline TritonConv2d (bs=160)   \n",
       "nn.Conv2d             192                     nn.Conv2d (bs=192)   \n",
       "Baseline TritonConv2d 192         Baseline TritonConv2d (bs=192)   \n",
       "nn.Conv2d             256                     nn.Conv2d (bs=256)   \n",
       "Baseline TritonConv2d 256         Baseline TritonConv2d (bs=256)   \n",
       "\n",
       "                                  avg_forward_ms  avg_backward_ms  \\\n",
       "variant               batch_size                                    \n",
       "nn.Conv2d             32                3.129189         2.526213   \n",
       "Baseline TritonConv2d 32               16.541553        11.801686   \n",
       "nn.Conv2d             64                3.018501         2.577050   \n",
       "Baseline TritonConv2d 64               19.343052        14.796444   \n",
       "nn.Conv2d             96                2.984024         2.630002   \n",
       "Baseline TritonConv2d 96               19.321949        14.905766   \n",
       "nn.Conv2d             128               2.827016         2.964769   \n",
       "Baseline TritonConv2d 128              19.316070        16.518956   \n",
       "nn.Conv2d             160               3.682120         3.065725   \n",
       "Baseline TritonConv2d 160              11.315238        14.260141   \n",
       "nn.Conv2d             192               3.461543         3.442064   \n",
       "Baseline TritonConv2d 192              15.010317        16.961555   \n",
       "nn.Conv2d             256               3.392876         3.734885   \n",
       "Baseline TritonConv2d 256              11.928773        21.347773   \n",
       "\n",
       "                                  avg_step_ms  samples_per_s  \\\n",
       "variant               batch_size                               \n",
       "nn.Conv2d             32             5.655401    5713.794252   \n",
       "Baseline TritonConv2d 32            28.343239    1190.182559   \n",
       "nn.Conv2d             64             5.595550   11605.944033   \n",
       "Baseline TritonConv2d 64            34.139496    1961.792757   \n",
       "nn.Conv2d             96             5.614026   17245.318782   \n",
       "Baseline TritonConv2d 96            34.227716    2875.527380   \n",
       "nn.Conv2d             128            5.791785   22337.548931   \n",
       "Baseline TritonConv2d 128           35.835026    3619.624595   \n",
       "nn.Conv2d             160            6.747845   23804.115582   \n",
       "Baseline TritonConv2d 160           25.575379    6273.461936   \n",
       "nn.Conv2d             192            6.903607   28129.045602   \n",
       "Baseline TritonConv2d 192           31.971872    6554.576549   \n",
       "nn.Conv2d             256            7.127761   36395.475281   \n",
       "Baseline TritonConv2d 256           33.276546    7787.248553   \n",
       "\n",
       "                                  max_mem_alloc_mb  max_mem_reserved_mb  \n",
       "variant               batch_size                                         \n",
       "nn.Conv2d             32                127.072266                138.0  \n",
       "Baseline TritonConv2d 32                154.655273                182.0  \n",
       "nn.Conv2d             64                127.260254                138.0  \n",
       "Baseline TritonConv2d 64                169.953613                204.0  \n",
       "nn.Conv2d             96                127.573730                144.0  \n",
       "Baseline TritonConv2d 96                195.142090                240.0  \n",
       "nn.Conv2d             128               132.817871                168.0  \n",
       "Baseline TritonConv2d 128               213.830078                312.0  \n",
       "nn.Conv2d             160               140.381836                162.0  \n",
       "Baseline TritonConv2d 160               235.769043                284.0  \n",
       "nn.Conv2d             192               148.069824                180.0  \n",
       "Baseline TritonConv2d 192               261.332031                330.0  \n",
       "nn.Conv2d             256               160.321289                184.0  \n",
       "Baseline TritonConv2d 256               298.083496                488.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_summaries = []\n",
    "batch_details = []\n",
    "conv_layer_rows = []\n",
    "\n",
    "for bs, loader in train_loaders.items():\n",
    "    print(f\"=== Batch size {bs} ===\")\n",
    "    torch_model, baseline_model = build_model_pair(config)\n",
    "\n",
    "    # per-layer bench (forward FP16, backward FP32)\n",
    "    conv_layer_rows.extend(benchmark_conv_layers(torch_model, baseline_model, bs, config))\n",
    "\n",
    "    torch_df, torch_summary = run_benchmark(torch_model, f\"nn.Conv2d (bs={bs})\", loader, config)\n",
    "    torch_summary.update({\"variant\": \"nn.Conv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(torch_summary)\n",
    "    batch_details.append(torch_df.assign(variant=\"nn.Conv2d\", batch_size=bs))\n",
    "\n",
    "    baseline_df, baseline_summary = run_benchmark(baseline_model, f\"Baseline TritonConv2d (bs={bs})\", loader, config)\n",
    "    baseline_summary.update({\"variant\": \"Baseline TritonConv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(baseline_summary)\n",
    "    batch_details.append(baseline_df.assign(variant=\"Baseline TritonConv2d\", batch_size=bs))\n",
    "\n",
    "summary_df = pd.DataFrame(batch_summaries).set_index([\"variant\", \"batch_size\"])\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b90a09",
   "metadata": {},
   "source": [
    "Вывод `detail_df.groupby(...).describe()` содержит count/mean/std/min/25%/50%/75%/max для метрик `step_ms`, `fwd_ms`, `bwd_ms`, `max_mem_alloc_mb` отдельно по каждому `(variant, batch_size)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e564a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">step_ms</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fwd_ms</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bwd_ms</th>\n",
       "      <th colspan=\"8\" halign=\"left\">max_mem_alloc_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>28.343239</td>\n",
       "      <td>6.449088</td>\n",
       "      <td>17.763648</td>\n",
       "      <td>21.686512</td>\n",
       "      <td>28.838496</td>\n",
       "      <td>34.879056</td>\n",
       "      <td>37.693440</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.541553</td>\n",
       "      <td>...</td>\n",
       "      <td>14.311424</td>\n",
       "      <td>15.296512</td>\n",
       "      <td>35.0</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>34.139496</td>\n",
       "      <td>6.795220</td>\n",
       "      <td>18.694144</td>\n",
       "      <td>30.803328</td>\n",
       "      <td>35.318081</td>\n",
       "      <td>36.399632</td>\n",
       "      <td>48.715775</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.343052</td>\n",
       "      <td>...</td>\n",
       "      <td>15.805440</td>\n",
       "      <td>16.402336</td>\n",
       "      <td>35.0</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>34.227716</td>\n",
       "      <td>5.084941</td>\n",
       "      <td>22.205953</td>\n",
       "      <td>31.768832</td>\n",
       "      <td>36.004065</td>\n",
       "      <td>36.549759</td>\n",
       "      <td>49.398912</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.321949</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500816</td>\n",
       "      <td>16.351233</td>\n",
       "      <td>35.0</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.835026</td>\n",
       "      <td>3.752803</td>\n",
       "      <td>24.877025</td>\n",
       "      <td>34.715152</td>\n",
       "      <td>37.468832</td>\n",
       "      <td>38.083183</td>\n",
       "      <td>39.139265</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.316070</td>\n",
       "      <td>...</td>\n",
       "      <td>17.124767</td>\n",
       "      <td>17.670143</td>\n",
       "      <td>35.0</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>25.575379</td>\n",
       "      <td>1.444005</td>\n",
       "      <td>24.161984</td>\n",
       "      <td>24.683088</td>\n",
       "      <td>25.313408</td>\n",
       "      <td>25.982368</td>\n",
       "      <td>31.222687</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.315238</td>\n",
       "      <td>...</td>\n",
       "      <td>14.216176</td>\n",
       "      <td>17.912832</td>\n",
       "      <td>35.0</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>31.971872</td>\n",
       "      <td>15.369424</td>\n",
       "      <td>26.870751</td>\n",
       "      <td>27.101264</td>\n",
       "      <td>27.370049</td>\n",
       "      <td>28.143104</td>\n",
       "      <td>108.837410</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.010317</td>\n",
       "      <td>...</td>\n",
       "      <td>17.031680</td>\n",
       "      <td>23.214081</td>\n",
       "      <td>35.0</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>261.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>33.276546</td>\n",
       "      <td>4.550427</td>\n",
       "      <td>30.807584</td>\n",
       "      <td>31.060784</td>\n",
       "      <td>31.539968</td>\n",
       "      <td>33.866511</td>\n",
       "      <td>56.799232</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.928773</td>\n",
       "      <td>...</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>26.157824</td>\n",
       "      <td>35.0</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>298.083496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.655401</td>\n",
       "      <td>0.598762</td>\n",
       "      <td>5.043584</td>\n",
       "      <td>5.161664</td>\n",
       "      <td>5.606784</td>\n",
       "      <td>6.115920</td>\n",
       "      <td>7.864320</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.129189</td>\n",
       "      <td>...</td>\n",
       "      <td>2.737728</td>\n",
       "      <td>4.162560</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.595550</td>\n",
       "      <td>0.704996</td>\n",
       "      <td>4.465440</td>\n",
       "      <td>5.076976</td>\n",
       "      <td>5.437760</td>\n",
       "      <td>5.908992</td>\n",
       "      <td>7.309792</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.018501</td>\n",
       "      <td>...</td>\n",
       "      <td>2.702272</td>\n",
       "      <td>3.891072</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.614026</td>\n",
       "      <td>0.529583</td>\n",
       "      <td>5.011840</td>\n",
       "      <td>5.115904</td>\n",
       "      <td>5.392352</td>\n",
       "      <td>6.089136</td>\n",
       "      <td>6.763648</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.984024</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896784</td>\n",
       "      <td>3.624960</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.791785</td>\n",
       "      <td>0.624845</td>\n",
       "      <td>4.773056</td>\n",
       "      <td>5.281920</td>\n",
       "      <td>5.731744</td>\n",
       "      <td>6.151600</td>\n",
       "      <td>7.126240</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.827016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.163648</td>\n",
       "      <td>4.120576</td>\n",
       "      <td>35.0</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.747845</td>\n",
       "      <td>0.424503</td>\n",
       "      <td>5.855424</td>\n",
       "      <td>6.535424</td>\n",
       "      <td>6.747936</td>\n",
       "      <td>6.990288</td>\n",
       "      <td>7.895680</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.682120</td>\n",
       "      <td>...</td>\n",
       "      <td>3.185280</td>\n",
       "      <td>3.690496</td>\n",
       "      <td>35.0</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.903607</td>\n",
       "      <td>0.758954</td>\n",
       "      <td>5.816192</td>\n",
       "      <td>6.212752</td>\n",
       "      <td>6.832288</td>\n",
       "      <td>7.596816</td>\n",
       "      <td>8.438080</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.461543</td>\n",
       "      <td>...</td>\n",
       "      <td>3.735552</td>\n",
       "      <td>4.905984</td>\n",
       "      <td>35.0</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7.127761</td>\n",
       "      <td>0.912408</td>\n",
       "      <td>6.128832</td>\n",
       "      <td>6.752560</td>\n",
       "      <td>6.808032</td>\n",
       "      <td>7.328640</td>\n",
       "      <td>10.129408</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.392876</td>\n",
       "      <td>...</td>\n",
       "      <td>3.761664</td>\n",
       "      <td>4.732928</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>160.321289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 step_ms                                   \\\n",
       "                                   count       mean        std        min   \n",
       "variant               batch_size                                            \n",
       "Baseline TritonConv2d 32            35.0  28.343239   6.449088  17.763648   \n",
       "                      64            35.0  34.139496   6.795220  18.694144   \n",
       "                      96            35.0  34.227716   5.084941  22.205953   \n",
       "                      128           35.0  35.835026   3.752803  24.877025   \n",
       "                      160           35.0  25.575379   1.444005  24.161984   \n",
       "                      192           35.0  31.971872  15.369424  26.870751   \n",
       "                      256           35.0  33.276546   4.550427  30.807584   \n",
       "nn.Conv2d             32            35.0   5.655401   0.598762   5.043584   \n",
       "                      64            35.0   5.595550   0.704996   4.465440   \n",
       "                      96            35.0   5.614026   0.529583   5.011840   \n",
       "                      128           35.0   5.791785   0.624845   4.773056   \n",
       "                      160           35.0   6.747845   0.424503   5.855424   \n",
       "                      192           35.0   6.903607   0.758954   5.816192   \n",
       "                      256           35.0   7.127761   0.912408   6.128832   \n",
       "\n",
       "                                                                               \\\n",
       "                                        25%        50%        75%         max   \n",
       "variant               batch_size                                                \n",
       "Baseline TritonConv2d 32          21.686512  28.838496  34.879056   37.693440   \n",
       "                      64          30.803328  35.318081  36.399632   48.715775   \n",
       "                      96          31.768832  36.004065  36.549759   49.398912   \n",
       "                      128         34.715152  37.468832  38.083183   39.139265   \n",
       "                      160         24.683088  25.313408  25.982368   31.222687   \n",
       "                      192         27.101264  27.370049  28.143104  108.837410   \n",
       "                      256         31.060784  31.539968  33.866511   56.799232   \n",
       "nn.Conv2d             32           5.161664   5.606784   6.115920    7.864320   \n",
       "                      64           5.076976   5.437760   5.908992    7.309792   \n",
       "                      96           5.115904   5.392352   6.089136    6.763648   \n",
       "                      128          5.281920   5.731744   6.151600    7.126240   \n",
       "                      160          6.535424   6.747936   6.990288    7.895680   \n",
       "                      192          6.212752   6.832288   7.596816    8.438080   \n",
       "                      256          6.752560   6.808032   7.328640   10.129408   \n",
       "\n",
       "                                 fwd_ms             ...     bwd_ms             \\\n",
       "                                  count       mean  ...        75%        max   \n",
       "variant               batch_size                    ...                         \n",
       "Baseline TritonConv2d 32           35.0  16.541553  ...  14.311424  15.296512   \n",
       "                      64           35.0  19.343052  ...  15.805440  16.402336   \n",
       "                      96           35.0  19.321949  ...  15.500816  16.351233   \n",
       "                      128          35.0  19.316070  ...  17.124767  17.670143   \n",
       "                      160          35.0  11.315238  ...  14.216176  17.912832   \n",
       "                      192          35.0  15.010317  ...  17.031680  23.214081   \n",
       "                      256          35.0  11.928773  ...  22.415872  26.157824   \n",
       "nn.Conv2d             32           35.0   3.129189  ...   2.737728   4.162560   \n",
       "                      64           35.0   3.018501  ...   2.702272   3.891072   \n",
       "                      96           35.0   2.984024  ...   2.896784   3.624960   \n",
       "                      128          35.0   2.827016  ...   3.163648   4.120576   \n",
       "                      160          35.0   3.682120  ...   3.185280   3.690496   \n",
       "                      192          35.0   3.461543  ...   3.735552   4.905984   \n",
       "                      256          35.0   3.392876  ...   3.761664   4.732928   \n",
       "\n",
       "                                 max_mem_alloc_mb                   \\\n",
       "                                            count        mean  std   \n",
       "variant               batch_size                                     \n",
       "Baseline TritonConv2d 32                     35.0  154.655273  0.0   \n",
       "                      64                     35.0  169.953613  0.0   \n",
       "                      96                     35.0  195.142090  0.0   \n",
       "                      128                    35.0  213.830078  0.0   \n",
       "                      160                    35.0  235.769043  0.0   \n",
       "                      192                    35.0  261.332031  0.0   \n",
       "                      256                    35.0  298.083496  0.0   \n",
       "nn.Conv2d             32                     35.0  127.072266  0.0   \n",
       "                      64                     35.0  127.260254  0.0   \n",
       "                      96                     35.0  127.573730  0.0   \n",
       "                      128                    35.0  132.817871  0.0   \n",
       "                      160                    35.0  140.381836  0.0   \n",
       "                      192                    35.0  148.069824  0.0   \n",
       "                      256                    35.0  160.321289  0.0   \n",
       "\n",
       "                                                                      \\\n",
       "                                         min         25%         50%   \n",
       "variant               batch_size                                       \n",
       "Baseline TritonConv2d 32          154.655273  154.655273  154.655273   \n",
       "                      64          169.953613  169.953613  169.953613   \n",
       "                      96          195.142090  195.142090  195.142090   \n",
       "                      128         213.830078  213.830078  213.830078   \n",
       "                      160         235.769043  235.769043  235.769043   \n",
       "                      192         261.332031  261.332031  261.332031   \n",
       "                      256         298.083496  298.083496  298.083496   \n",
       "nn.Conv2d             32          127.072266  127.072266  127.072266   \n",
       "                      64          127.260254  127.260254  127.260254   \n",
       "                      96          127.573730  127.573730  127.573730   \n",
       "                      128         132.817871  132.817871  132.817871   \n",
       "                      160         140.381836  140.381836  140.381836   \n",
       "                      192         148.069824  148.069824  148.069824   \n",
       "                      256         160.321289  160.321289  160.321289   \n",
       "\n",
       "                                                          \n",
       "                                         75%         max  \n",
       "variant               batch_size                          \n",
       "Baseline TritonConv2d 32          154.655273  154.655273  \n",
       "                      64          169.953613  169.953613  \n",
       "                      96          195.142090  195.142090  \n",
       "                      128         213.830078  213.830078  \n",
       "                      160         235.769043  235.769043  \n",
       "                      192         261.332031  261.332031  \n",
       "                      256         298.083496  298.083496  \n",
       "nn.Conv2d             32          127.072266  127.072266  \n",
       "                      64          127.260254  127.260254  \n",
       "                      96          127.573730  127.573730  \n",
       "                      128         132.817871  132.817871  \n",
       "                      160         140.381836  140.381836  \n",
       "                      192         148.069824  148.069824  \n",
       "                      256         160.321289  160.321289  \n",
       "\n",
       "[14 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_df = pd.concat(batch_details, ignore_index=True)\n",
    "metrics = [\"step_ms\", \"fwd_ms\", \"bwd_ms\", \"max_mem_alloc_mb\"]\n",
    "detail_df.groupby([\"variant\", \"batch_size\"])[metrics].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d04038a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 variant  batch_size                           label  \\\n",
       " 0              nn.Conv2d         128              nn.Conv2d (bs=128)   \n",
       " 1              nn.Conv2d          96               nn.Conv2d (bs=96)   \n",
       " 2              nn.Conv2d          64               nn.Conv2d (bs=64)   \n",
       " 3  Baseline TritonConv2d         160  Baseline TritonConv2d (bs=160)   \n",
       " 4  Baseline TritonConv2d         256  Baseline TritonConv2d (bs=256)   \n",
       " 5  Baseline TritonConv2d         192  Baseline TritonConv2d (bs=192)   \n",
       " \n",
       "    avg_forward_ms  avg_backward_ms  avg_step_ms  samples_per_s  \\\n",
       " 0        2.827016         2.964769     5.791785   22337.548931   \n",
       " 1        2.984024         2.630002     5.614026   17245.318782   \n",
       " 2        3.018501         2.577050     5.595550   11605.944033   \n",
       " 3       11.315238        14.260141    25.575379    6273.461936   \n",
       " 4       11.928773        21.347773    33.276546    7787.248553   \n",
       " 5       15.010317        16.961555    31.971872    6554.576549   \n",
       " \n",
       "    max_mem_alloc_mb  max_mem_reserved_mb  \n",
       " 0        132.817871                168.0  \n",
       " 1        127.573730                144.0  \n",
       " 2        127.260254                138.0  \n",
       " 3        235.769043                284.0  \n",
       " 4        298.083496                488.0  \n",
       " 5        261.332031                330.0  ,\n",
       "                  variant  batch_size                           label  \\\n",
       " 0              nn.Conv2d          32               nn.Conv2d (bs=32)   \n",
       " 1              nn.Conv2d          64               nn.Conv2d (bs=64)   \n",
       " 2              nn.Conv2d          96               nn.Conv2d (bs=96)   \n",
       " 3  Baseline TritonConv2d          32   Baseline TritonConv2d (bs=32)   \n",
       " 4  Baseline TritonConv2d         160  Baseline TritonConv2d (bs=160)   \n",
       " 5  Baseline TritonConv2d          64   Baseline TritonConv2d (bs=64)   \n",
       " \n",
       "    avg_forward_ms  avg_backward_ms  avg_step_ms  samples_per_s  \\\n",
       " 0        3.129189         2.526213     5.655401    5713.794252   \n",
       " 1        3.018501         2.577050     5.595550   11605.944033   \n",
       " 2        2.984024         2.630002     5.614026   17245.318782   \n",
       " 3       16.541553        11.801686    28.343239    1190.182559   \n",
       " 4       11.315238        14.260141    25.575379    6273.461936   \n",
       " 5       19.343052        14.796444    34.139496    1961.792757   \n",
       " \n",
       "    max_mem_alloc_mb  max_mem_reserved_mb  \n",
       " 0        127.072266                138.0  \n",
       " 1        127.260254                138.0  \n",
       " 2        127.573730                144.0  \n",
       " 3        154.655273                182.0  \n",
       " 4        235.769043                284.0  \n",
       " 5        169.953613                204.0  )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_bs_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_forward_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "backward_bs_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_backward_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "forward_bs_top, backward_bs_top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f51d43",
   "metadata": {},
   "source": [
    "Per-layer metrics: forward/backward time and memory for each batch size and variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79bbdf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>in_channels</th>\n",
       "      <th>out_channels</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>stride</th>\n",
       "      <th>padding</th>\n",
       "      <th>dilation</th>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>throughput_sps</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>channel_keep_ratio</th>\n",
       "      <th>input_keep_ratio</th>\n",
       "      <th>block_size</th>\n",
       "      <th>grad_block_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.083046</td>\n",
       "      <td>0.160826</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>132337.776140</td>\n",
       "      <td>57.015137</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.442019</td>\n",
       "      <td>0.776563</td>\n",
       "      <td>1.218582</td>\n",
       "      <td>26268.444360</td>\n",
       "      <td>74.058594</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.089254</td>\n",
       "      <td>0.152520</td>\n",
       "      <td>0.241774</td>\n",
       "      <td>136234.527725</td>\n",
       "      <td>55.202637</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.811946</td>\n",
       "      <td>0.679099</td>\n",
       "      <td>1.491045</td>\n",
       "      <td>23210.801667</td>\n",
       "      <td>70.132812</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.134598</td>\n",
       "      <td>0.311456</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>72197.255429</td>\n",
       "      <td>55.202637</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.916042</td>\n",
       "      <td>0.860070</td>\n",
       "      <td>1.776112</td>\n",
       "      <td>144183.714106</td>\n",
       "      <td>69.757812</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0.309704</td>\n",
       "      <td>0.450315</td>\n",
       "      <td>568691.095826</td>\n",
       "      <td>77.257324</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.973586</td>\n",
       "      <td>0.865216</td>\n",
       "      <td>1.838802</td>\n",
       "      <td>140062.220837</td>\n",
       "      <td>114.757812</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.130096</td>\n",
       "      <td>0.312629</td>\n",
       "      <td>0.442725</td>\n",
       "      <td>581715.011749</td>\n",
       "      <td>77.257324</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.937651</td>\n",
       "      <td>0.883835</td>\n",
       "      <td>1.821486</td>\n",
       "      <td>141198.567677</td>\n",
       "      <td>114.757812</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     layer    layer_type  in_channels  out_channels  \\\n",
       "0                    conv1        Conv2d            3            64   \n",
       "1                    conv1  TritonConv2d            3            64   \n",
       "2           layer1.0.conv1        Conv2d           64            64   \n",
       "3           layer1.0.conv1  TritonConv2d           64            64   \n",
       "4           layer1.0.conv2        Conv2d           64            64   \n",
       "..                     ...           ...          ...           ...   \n",
       "275  layer4.0.downsample.0  TritonConv2d          256           512   \n",
       "276         layer4.1.conv1        Conv2d          512           512   \n",
       "277         layer4.1.conv1  TritonConv2d          512           512   \n",
       "278         layer4.1.conv2        Conv2d          512           512   \n",
       "279         layer4.1.conv2  TritonConv2d          512           512   \n",
       "\n",
       "    kernel_size  stride padding dilation                variant  batch_size  \\\n",
       "0        (7, 7)  (2, 2)  (3, 3)   (1, 1)              nn.Conv2d          32   \n",
       "1        (7, 7)  (2, 2)  (3, 3)   (1, 1)  Baseline TritonConv2d          32   \n",
       "2        (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d          32   \n",
       "3        (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d          32   \n",
       "4        (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d          32   \n",
       "..          ...     ...     ...      ...                    ...         ...   \n",
       "275      (1, 1)  (2, 2)  (0, 0)   (1, 1)  Baseline TritonConv2d         256   \n",
       "276      (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d         256   \n",
       "277      (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d         256   \n",
       "278      (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d         256   \n",
       "279      (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d         256   \n",
       "\n",
       "     avg_forward_ms  avg_backward_ms  avg_step_ms  throughput_sps  \\\n",
       "0          0.083046         0.160826     0.243872   132337.776140   \n",
       "1          0.442019         0.776563     1.218582    26268.444360   \n",
       "2          0.089254         0.152520     0.241774   136234.527725   \n",
       "3          0.811946         0.679099     1.491045    23210.801667   \n",
       "4          0.134598         0.311456     0.446054    72197.255429   \n",
       "..              ...              ...          ...             ...   \n",
       "275        0.916042         0.860070     1.776112   144183.714106   \n",
       "276        0.140611         0.309704     0.450315   568691.095826   \n",
       "277        0.973586         0.865216     1.838802   140062.220837   \n",
       "278        0.130096         0.312629     0.442725   581715.011749   \n",
       "279        0.937651         0.883835     1.821486   141198.567677   \n",
       "\n",
       "     max_mem_alloc_mb  max_mem_reserved_mb  channel_keep_ratio  \\\n",
       "0           57.015137                 68.0                 NaN   \n",
       "1           74.058594                 90.0                 1.0   \n",
       "2           55.202637                 68.0                 NaN   \n",
       "3           70.132812                 90.0                 1.0   \n",
       "4           55.202637                 90.0                 NaN   \n",
       "..                ...                  ...                 ...   \n",
       "275         69.757812                 70.0                 1.0   \n",
       "276         77.257324                 90.0                 NaN   \n",
       "277        114.757812                130.0                 1.0   \n",
       "278         77.257324                130.0                 NaN   \n",
       "279        114.757812                130.0                 1.0   \n",
       "\n",
       "     input_keep_ratio  block_size  grad_block_size  \n",
       "0                 NaN         NaN              NaN  \n",
       "1                 1.0         NaN              NaN  \n",
       "2                 NaN         NaN              NaN  \n",
       "3                 1.0         NaN              NaN  \n",
       "4                 NaN         NaN              NaN  \n",
       "..                ...         ...              ...  \n",
       "275               1.0         NaN              NaN  \n",
       "276               NaN         NaN              NaN  \n",
       "277               1.0         NaN              NaN  \n",
       "278               NaN         NaN              NaN  \n",
       "279               1.0         NaN              NaN  \n",
       "\n",
       "[280 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_df = pd.DataFrame(conv_layer_rows)\n",
    "conv_layer_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef96d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>layer_type_torch</th>\n",
       "      <th>in_channels_torch</th>\n",
       "      <th>out_channels_torch</th>\n",
       "      <th>kernel_size_torch</th>\n",
       "      <th>stride_torch</th>\n",
       "      <th>padding_torch</th>\n",
       "      <th>dilation_torch</th>\n",
       "      <th>variant_torch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>block_size_baseline</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187880</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>0.200128</td>\n",
       "      <td>0.198495</td>\n",
       "      <td>1.298929</td>\n",
       "      <td>1.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109927</td>\n",
       "      <td>0.224592</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.170374</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151958</td>\n",
       "      <td>0.370563</td>\n",
       "      <td>0.258394</td>\n",
       "      <td>0.257067</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141861</td>\n",
       "      <td>0.400772</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>0.262489</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142536</td>\n",
       "      <td>0.384875</td>\n",
       "      <td>0.260990</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126829</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.225280</td>\n",
       "      <td>0.231554</td>\n",
       "      <td>1.278724</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156501</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.250072</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137157</td>\n",
       "      <td>0.354888</td>\n",
       "      <td>0.242592</td>\n",
       "      <td>0.242499</td>\n",
       "      <td>1.064886</td>\n",
       "      <td>1.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144426</td>\n",
       "      <td>0.357950</td>\n",
       "      <td>0.244896</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138747</td>\n",
       "      <td>0.353718</td>\n",
       "      <td>0.243057</td>\n",
       "      <td>0.242728</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     layer layer_type_torch  in_channels_torch  \\\n",
       "0                    conv1           Conv2d                  3   \n",
       "1           layer1.0.conv1           Conv2d                 64   \n",
       "2           layer1.0.conv2           Conv2d                 64   \n",
       "3           layer1.1.conv1           Conv2d                 64   \n",
       "4           layer1.1.conv2           Conv2d                 64   \n",
       "..                     ...              ...                ...   \n",
       "135         layer4.0.conv1           Conv2d                256   \n",
       "136         layer4.0.conv2           Conv2d                512   \n",
       "137  layer4.0.downsample.0           Conv2d                256   \n",
       "138         layer4.1.conv1           Conv2d                512   \n",
       "139         layer4.1.conv2           Conv2d                512   \n",
       "\n",
       "     out_channels_torch kernel_size_torch stride_torch padding_torch  \\\n",
       "0                    64            (7, 7)       (2, 2)        (3, 3)   \n",
       "1                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "2                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "3                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "4                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "..                  ...               ...          ...           ...   \n",
       "135                 512            (3, 3)       (2, 2)        (1, 1)   \n",
       "136                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "137                 512            (1, 1)       (2, 2)        (0, 0)   \n",
       "138                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "139                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "\n",
       "    dilation_torch variant_torch  batch_size  ...  \\\n",
       "0           (1, 1)     nn.Conv2d          32  ...   \n",
       "1           (1, 1)     nn.Conv2d          32  ...   \n",
       "2           (1, 1)     nn.Conv2d          32  ...   \n",
       "3           (1, 1)     nn.Conv2d          32  ...   \n",
       "4           (1, 1)     nn.Conv2d          32  ...   \n",
       "..             ...           ...         ...  ...   \n",
       "135         (1, 1)     nn.Conv2d         256  ...   \n",
       "136         (1, 1)     nn.Conv2d         256  ...   \n",
       "137         (1, 1)     nn.Conv2d         256  ...   \n",
       "138         (1, 1)     nn.Conv2d         256  ...   \n",
       "139         (1, 1)     nn.Conv2d         256  ...   \n",
       "\n",
       "     channel_keep_ratio_baseline  input_keep_ratio_baseline  \\\n",
       "0                            1.0                        1.0   \n",
       "1                            1.0                        1.0   \n",
       "2                            1.0                        1.0   \n",
       "3                            1.0                        1.0   \n",
       "4                            1.0                        1.0   \n",
       "..                           ...                        ...   \n",
       "135                          1.0                        1.0   \n",
       "136                          1.0                        1.0   \n",
       "137                          1.0                        1.0   \n",
       "138                          1.0                        1.0   \n",
       "139                          1.0                        1.0   \n",
       "\n",
       "     block_size_baseline  grad_block_size_baseline  speedup_forward  \\\n",
       "0                    NaN                       NaN         0.187880   \n",
       "1                    NaN                       NaN         0.109927   \n",
       "2                    NaN                       NaN         0.151958   \n",
       "3                    NaN                       NaN         0.141861   \n",
       "4                    NaN                       NaN         0.142536   \n",
       "..                   ...                       ...              ...   \n",
       "135                  NaN                       NaN         0.126829   \n",
       "136                  NaN                       NaN         0.156501   \n",
       "137                  NaN                       NaN         0.137157   \n",
       "138                  NaN                       NaN         0.144426   \n",
       "139                  NaN                       NaN         0.138747   \n",
       "\n",
       "     speedup_backward  speedup_step  throughput_ratio  mem_alloc_ratio  \\\n",
       "0            0.207099      0.200128          0.198495         1.298929   \n",
       "1            0.224592      0.162151          0.170374         1.270461   \n",
       "2            0.370563      0.258394          0.257067         1.270461   \n",
       "3            0.400772      0.263423          0.262489         1.270461   \n",
       "4            0.384875      0.260990          0.259953         1.270461   \n",
       "..                ...           ...               ...              ...   \n",
       "135          0.348895      0.225280          0.231554         1.278724   \n",
       "136          0.362069      0.250072          0.250627         1.485397   \n",
       "137          0.354888      0.242592          0.242499         1.064886   \n",
       "138          0.357950      0.244896          0.246289         1.485397   \n",
       "139          0.353718      0.243057          0.242728         1.485397   \n",
       "\n",
       "     mem_reserved_ratio  \n",
       "0              1.323529  \n",
       "1              1.323529  \n",
       "2              1.000000  \n",
       "3              1.000000  \n",
       "4              1.000000  \n",
       "..                  ...  \n",
       "135            1.255814  \n",
       "136            1.465116  \n",
       "137            1.060606  \n",
       "138            1.444444  \n",
       "139            1.000000  \n",
       "\n",
       "[140 rows x 44 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_conv_df = conv_layer_df[conv_layer_df[\"variant\"] == \"nn.Conv2d\"]\n",
    "baseline_conv_df = conv_layer_df[conv_layer_df[\"variant\"] == \"Baseline TritonConv2d\"]\n",
    "\n",
    "conv_layer_compare_df = torch_conv_df.merge(\n",
    "    baseline_conv_df,\n",
    "    on=[\"layer\", \"batch_size\"],\n",
    "    suffixes=(\"_torch\", \"_baseline\"),\n",
    ")\n",
    "\n",
    "conv_layer_compare_df[\"speedup_forward\"] = conv_layer_compare_df[\"avg_forward_ms_torch\"] / conv_layer_compare_df[\"avg_forward_ms_baseline\"]\n",
    "conv_layer_compare_df[\"speedup_backward\"] = conv_layer_compare_df[\"avg_backward_ms_torch\"] / conv_layer_compare_df[\"avg_backward_ms_baseline\"]\n",
    "conv_layer_compare_df[\"speedup_step\"] = conv_layer_compare_df[\"avg_step_ms_torch\"] / conv_layer_compare_df[\"avg_step_ms_baseline\"]\n",
    "conv_layer_compare_df[\"throughput_ratio\"] = conv_layer_compare_df[\"throughput_sps_baseline\"] / conv_layer_compare_df[\"throughput_sps_torch\"]\n",
    "conv_layer_compare_df[\"mem_alloc_ratio\"] = conv_layer_compare_df[\"max_mem_alloc_mb_baseline\"] / conv_layer_compare_df[\"max_mem_alloc_mb_torch\"]\n",
    "conv_layer_compare_df[\"mem_reserved_ratio\"] = conv_layer_compare_df[\"max_mem_reserved_mb_baseline\"] / conv_layer_compare_df[\"max_mem_reserved_mb_torch\"]\n",
    "conv_layer_compare_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ea76a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>kernel_size_torch</th>\n",
       "      <th>stride_torch</th>\n",
       "      <th>padding_torch</th>\n",
       "      <th>dilation_torch</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>block_size_baseline</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_backward_ms_torch</th>\n",
       "      <th>avg_backward_ms_baseline</th>\n",
       "      <th>avg_step_ms_torch</th>\n",
       "      <th>avg_step_ms_baseline</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193026</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.913070</td>\n",
       "      <td>0.303460</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.491844</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>1.233255</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>96</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245619</td>\n",
       "      <td>0.608869</td>\n",
       "      <td>0.381936</td>\n",
       "      <td>1.337021</td>\n",
       "      <td>0.305380</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>0.403403</td>\n",
       "      <td>0.285662</td>\n",
       "      <td>1.212119</td>\n",
       "      <td>1.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.449296</td>\n",
       "      <td>0.259686</td>\n",
       "      <td>0.915749</td>\n",
       "      <td>0.283652</td>\n",
       "      <td>0.168451</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.283578</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>128</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215501</td>\n",
       "      <td>0.511493</td>\n",
       "      <td>0.320051</td>\n",
       "      <td>1.173712</td>\n",
       "      <td>0.278067</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>0.421317</td>\n",
       "      <td>0.272683</td>\n",
       "      <td>1.398639</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>32</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283782</td>\n",
       "      <td>0.666102</td>\n",
       "      <td>0.397226</td>\n",
       "      <td>1.460392</td>\n",
       "      <td>0.298120</td>\n",
       "      <td>0.142823</td>\n",
       "      <td>0.426034</td>\n",
       "      <td>0.271999</td>\n",
       "      <td>1.034387</td>\n",
       "      <td>1.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>layer2.0.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301246</td>\n",
       "      <td>0.745971</td>\n",
       "      <td>0.433376</td>\n",
       "      <td>1.603240</td>\n",
       "      <td>0.286691</td>\n",
       "      <td>0.154129</td>\n",
       "      <td>0.403831</td>\n",
       "      <td>0.270313</td>\n",
       "      <td>1.095275</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "      <td>32</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290182</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>0.395958</td>\n",
       "      <td>1.466955</td>\n",
       "      <td>0.295756</td>\n",
       "      <td>0.131059</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.269919</td>\n",
       "      <td>1.029400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184387</td>\n",
       "      <td>0.442437</td>\n",
       "      <td>0.271282</td>\n",
       "      <td>1.011886</td>\n",
       "      <td>0.275864</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.416754</td>\n",
       "      <td>0.268095</td>\n",
       "      <td>1.236068</td>\n",
       "      <td>1.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>0.463666</td>\n",
       "      <td>0.293990</td>\n",
       "      <td>1.110941</td>\n",
       "      <td>0.272580</td>\n",
       "      <td>0.145704</td>\n",
       "      <td>0.430655</td>\n",
       "      <td>0.264632</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>0.507544</td>\n",
       "      <td>0.313651</td>\n",
       "      <td>1.187634</td>\n",
       "      <td>0.272012</td>\n",
       "      <td>0.153959</td>\n",
       "      <td>0.411680</td>\n",
       "      <td>0.264098</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309365</td>\n",
       "      <td>0.812904</td>\n",
       "      <td>0.449824</td>\n",
       "      <td>1.707166</td>\n",
       "      <td>0.263526</td>\n",
       "      <td>0.157067</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>1.176586</td>\n",
       "      <td>1.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322890</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.452026</td>\n",
       "      <td>1.715971</td>\n",
       "      <td>0.262489</td>\n",
       "      <td>0.141861</td>\n",
       "      <td>0.400772</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199883</td>\n",
       "      <td>0.487173</td>\n",
       "      <td>0.291517</td>\n",
       "      <td>1.106922</td>\n",
       "      <td>0.271576</td>\n",
       "      <td>0.147856</td>\n",
       "      <td>0.410292</td>\n",
       "      <td>0.263358</td>\n",
       "      <td>1.385012</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328859</td>\n",
       "      <td>0.856621</td>\n",
       "      <td>0.460939</td>\n",
       "      <td>1.758669</td>\n",
       "      <td>0.260953</td>\n",
       "      <td>0.146422</td>\n",
       "      <td>0.383903</td>\n",
       "      <td>0.262096</td>\n",
       "      <td>1.421627</td>\n",
       "      <td>1.425532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314736</td>\n",
       "      <td>0.809608</td>\n",
       "      <td>0.448738</td>\n",
       "      <td>1.714830</td>\n",
       "      <td>0.261636</td>\n",
       "      <td>0.148032</td>\n",
       "      <td>0.388751</td>\n",
       "      <td>0.261680</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.270270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    layer  batch_size kernel_size_torch stride_torch  \\\n",
       "0          layer4.0.conv1         128            (3, 3)       (2, 2)   \n",
       "1          layer4.0.conv1          96            (3, 3)       (2, 2)   \n",
       "2          layer3.1.conv2          64            (3, 3)       (1, 1)   \n",
       "3          layer4.0.conv2         128            (3, 3)       (1, 1)   \n",
       "4   layer4.0.downsample.0          32            (1, 1)       (2, 2)   \n",
       "5          layer2.0.conv1          32            (3, 3)       (2, 2)   \n",
       "6   layer2.0.downsample.0          32            (1, 1)       (2, 2)   \n",
       "7          layer4.0.conv1         160            (3, 3)       (2, 2)   \n",
       "8          layer4.0.conv2          64            (3, 3)       (1, 1)   \n",
       "9          layer4.0.conv2          96            (3, 3)       (1, 1)   \n",
       "10         layer3.1.conv1          32            (3, 3)       (1, 1)   \n",
       "11         layer1.1.conv1          32            (3, 3)       (1, 1)   \n",
       "12         layer3.0.conv2         160            (3, 3)       (1, 1)   \n",
       "13         layer4.1.conv1         160            (3, 3)       (1, 1)   \n",
       "14         layer3.1.conv1         128            (3, 3)       (1, 1)   \n",
       "\n",
       "   padding_torch dilation_torch  channel_keep_ratio_baseline  \\\n",
       "0         (1, 1)         (1, 1)                          1.0   \n",
       "1         (1, 1)         (1, 1)                          1.0   \n",
       "2         (1, 1)         (1, 1)                          1.0   \n",
       "3         (1, 1)         (1, 1)                          1.0   \n",
       "4         (0, 0)         (1, 1)                          1.0   \n",
       "5         (1, 1)         (1, 1)                          1.0   \n",
       "6         (0, 0)         (1, 1)                          1.0   \n",
       "7         (1, 1)         (1, 1)                          1.0   \n",
       "8         (1, 1)         (1, 1)                          1.0   \n",
       "9         (1, 1)         (1, 1)                          1.0   \n",
       "10        (1, 1)         (1, 1)                          1.0   \n",
       "11        (1, 1)         (1, 1)                          1.0   \n",
       "12        (1, 1)         (1, 1)                          1.0   \n",
       "13        (1, 1)         (1, 1)                          1.0   \n",
       "14        (1, 1)         (1, 1)                          1.0   \n",
       "\n",
       "    input_keep_ratio_baseline  block_size_baseline  grad_block_size_baseline  \\\n",
       "0                         1.0                  NaN                       NaN   \n",
       "1                         1.0                  NaN                       NaN   \n",
       "2                         1.0                  NaN                       NaN   \n",
       "3                         1.0                  NaN                       NaN   \n",
       "4                         1.0                  NaN                       NaN   \n",
       "5                         1.0                  NaN                       NaN   \n",
       "6                         1.0                  NaN                       NaN   \n",
       "7                         1.0                  NaN                       NaN   \n",
       "8                         1.0                  NaN                       NaN   \n",
       "9                         1.0                  NaN                       NaN   \n",
       "10                        1.0                  NaN                       NaN   \n",
       "11                        1.0                  NaN                       NaN   \n",
       "12                        1.0                  NaN                       NaN   \n",
       "13                        1.0                  NaN                       NaN   \n",
       "14                        1.0                  NaN                       NaN   \n",
       "\n",
       "    ...  avg_backward_ms_torch  avg_backward_ms_baseline  avg_step_ms_torch  \\\n",
       "0   ...               0.193026                  0.392453           0.278341   \n",
       "1   ...               0.245619                  0.608869           0.381936   \n",
       "2   ...               0.181112                  0.449296           0.259686   \n",
       "3   ...               0.215501                  0.511493           0.320051   \n",
       "4   ...               0.283782                  0.666102           0.397226   \n",
       "5   ...               0.301246                  0.745971           0.433376   \n",
       "6   ...               0.290182                  0.659870           0.395958   \n",
       "7   ...               0.184387                  0.442437           0.271282   \n",
       "8   ...               0.199680                  0.463666           0.293990   \n",
       "9   ...               0.208946                  0.507544           0.313651   \n",
       "10  ...               0.309365                  0.812904           0.449824   \n",
       "11  ...               0.322890                  0.805669           0.452026   \n",
       "12  ...               0.199883                  0.487173           0.291517   \n",
       "13  ...               0.328859                  0.856621           0.460939   \n",
       "14  ...               0.314736                  0.809608           0.448738   \n",
       "\n",
       "    avg_step_ms_baseline  throughput_ratio  speedup_forward  speedup_backward  \\\n",
       "0               0.913070          0.303460         0.163873          0.491844   \n",
       "1               1.337021          0.305380         0.187209          0.403403   \n",
       "2               0.915749          0.283652         0.168451          0.403102   \n",
       "3               1.173712          0.278067         0.157879          0.421317   \n",
       "4               1.460392          0.298120         0.142823          0.426034   \n",
       "5               1.603240          0.286691         0.154129          0.403831   \n",
       "6               1.466955          0.295756         0.131059          0.439757   \n",
       "7               1.011886          0.275864         0.152594          0.416754   \n",
       "8               1.110941          0.272580         0.145704          0.430655   \n",
       "9               1.187634          0.272012         0.153959          0.411680   \n",
       "10              1.707166          0.263526         0.157067          0.380567   \n",
       "11              1.715971          0.262489         0.141861          0.400772   \n",
       "12              1.106922          0.271576         0.147856          0.410292   \n",
       "13              1.758669          0.260953         0.146422          0.383903   \n",
       "14              1.714830          0.261636         0.148032          0.388751   \n",
       "\n",
       "    speedup_step  mem_alloc_ratio  mem_reserved_ratio  \n",
       "0       0.304840         1.233255            1.000000  \n",
       "1       0.285662         1.212119            1.046512  \n",
       "2       0.283578         1.204192            1.000000  \n",
       "3       0.272683         1.398639            1.444444  \n",
       "4       0.271999         1.034387            1.030303  \n",
       "5       0.270313         1.095275            1.029412  \n",
       "6       0.269919         1.029400            1.000000  \n",
       "7       0.268095         1.236068            1.022222  \n",
       "8       0.264632         1.364370            1.232558  \n",
       "9       0.264098         1.391945            1.255814  \n",
       "10      0.263492         1.176586            1.294118  \n",
       "11      0.263423         1.270461            1.000000  \n",
       "12      0.263358         1.385012            1.600000  \n",
       "13      0.262096         1.421627            1.425532  \n",
       "14      0.261680         1.318840            1.270270  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_ranking_df = conv_layer_compare_df[[\n",
    "    \"layer\",\n",
    "    \"batch_size\",\n",
    "    \"kernel_size_torch\",\n",
    "    \"stride_torch\",\n",
    "    \"padding_torch\",\n",
    "    \"dilation_torch\",\n",
    "    \"channel_keep_ratio_baseline\",\n",
    "    \"input_keep_ratio_baseline\",\n",
    "    \"block_size_baseline\",\n",
    "    \"grad_block_size_baseline\",\n",
    "    \"avg_forward_ms_torch\",\n",
    "    \"avg_forward_ms_baseline\",\n",
    "    \"avg_backward_ms_torch\",\n",
    "    \"avg_backward_ms_baseline\",\n",
    "    \"avg_step_ms_torch\",\n",
    "    \"avg_step_ms_baseline\",\n",
    "    \"throughput_ratio\",\n",
    "    \"speedup_forward\",\n",
    "    \"speedup_backward\",\n",
    "    \"speedup_step\",\n",
    "    \"mem_alloc_ratio\",\n",
    "    \"mem_reserved_ratio\",\n",
    "]].sort_values(\"speedup_step\", ascending=False).reset_index(drop=True)\n",
    "conv_layer_ranking_df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd2b6d",
   "metadata": {},
   "source": [
    "`baseline_vs_torch_df` сравнивает nn.Conv2d и Baseline TritonConv2d: пары столбцов с абсолютными значениями (forward/backward/step время, throughput, память) и коэффициенты ускорения (`speedup_*`, `throughput_ratio`, `mem_*_ratio`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d81011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>torch_forward_ms</th>\n",
       "      <th>baseline_forward_ms</th>\n",
       "      <th>torch_backward_ms</th>\n",
       "      <th>baseline_backward_ms</th>\n",
       "      <th>torch_step_ms</th>\n",
       "      <th>baseline_step_ms</th>\n",
       "      <th>torch_samples_per_s</th>\n",
       "      <th>baseline_samples_per_s</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>torch_mem_alloc_mb</th>\n",
       "      <th>baseline_mem_alloc_mb</th>\n",
       "      <th>torch_mem_reserved_mb</th>\n",
       "      <th>baseline_mem_reserved_mb</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.129189</td>\n",
       "      <td>16.541553</td>\n",
       "      <td>2.526213</td>\n",
       "      <td>11.801686</td>\n",
       "      <td>5.655401</td>\n",
       "      <td>28.343239</td>\n",
       "      <td>5713.794252</td>\n",
       "      <td>1190.182559</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.214055</td>\n",
       "      <td>0.199533</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>138.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.217066</td>\n",
       "      <td>1.318841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3.018501</td>\n",
       "      <td>19.343052</td>\n",
       "      <td>2.577050</td>\n",
       "      <td>14.796444</td>\n",
       "      <td>5.595550</td>\n",
       "      <td>34.139496</td>\n",
       "      <td>11605.944033</td>\n",
       "      <td>1961.792757</td>\n",
       "      <td>0.156051</td>\n",
       "      <td>0.174167</td>\n",
       "      <td>0.163903</td>\n",
       "      <td>0.169033</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>138.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.335481</td>\n",
       "      <td>1.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.984024</td>\n",
       "      <td>19.321949</td>\n",
       "      <td>2.630002</td>\n",
       "      <td>14.905766</td>\n",
       "      <td>5.614026</td>\n",
       "      <td>34.227716</td>\n",
       "      <td>17245.318782</td>\n",
       "      <td>2875.527380</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.176442</td>\n",
       "      <td>0.164020</td>\n",
       "      <td>0.166742</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>144.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.529642</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.827016</td>\n",
       "      <td>19.316070</td>\n",
       "      <td>2.964769</td>\n",
       "      <td>16.518956</td>\n",
       "      <td>5.791785</td>\n",
       "      <td>35.835026</td>\n",
       "      <td>22337.548931</td>\n",
       "      <td>3619.624595</td>\n",
       "      <td>0.146356</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>0.161624</td>\n",
       "      <td>0.162042</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>168.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1.609950</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3.682120</td>\n",
       "      <td>11.315238</td>\n",
       "      <td>3.065725</td>\n",
       "      <td>14.260141</td>\n",
       "      <td>6.747845</td>\n",
       "      <td>25.575379</td>\n",
       "      <td>23804.115582</td>\n",
       "      <td>6273.461936</td>\n",
       "      <td>0.325413</td>\n",
       "      <td>0.214986</td>\n",
       "      <td>0.263841</td>\n",
       "      <td>0.263545</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>162.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1.679484</td>\n",
       "      <td>1.753086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3.461543</td>\n",
       "      <td>15.010317</td>\n",
       "      <td>3.442064</td>\n",
       "      <td>16.961555</td>\n",
       "      <td>6.903607</td>\n",
       "      <td>31.971872</td>\n",
       "      <td>28129.045602</td>\n",
       "      <td>6554.576549</td>\n",
       "      <td>0.230611</td>\n",
       "      <td>0.202933</td>\n",
       "      <td>0.215928</td>\n",
       "      <td>0.233018</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>180.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.764924</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3.392876</td>\n",
       "      <td>11.928773</td>\n",
       "      <td>3.734885</td>\n",
       "      <td>21.347773</td>\n",
       "      <td>7.127761</td>\n",
       "      <td>33.276546</td>\n",
       "      <td>36395.475281</td>\n",
       "      <td>7787.248553</td>\n",
       "      <td>0.284428</td>\n",
       "      <td>0.174954</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>0.213962</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>184.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>1.859288</td>\n",
       "      <td>2.652174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            torch_forward_ms  baseline_forward_ms  torch_backward_ms  \\\n",
       "batch_size                                                             \n",
       "32                  3.129189            16.541553           2.526213   \n",
       "64                  3.018501            19.343052           2.577050   \n",
       "96                  2.984024            19.321949           2.630002   \n",
       "128                 2.827016            19.316070           2.964769   \n",
       "160                 3.682120            11.315238           3.065725   \n",
       "192                 3.461543            15.010317           3.442064   \n",
       "256                 3.392876            11.928773           3.734885   \n",
       "\n",
       "            baseline_backward_ms  torch_step_ms  baseline_step_ms  \\\n",
       "batch_size                                                          \n",
       "32                     11.801686       5.655401         28.343239   \n",
       "64                     14.796444       5.595550         34.139496   \n",
       "96                     14.905766       5.614026         34.227716   \n",
       "128                    16.518956       5.791785         35.835026   \n",
       "160                    14.260141       6.747845         25.575379   \n",
       "192                    16.961555       6.903607         31.971872   \n",
       "256                    21.347773       7.127761         33.276546   \n",
       "\n",
       "            torch_samples_per_s  baseline_samples_per_s  speedup_forward  \\\n",
       "batch_size                                                                 \n",
       "32                  5713.794252             1190.182559         0.189171   \n",
       "64                 11605.944033             1961.792757         0.156051   \n",
       "96                 17245.318782             2875.527380         0.154437   \n",
       "128                22337.548931             3619.624595         0.146356   \n",
       "160                23804.115582             6273.461936         0.325413   \n",
       "192                28129.045602             6554.576549         0.230611   \n",
       "256                36395.475281             7787.248553         0.284428   \n",
       "\n",
       "            speedup_backward  speedup_step  throughput_ratio  \\\n",
       "batch_size                                                     \n",
       "32                  0.214055      0.199533          0.208300   \n",
       "64                  0.174167      0.163903          0.169033   \n",
       "96                  0.176442      0.164020          0.166742   \n",
       "128                 0.179477      0.161624          0.162042   \n",
       "160                 0.214986      0.263841          0.263545   \n",
       "192                 0.202933      0.215928          0.233018   \n",
       "256                 0.174954      0.214198          0.213962   \n",
       "\n",
       "            torch_mem_alloc_mb  baseline_mem_alloc_mb  torch_mem_reserved_mb  \\\n",
       "batch_size                                                                     \n",
       "32                  127.072266             154.655273                  138.0   \n",
       "64                  127.260254             169.953613                  138.0   \n",
       "96                  127.573730             195.142090                  144.0   \n",
       "128                 132.817871             213.830078                  168.0   \n",
       "160                 140.381836             235.769043                  162.0   \n",
       "192                 148.069824             261.332031                  180.0   \n",
       "256                 160.321289             298.083496                  184.0   \n",
       "\n",
       "            baseline_mem_reserved_mb  mem_alloc_ratio  mem_reserved_ratio  \n",
       "batch_size                                                                 \n",
       "32                             182.0         1.217066            1.318841  \n",
       "64                             204.0         1.335481            1.478261  \n",
       "96                             240.0         1.529642            1.666667  \n",
       "128                            312.0         1.609950            1.857143  \n",
       "160                            284.0         1.679484            1.753086  \n",
       "192                            330.0         1.764924            1.833333  \n",
       "256                            488.0         1.859288            2.652174  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_compare_rows = []\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    torch_row = summary_df.loc[(\"nn.Conv2d\", bs)]\n",
    "    baseline_row = summary_df.loc[(\"Baseline TritonConv2d\", bs)]\n",
    "    comparison = {\n",
    "        \"batch_size\": bs,\n",
    "        \"torch_forward_ms\": torch_row[\"avg_forward_ms\"],\n",
    "        \"baseline_forward_ms\": baseline_row[\"avg_forward_ms\"],\n",
    "        \"torch_backward_ms\": torch_row[\"avg_backward_ms\"],\n",
    "        \"baseline_backward_ms\": baseline_row[\"avg_backward_ms\"],\n",
    "        \"torch_step_ms\": torch_row[\"avg_step_ms\"],\n",
    "        \"baseline_step_ms\": baseline_row[\"avg_step_ms\"],\n",
    "        \"torch_samples_per_s\": torch_row[\"samples_per_s\"],\n",
    "        \"baseline_samples_per_s\": baseline_row[\"samples_per_s\"],\n",
    "        \"speedup_forward\": torch_row[\"avg_forward_ms\"] / baseline_row[\"avg_forward_ms\"],\n",
    "        \"speedup_backward\": torch_row[\"avg_backward_ms\"] / baseline_row[\"avg_backward_ms\"],\n",
    "        \"speedup_step\": torch_row[\"avg_step_ms\"] / baseline_row[\"avg_step_ms\"],\n",
    "        \"throughput_ratio\": baseline_row[\"samples_per_s\"] / torch_row[\"samples_per_s\"],\n",
    "        \"torch_mem_alloc_mb\": torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"baseline_mem_alloc_mb\": baseline_row[\"max_mem_alloc_mb\"],\n",
    "        \"torch_mem_reserved_mb\": torch_row[\"max_mem_reserved_mb\"],\n",
    "        \"baseline_mem_reserved_mb\": baseline_row[\"max_mem_reserved_mb\"],\n",
    "        \"mem_alloc_ratio\": baseline_row[\"max_mem_alloc_mb\"] / torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"mem_reserved_ratio\": baseline_row[\"max_mem_reserved_mb\"] / torch_row[\"max_mem_reserved_mb\"],\n",
    "    }\n",
    "    baseline_compare_rows.append(comparison)\n",
    "\n",
    "baseline_vs_torch_df = pd.DataFrame(baseline_compare_rows).set_index(\"batch_size\")\n",
    "baseline_vs_torch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91f8b1",
   "metadata": {},
   "source": [
    "### Эксперимент со sparsity (channel/block/input)\n",
    "\n",
    "В этой секции к baseline-модели применяются маски:\n",
    "- `mode=\"channel\"` — обнуляем выходные каналы (Cout).\n",
    "- `mode=\"block\"` — обнуляем фильтры блоками по `block_size`.\n",
    "- `mode=\"input\"` — обнуляем входные каналы (Cin).\n",
    "`keep_ratio` задаёт долю оставленных каналов. Маски действуют и на forward, и на backward. Метрики:\n",
    "- Время/скорость: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `samples_per_s`.\n",
    "- Память: `max_mem_alloc_mb`, `max_mem_reserved_mb`.\n",
    "- Сравнение с Torch: `speedup_*_vs_torch`, `throughput_ratio_vs_torch`, `mem_*_ratio_vs_torch`.\n",
    "Сравнивайте сценарии: где `speedup_*_vs_torch > 1` при приемлемой памяти — наиболее выигрышные комбинации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9fee49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.020874</td>\n",
       "      <td>14.151008</td>\n",
       "      <td>28.171882</td>\n",
       "      <td>4548.125423</td>\n",
       "      <td>189.021484</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Channel sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>14.740871</td>\n",
       "      <td>14.232346</td>\n",
       "      <td>28.973216</td>\n",
       "      <td>4423.123514</td>\n",
       "      <td>210.301270</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Channel sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.634723</td>\n",
       "      <td>14.544662</td>\n",
       "      <td>29.179385</td>\n",
       "      <td>4389.509238</td>\n",
       "      <td>212.101562</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.732156</td>\n",
       "      <td>14.499875</td>\n",
       "      <td>29.232031</td>\n",
       "      <td>4384.171950</td>\n",
       "      <td>212.101562</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Block sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>14.709338</td>\n",
       "      <td>14.571549</td>\n",
       "      <td>29.280887</td>\n",
       "      <td>4373.672844</td>\n",
       "      <td>215.029297</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Block sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>14.493759</td>\n",
       "      <td>15.142440</td>\n",
       "      <td>29.636199</td>\n",
       "      <td>4326.114462</td>\n",
       "      <td>214.270996</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Channel sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>14.915532</td>\n",
       "      <td>15.244357</td>\n",
       "      <td>30.159888</td>\n",
       "      <td>4252.904420</td>\n",
       "      <td>213.857422</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Input sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>16.516674</td>\n",
       "      <td>14.454682</td>\n",
       "      <td>30.971356</td>\n",
       "      <td>4219.935188</td>\n",
       "      <td>172.362793</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Input sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>16.310909</td>\n",
       "      <td>14.570102</td>\n",
       "      <td>30.881011</td>\n",
       "      <td>4205.270766</td>\n",
       "      <td>191.394531</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Channel sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>15.800607</td>\n",
       "      <td>15.110925</td>\n",
       "      <td>30.911532</td>\n",
       "      <td>4184.812538</td>\n",
       "      <td>215.029297</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Block sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>22.666400</td>\n",
       "      <td>18.299541</td>\n",
       "      <td>40.965941</td>\n",
       "      <td>3220.994390</td>\n",
       "      <td>210.301270</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Input sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>23.035645</td>\n",
       "      <td>18.711691</td>\n",
       "      <td>41.747336</td>\n",
       "      <td>3107.733745</td>\n",
       "      <td>202.149414</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label  avg_forward_ms  avg_backward_ms  \\\n",
       "0     Input sparsity (keep=0.50, bs=128)       14.020874        14.151008   \n",
       "1   Channel sparsity (keep=0.25, bs=128)       14.740871        14.232346   \n",
       "2   Channel sparsity (keep=0.50, bs=128)       14.634723        14.544662   \n",
       "3     Block sparsity (keep=0.50, bs=128)       14.732156        14.499875   \n",
       "4     Block sparsity (keep=0.75, bs=128)       14.709338        14.571549   \n",
       "5     Block sparsity (keep=0.60, bs=128)       14.493759        15.142440   \n",
       "6   Channel sparsity (keep=0.60, bs=128)       14.915532        15.244357   \n",
       "7     Input sparsity (keep=0.25, bs=128)       16.516674        14.454682   \n",
       "8     Input sparsity (keep=0.60, bs=128)       16.310909        14.570102   \n",
       "9   Channel sparsity (keep=0.75, bs=128)       15.800607        15.110925   \n",
       "10    Block sparsity (keep=0.25, bs=128)       22.666400        18.299541   \n",
       "11    Input sparsity (keep=0.75, bs=128)       23.035645        18.711691   \n",
       "\n",
       "    avg_step_ms  samples_per_s  max_mem_alloc_mb  max_mem_reserved_mb  \\\n",
       "0     28.171882    4548.125423        189.021484                494.0   \n",
       "1     28.973216    4423.123514        210.301270                494.0   \n",
       "2     29.179385    4389.509238        212.101562                494.0   \n",
       "3     29.232031    4384.171950        212.101562                494.0   \n",
       "4     29.280887    4373.672844        215.029297                494.0   \n",
       "5     29.636199    4326.114462        214.270996                494.0   \n",
       "6     30.159888    4252.904420        213.857422                494.0   \n",
       "7     30.971356    4219.935188        172.362793                494.0   \n",
       "8     30.881011    4205.270766        191.394531                494.0   \n",
       "9     30.911532    4184.812538        215.029297                494.0   \n",
       "10    40.965941    3220.994390        210.301270                494.0   \n",
       "11    41.747336    3107.733745        202.149414                494.0   \n",
       "\n",
       "              variant     mode  keep_ratio  batch_size  \n",
       "0     Sparsity::input    input        0.50         128  \n",
       "1   Sparsity::channel  channel        0.25         128  \n",
       "2   Sparsity::channel  channel        0.50         128  \n",
       "3     Sparsity::block    block        0.50         128  \n",
       "4     Sparsity::block    block        0.75         128  \n",
       "5     Sparsity::block    block        0.60         128  \n",
       "6   Sparsity::channel  channel        0.60         128  \n",
       "7     Sparsity::input    input        0.25         128  \n",
       "8     Sparsity::input    input        0.60         128  \n",
       "9   Sparsity::channel  channel        0.75         128  \n",
       "10    Sparsity::block    block        0.25         128  \n",
       "11    Sparsity::input    input        0.75         128  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_cfg = config[\"sparsity_bench\"]\n",
    "sparsity_bs = sparsity_cfg[\"batch_size\"]\n",
    "if sparsity_bs not in train_loaders:\n",
    "    train_loaders[sparsity_bs] = make_loader(sparsity_bs)\n",
    "sparsity_loader = train_loaders[sparsity_bs]\n",
    "\n",
    "sparsity_summaries = []\n",
    "sparsity_details = []\n",
    "\n",
    "for mode in sparsity_cfg[\"modes\"]:\n",
    "    for ratio in sparsity_cfg[\"keep_ratios\"]:\n",
    "        _, baseline_model = build_model_pair(config)\n",
    "        apply_sparsity_to_model(\n",
    "            baseline_model,\n",
    "            mode,\n",
    "            keep_ratio=ratio,\n",
    "            block_size=sparsity_cfg.get(\"block_size\", 4),\n",
    "        )\n",
    "        label = f\"{mode.capitalize()} sparsity (keep={ratio:.2f}, bs={sparsity_bs})\"\n",
    "        bench_df, bench_summary = run_benchmark(baseline_model, label, sparsity_loader, config)\n",
    "        bench_summary.update({\n",
    "            \"variant\": f\"Sparsity::{mode}\",\n",
    "            \"mode\": mode,\n",
    "            \"keep_ratio\": ratio,\n",
    "            \"batch_size\": sparsity_bs,\n",
    "        })\n",
    "        sparsity_summaries.append(bench_summary)\n",
    "        sparsity_details.append(\n",
    "            bench_df.assign(variant=f\"Sparsity::{mode}\", mode=mode, keep_ratio=ratio, batch_size=sparsity_bs)\n",
    "        )\n",
    "\n",
    "sparsity_summary_df = pd.DataFrame(sparsity_summaries).sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d37f9",
   "metadata": {},
   "source": [
    "### Как интерпретировать таблицу сравнения sparsity\n",
    "\n",
    "`sparsity_compare_df` содержит все сценарии sparsity, отсортированные по `samples_per_s` (или speedup):\n",
    "- `speedup_forward_vs_torch`, `speedup_backward_vs_torch`, `speedup_step_vs_torch` показывают ускорение относительно nn.Conv2d.\n",
    "- `throughput_ratio_vs_torch` — прирост/просадка пропускной способности.\n",
    "- `mem_*_ratio_vs_torch` — отношение пиков памяти; <1 означает экономию памяти.\n",
    "Ищите строки с `speedup_step_vs_torch > 1` и приемлемыми `mem_*_ratio_vs_torch`, чтобы выбрать конфигурации для использования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e7be95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>speedup_forward_vs_torch</th>\n",
       "      <th>speedup_backward_vs_torch</th>\n",
       "      <th>speedup_step_vs_torch</th>\n",
       "      <th>throughput_ratio_vs_torch</th>\n",
       "      <th>mem_alloc_ratio_vs_torch</th>\n",
       "      <th>mem_reserved_ratio_vs_torch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.020874</td>\n",
       "      <td>14.151008</td>\n",
       "      <td>28.171882</td>\n",
       "      <td>4548.125423</td>\n",
       "      <td>189.021484</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.201629</td>\n",
       "      <td>0.209509</td>\n",
       "      <td>0.205587</td>\n",
       "      <td>0.203609</td>\n",
       "      <td>1.423163</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Channel sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>14.740871</td>\n",
       "      <td>14.232346</td>\n",
       "      <td>28.973216</td>\n",
       "      <td>4423.123514</td>\n",
       "      <td>210.301270</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.208312</td>\n",
       "      <td>0.199901</td>\n",
       "      <td>0.198013</td>\n",
       "      <td>1.583381</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Channel sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.634723</td>\n",
       "      <td>14.544662</td>\n",
       "      <td>29.179385</td>\n",
       "      <td>4389.509238</td>\n",
       "      <td>212.101562</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.193172</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.198489</td>\n",
       "      <td>0.196508</td>\n",
       "      <td>1.596935</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>14.732156</td>\n",
       "      <td>14.499875</td>\n",
       "      <td>29.232031</td>\n",
       "      <td>4384.171950</td>\n",
       "      <td>212.101562</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.191894</td>\n",
       "      <td>0.204469</td>\n",
       "      <td>0.198131</td>\n",
       "      <td>0.196269</td>\n",
       "      <td>1.596935</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Block sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>14.709338</td>\n",
       "      <td>14.571549</td>\n",
       "      <td>29.280887</td>\n",
       "      <td>4373.672844</td>\n",
       "      <td>215.029297</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.192192</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>0.197801</td>\n",
       "      <td>0.195799</td>\n",
       "      <td>1.618979</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Block sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>14.493759</td>\n",
       "      <td>15.142440</td>\n",
       "      <td>29.636199</td>\n",
       "      <td>4326.114462</td>\n",
       "      <td>214.270996</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.195792</td>\n",
       "      <td>0.195429</td>\n",
       "      <td>0.193670</td>\n",
       "      <td>1.613269</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Channel sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>14.915532</td>\n",
       "      <td>15.244357</td>\n",
       "      <td>30.159888</td>\n",
       "      <td>4252.904420</td>\n",
       "      <td>213.857422</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.189535</td>\n",
       "      <td>0.194483</td>\n",
       "      <td>0.192036</td>\n",
       "      <td>0.190393</td>\n",
       "      <td>1.610155</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Input sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>16.516674</td>\n",
       "      <td>14.454682</td>\n",
       "      <td>30.971356</td>\n",
       "      <td>4219.935188</td>\n",
       "      <td>172.362793</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.171161</td>\n",
       "      <td>0.205108</td>\n",
       "      <td>0.187005</td>\n",
       "      <td>0.188917</td>\n",
       "      <td>1.297738</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Input sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>16.310909</td>\n",
       "      <td>14.570102</td>\n",
       "      <td>30.881011</td>\n",
       "      <td>4205.270766</td>\n",
       "      <td>191.394531</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.173321</td>\n",
       "      <td>0.203483</td>\n",
       "      <td>0.187552</td>\n",
       "      <td>0.188260</td>\n",
       "      <td>1.441030</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Channel sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>15.800607</td>\n",
       "      <td>15.110925</td>\n",
       "      <td>30.911532</td>\n",
       "      <td>4184.812538</td>\n",
       "      <td>215.029297</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.178918</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.187366</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>1.618979</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Block sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>22.666400</td>\n",
       "      <td>18.299541</td>\n",
       "      <td>40.965941</td>\n",
       "      <td>3220.994390</td>\n",
       "      <td>210.301270</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.124723</td>\n",
       "      <td>0.162013</td>\n",
       "      <td>0.141380</td>\n",
       "      <td>0.144196</td>\n",
       "      <td>1.583381</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Input sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>23.035645</td>\n",
       "      <td>18.711691</td>\n",
       "      <td>41.747336</td>\n",
       "      <td>3107.733745</td>\n",
       "      <td>202.149414</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.122724</td>\n",
       "      <td>0.158445</td>\n",
       "      <td>0.138734</td>\n",
       "      <td>0.139126</td>\n",
       "      <td>1.522005</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label  avg_forward_ms  avg_backward_ms  \\\n",
       "0     Input sparsity (keep=0.50, bs=128)       14.020874        14.151008   \n",
       "1   Channel sparsity (keep=0.25, bs=128)       14.740871        14.232346   \n",
       "2   Channel sparsity (keep=0.50, bs=128)       14.634723        14.544662   \n",
       "3     Block sparsity (keep=0.50, bs=128)       14.732156        14.499875   \n",
       "4     Block sparsity (keep=0.75, bs=128)       14.709338        14.571549   \n",
       "5     Block sparsity (keep=0.60, bs=128)       14.493759        15.142440   \n",
       "6   Channel sparsity (keep=0.60, bs=128)       14.915532        15.244357   \n",
       "7     Input sparsity (keep=0.25, bs=128)       16.516674        14.454682   \n",
       "8     Input sparsity (keep=0.60, bs=128)       16.310909        14.570102   \n",
       "9   Channel sparsity (keep=0.75, bs=128)       15.800607        15.110925   \n",
       "10    Block sparsity (keep=0.25, bs=128)       22.666400        18.299541   \n",
       "11    Input sparsity (keep=0.75, bs=128)       23.035645        18.711691   \n",
       "\n",
       "    avg_step_ms  samples_per_s  max_mem_alloc_mb  max_mem_reserved_mb  \\\n",
       "0     28.171882    4548.125423        189.021484                494.0   \n",
       "1     28.973216    4423.123514        210.301270                494.0   \n",
       "2     29.179385    4389.509238        212.101562                494.0   \n",
       "3     29.232031    4384.171950        212.101562                494.0   \n",
       "4     29.280887    4373.672844        215.029297                494.0   \n",
       "5     29.636199    4326.114462        214.270996                494.0   \n",
       "6     30.159888    4252.904420        213.857422                494.0   \n",
       "7     30.971356    4219.935188        172.362793                494.0   \n",
       "8     30.881011    4205.270766        191.394531                494.0   \n",
       "9     30.911532    4184.812538        215.029297                494.0   \n",
       "10    40.965941    3220.994390        210.301270                494.0   \n",
       "11    41.747336    3107.733745        202.149414                494.0   \n",
       "\n",
       "              variant     mode  keep_ratio  batch_size  \\\n",
       "0     Sparsity::input    input        0.50         128   \n",
       "1   Sparsity::channel  channel        0.25         128   \n",
       "2   Sparsity::channel  channel        0.50         128   \n",
       "3     Sparsity::block    block        0.50         128   \n",
       "4     Sparsity::block    block        0.75         128   \n",
       "5     Sparsity::block    block        0.60         128   \n",
       "6   Sparsity::channel  channel        0.60         128   \n",
       "7     Sparsity::input    input        0.25         128   \n",
       "8     Sparsity::input    input        0.60         128   \n",
       "9   Sparsity::channel  channel        0.75         128   \n",
       "10    Sparsity::block    block        0.25         128   \n",
       "11    Sparsity::input    input        0.75         128   \n",
       "\n",
       "    speedup_forward_vs_torch  speedup_backward_vs_torch  \\\n",
       "0                   0.201629                   0.209509   \n",
       "1                   0.191781                   0.208312   \n",
       "2                   0.193172                   0.203839   \n",
       "3                   0.191894                   0.204469   \n",
       "4                   0.192192                   0.203463   \n",
       "5                   0.195051                   0.195792   \n",
       "6                   0.189535                   0.194483   \n",
       "7                   0.171161                   0.205108   \n",
       "8                   0.173321                   0.203483   \n",
       "9                   0.178918                   0.196200   \n",
       "10                  0.124723                   0.162013   \n",
       "11                  0.122724                   0.158445   \n",
       "\n",
       "    speedup_step_vs_torch  throughput_ratio_vs_torch  \\\n",
       "0                0.205587                   0.203609   \n",
       "1                0.199901                   0.198013   \n",
       "2                0.198489                   0.196508   \n",
       "3                0.198131                   0.196269   \n",
       "4                0.197801                   0.195799   \n",
       "5                0.195429                   0.193670   \n",
       "6                0.192036                   0.190393   \n",
       "7                0.187005                   0.188917   \n",
       "8                0.187552                   0.188260   \n",
       "9                0.187366                   0.187344   \n",
       "10               0.141380                   0.144196   \n",
       "11               0.138734                   0.139126   \n",
       "\n",
       "    mem_alloc_ratio_vs_torch  mem_reserved_ratio_vs_torch  \n",
       "0                   1.423163                     2.940476  \n",
       "1                   1.583381                     2.940476  \n",
       "2                   1.596935                     2.940476  \n",
       "3                   1.596935                     2.940476  \n",
       "4                   1.618979                     2.940476  \n",
       "5                   1.613269                     2.940476  \n",
       "6                   1.610155                     2.940476  \n",
       "7                   1.297738                     2.940476  \n",
       "8                   1.441030                     2.940476  \n",
       "9                   1.618979                     2.940476  \n",
       "10                  1.583381                     2.940476  \n",
       "11                  1.522005                     2.940476  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_reference = summary_df.loc[(\"nn.Conv2d\", sparsity_bs)]\n",
    "\n",
    "sparsity_compare_df = sparsity_summary_df.copy()\n",
    "sparsity_compare_df[\"speedup_forward_vs_torch\"] = sparsity_reference[\"avg_forward_ms\"] / sparsity_compare_df[\"avg_forward_ms\"]\n",
    "sparsity_compare_df[\"speedup_backward_vs_torch\"] = sparsity_reference[\"avg_backward_ms\"] / sparsity_compare_df[\"avg_backward_ms\"]\n",
    "sparsity_compare_df[\"speedup_step_vs_torch\"] = sparsity_reference[\"avg_step_ms\"] / sparsity_compare_df[\"avg_step_ms\"]\n",
    "sparsity_compare_df[\"throughput_ratio_vs_torch\"] = sparsity_compare_df[\"samples_per_s\"] / sparsity_reference[\"samples_per_s\"]\n",
    "sparsity_compare_df[\"mem_alloc_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_alloc_mb\"] / sparsity_reference[\"max_mem_alloc_mb\"]\n",
    "sparsity_compare_df[\"mem_reserved_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_reserved_mb\"] / sparsity_reference[\"max_mem_reserved_mb\"]\n",
    "sparsity_compare_df = sparsity_compare_df.sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_compare_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c83ece",
   "metadata": {},
   "source": [
    "### Ренкинг лучших сценариев\n",
    "\n",
    "В этой таблице собраны лучшие сценарии по различным критериям (быстрейший шаг, максимальный throughput, наименьшая память). Смотрите на:\n",
    "- `label` / `variant` — какой режим (sparsity или baseline) и какой batch.\n",
    "- `speedup_*_vs_torch` или абсолютные времена — что именно оптимизируем.\n",
    "- Память — если целитесь в ограничение по GPU, учитывайте `mem_*`.\n",
    "Используйте ренкинг как быструю шпаргалку для выбора режима на конкретном GPU/батче.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba124c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>throughput_ratio_vs_torch</th>\n",
       "      <th>speedup_forward_vs_torch</th>\n",
       "      <th>speedup_backward_vs_torch</th>\n",
       "      <th>speedup_step_vs_torch</th>\n",
       "      <th>mem_alloc_ratio_vs_torch</th>\n",
       "      <th>mem_reserved_ratio_vs_torch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4548.125423</td>\n",
       "      <td>0.203609</td>\n",
       "      <td>0.201629</td>\n",
       "      <td>0.209509</td>\n",
       "      <td>0.205587</td>\n",
       "      <td>1.423163</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4423.123514</td>\n",
       "      <td>0.198013</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.208312</td>\n",
       "      <td>0.199901</td>\n",
       "      <td>1.583381</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4389.509238</td>\n",
       "      <td>0.196508</td>\n",
       "      <td>0.193172</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.198489</td>\n",
       "      <td>1.596935</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4384.171950</td>\n",
       "      <td>0.196269</td>\n",
       "      <td>0.191894</td>\n",
       "      <td>0.204469</td>\n",
       "      <td>0.198131</td>\n",
       "      <td>1.596935</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4373.672844</td>\n",
       "      <td>0.195799</td>\n",
       "      <td>0.192192</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>0.197801</td>\n",
       "      <td>1.618979</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4326.114462</td>\n",
       "      <td>0.193670</td>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.195792</td>\n",
       "      <td>0.195429</td>\n",
       "      <td>1.613269</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4252.904420</td>\n",
       "      <td>0.190393</td>\n",
       "      <td>0.189535</td>\n",
       "      <td>0.194483</td>\n",
       "      <td>0.192036</td>\n",
       "      <td>1.610155</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4219.935188</td>\n",
       "      <td>0.188917</td>\n",
       "      <td>0.171161</td>\n",
       "      <td>0.205108</td>\n",
       "      <td>0.187005</td>\n",
       "      <td>1.297738</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4205.270766</td>\n",
       "      <td>0.188260</td>\n",
       "      <td>0.173321</td>\n",
       "      <td>0.203483</td>\n",
       "      <td>0.187552</td>\n",
       "      <td>1.441030</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4184.812538</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>0.178918</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.187366</td>\n",
       "      <td>1.618979</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3220.994390</td>\n",
       "      <td>0.144196</td>\n",
       "      <td>0.124723</td>\n",
       "      <td>0.162013</td>\n",
       "      <td>0.141380</td>\n",
       "      <td>1.583381</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3107.733745</td>\n",
       "      <td>0.139126</td>\n",
       "      <td>0.122724</td>\n",
       "      <td>0.158445</td>\n",
       "      <td>0.138734</td>\n",
       "      <td>1.522005</td>\n",
       "      <td>2.940476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variant     mode  keep_ratio  samples_per_s  \\\n",
       "0     Sparsity::input    input        0.50    4548.125423   \n",
       "1   Sparsity::channel  channel        0.25    4423.123514   \n",
       "2   Sparsity::channel  channel        0.50    4389.509238   \n",
       "3     Sparsity::block    block        0.50    4384.171950   \n",
       "4     Sparsity::block    block        0.75    4373.672844   \n",
       "5     Sparsity::block    block        0.60    4326.114462   \n",
       "6   Sparsity::channel  channel        0.60    4252.904420   \n",
       "7     Sparsity::input    input        0.25    4219.935188   \n",
       "8     Sparsity::input    input        0.60    4205.270766   \n",
       "9   Sparsity::channel  channel        0.75    4184.812538   \n",
       "10    Sparsity::block    block        0.25    3220.994390   \n",
       "11    Sparsity::input    input        0.75    3107.733745   \n",
       "\n",
       "    throughput_ratio_vs_torch  speedup_forward_vs_torch  \\\n",
       "0                    0.203609                  0.201629   \n",
       "1                    0.198013                  0.191781   \n",
       "2                    0.196508                  0.193172   \n",
       "3                    0.196269                  0.191894   \n",
       "4                    0.195799                  0.192192   \n",
       "5                    0.193670                  0.195051   \n",
       "6                    0.190393                  0.189535   \n",
       "7                    0.188917                  0.171161   \n",
       "8                    0.188260                  0.173321   \n",
       "9                    0.187344                  0.178918   \n",
       "10                   0.144196                  0.124723   \n",
       "11                   0.139126                  0.122724   \n",
       "\n",
       "    speedup_backward_vs_torch  speedup_step_vs_torch  \\\n",
       "0                    0.209509               0.205587   \n",
       "1                    0.208312               0.199901   \n",
       "2                    0.203839               0.198489   \n",
       "3                    0.204469               0.198131   \n",
       "4                    0.203463               0.197801   \n",
       "5                    0.195792               0.195429   \n",
       "6                    0.194483               0.192036   \n",
       "7                    0.205108               0.187005   \n",
       "8                    0.203483               0.187552   \n",
       "9                    0.196200               0.187366   \n",
       "10                   0.162013               0.141380   \n",
       "11                   0.158445               0.138734   \n",
       "\n",
       "    mem_alloc_ratio_vs_torch  mem_reserved_ratio_vs_torch  \n",
       "0                   1.423163                     2.940476  \n",
       "1                   1.583381                     2.940476  \n",
       "2                   1.596935                     2.940476  \n",
       "3                   1.596935                     2.940476  \n",
       "4                   1.618979                     2.940476  \n",
       "5                   1.613269                     2.940476  \n",
       "6                   1.610155                     2.940476  \n",
       "7                   1.297738                     2.940476  \n",
       "8                   1.441030                     2.940476  \n",
       "9                   1.618979                     2.940476  \n",
       "10                  1.583381                     2.940476  \n",
       "11                  1.522005                     2.940476  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_df = sparsity_compare_df[[\n",
    "    \"variant\",\n",
    "    \"mode\",\n",
    "    \"keep_ratio\",\n",
    "    \"samples_per_s\",\n",
    "    \"throughput_ratio_vs_torch\",\n",
    "    \"speedup_forward_vs_torch\",\n",
    "    \"speedup_backward_vs_torch\",\n",
    "    \"speedup_step_vs_torch\",\n",
    "    \"mem_alloc_ratio_vs_torch\",\n",
    "    \"mem_reserved_ratio_vs_torch\",\n",
    "]].copy()\n",
    "ranking_df = ranking_df.sort_values(\"throughput_ratio_vs_torch\", ascending=False).reset_index(drop=True)\n",
    "ranking_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915c106",
   "metadata": {},
   "source": [
    "Final rankings for model batch sizes and per-layer convs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bae397",
   "metadata": {},
   "source": [
    "Model batch-size rankings (step/throughput/memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30b30e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_step_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_step_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "model_throughput_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"samples_per_s\", ascending=False)\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "model_memory_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"max_mem_alloc_mb\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4782383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>3.018501</td>\n",
       "      <td>2.577050</td>\n",
       "      <td>5.595550</td>\n",
       "      <td>11605.944033</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>2.984024</td>\n",
       "      <td>2.630002</td>\n",
       "      <td>5.614026</td>\n",
       "      <td>17245.318782</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>3.129189</td>\n",
       "      <td>2.526213</td>\n",
       "      <td>5.655401</td>\n",
       "      <td>5713.794252</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>160</td>\n",
       "      <td>11.315238</td>\n",
       "      <td>14.260141</td>\n",
       "      <td>25.575379</td>\n",
       "      <td>6273.461936</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>16.541553</td>\n",
       "      <td>11.801686</td>\n",
       "      <td>28.343239</td>\n",
       "      <td>1190.182559</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>192</td>\n",
       "      <td>15.010317</td>\n",
       "      <td>16.961555</td>\n",
       "      <td>31.971872</td>\n",
       "      <td>6554.576549</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>3.392876</td>\n",
       "      <td>3.734885</td>\n",
       "      <td>7.127761</td>\n",
       "      <td>36395.475281</td>\n",
       "      <td>160.321289</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>192</td>\n",
       "      <td>3.461543</td>\n",
       "      <td>3.442064</td>\n",
       "      <td>6.903607</td>\n",
       "      <td>28129.045602</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>160</td>\n",
       "      <td>3.682120</td>\n",
       "      <td>3.065725</td>\n",
       "      <td>6.747845</td>\n",
       "      <td>23804.115582</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>11.928773</td>\n",
       "      <td>21.347773</td>\n",
       "      <td>33.276546</td>\n",
       "      <td>7787.248553</td>\n",
       "      <td>298.083496</td>\n",
       "      <td>488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>192</td>\n",
       "      <td>15.010317</td>\n",
       "      <td>16.961555</td>\n",
       "      <td>31.971872</td>\n",
       "      <td>6554.576549</td>\n",
       "      <td>261.332031</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>160</td>\n",
       "      <td>11.315238</td>\n",
       "      <td>14.260141</td>\n",
       "      <td>25.575379</td>\n",
       "      <td>6273.461936</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>3.129189</td>\n",
       "      <td>2.526213</td>\n",
       "      <td>5.655401</td>\n",
       "      <td>5713.794252</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>3.018501</td>\n",
       "      <td>2.577050</td>\n",
       "      <td>5.595550</td>\n",
       "      <td>11605.944033</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>2.984024</td>\n",
       "      <td>2.630002</td>\n",
       "      <td>5.614026</td>\n",
       "      <td>17245.318782</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>16.541553</td>\n",
       "      <td>11.801686</td>\n",
       "      <td>28.343239</td>\n",
       "      <td>1190.182559</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>19.343052</td>\n",
       "      <td>14.796444</td>\n",
       "      <td>34.139496</td>\n",
       "      <td>1961.792757</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>19.321949</td>\n",
       "      <td>14.905766</td>\n",
       "      <td>34.227716</td>\n",
       "      <td>2875.527380</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric                variant  batch_size  avg_forward_ms  \\\n",
       "0         fastest_step              nn.Conv2d          64        3.018501   \n",
       "1         fastest_step              nn.Conv2d          96        2.984024   \n",
       "2         fastest_step              nn.Conv2d          32        3.129189   \n",
       "3         fastest_step  Baseline TritonConv2d         160       11.315238   \n",
       "4         fastest_step  Baseline TritonConv2d          32       16.541553   \n",
       "5         fastest_step  Baseline TritonConv2d         192       15.010317   \n",
       "6   highest_throughput              nn.Conv2d         256        3.392876   \n",
       "7   highest_throughput              nn.Conv2d         192        3.461543   \n",
       "8   highest_throughput              nn.Conv2d         160        3.682120   \n",
       "9   highest_throughput  Baseline TritonConv2d         256       11.928773   \n",
       "10  highest_throughput  Baseline TritonConv2d         192       15.010317   \n",
       "11  highest_throughput  Baseline TritonConv2d         160       11.315238   \n",
       "12    lowest_mem_alloc              nn.Conv2d          32        3.129189   \n",
       "13    lowest_mem_alloc              nn.Conv2d          64        3.018501   \n",
       "14    lowest_mem_alloc              nn.Conv2d          96        2.984024   \n",
       "15    lowest_mem_alloc  Baseline TritonConv2d          32       16.541553   \n",
       "16    lowest_mem_alloc  Baseline TritonConv2d          64       19.343052   \n",
       "17    lowest_mem_alloc  Baseline TritonConv2d          96       19.321949   \n",
       "\n",
       "    avg_backward_ms  avg_step_ms  samples_per_s  max_mem_alloc_mb  \\\n",
       "0          2.577050     5.595550   11605.944033        127.260254   \n",
       "1          2.630002     5.614026   17245.318782        127.573730   \n",
       "2          2.526213     5.655401    5713.794252        127.072266   \n",
       "3         14.260141    25.575379    6273.461936        235.769043   \n",
       "4         11.801686    28.343239    1190.182559        154.655273   \n",
       "5         16.961555    31.971872    6554.576549        261.332031   \n",
       "6          3.734885     7.127761   36395.475281        160.321289   \n",
       "7          3.442064     6.903607   28129.045602        148.069824   \n",
       "8          3.065725     6.747845   23804.115582        140.381836   \n",
       "9         21.347773    33.276546    7787.248553        298.083496   \n",
       "10        16.961555    31.971872    6554.576549        261.332031   \n",
       "11        14.260141    25.575379    6273.461936        235.769043   \n",
       "12         2.526213     5.655401    5713.794252        127.072266   \n",
       "13         2.577050     5.595550   11605.944033        127.260254   \n",
       "14         2.630002     5.614026   17245.318782        127.573730   \n",
       "15        11.801686    28.343239    1190.182559        154.655273   \n",
       "16        14.796444    34.139496    1961.792757        169.953613   \n",
       "17        14.905766    34.227716    2875.527380        195.142090   \n",
       "\n",
       "    max_mem_reserved_mb  \n",
       "0                 138.0  \n",
       "1                 144.0  \n",
       "2                 138.0  \n",
       "3                 284.0  \n",
       "4                 182.0  \n",
       "5                 330.0  \n",
       "6                 184.0  \n",
       "7                 180.0  \n",
       "8                 162.0  \n",
       "9                 488.0  \n",
       "10                330.0  \n",
       "11                284.0  \n",
       "12                138.0  \n",
       "13                138.0  \n",
       "14                144.0  \n",
       "15                182.0  \n",
       "16                204.0  \n",
       "17                240.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rankings_df = pd.concat(\n",
    "    [\n",
    "        model_step_top.assign(metric=\"fastest_step\"),\n",
    "        model_throughput_top.assign(metric=\"highest_throughput\"),\n",
    "        model_memory_top.assign(metric=\"lowest_mem_alloc\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "model_rankings_df = model_rankings_df[[\n",
    "    \"metric\",\n",
    "    \"variant\",\n",
    "    \"batch_size\",\n",
    "    \"avg_forward_ms\",\n",
    "    \"avg_backward_ms\",\n",
    "    \"avg_step_ms\",\n",
    "    \"samples_per_s\",\n",
    "    \"max_mem_alloc_mb\",\n",
    "    \"max_mem_reserved_mb\",\n",
    "]]\n",
    "model_rankings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6a67c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>layer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer_type_baseline</th>\n",
       "      <th>kernel_size_baseline</th>\n",
       "      <th>stride_baseline</th>\n",
       "      <th>padding_baseline</th>\n",
       "      <th>dilation_baseline</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>avg_forward_ms_baseline</th>\n",
       "      <th>avg_backward_ms_baseline</th>\n",
       "      <th>avg_step_ms_baseline</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442019</td>\n",
       "      <td>0.776563</td>\n",
       "      <td>1.218582</td>\n",
       "      <td>0.187880</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>0.200128</td>\n",
       "      <td>0.198495</td>\n",
       "      <td>1.298929</td>\n",
       "      <td>1.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460432</td>\n",
       "      <td>0.989592</td>\n",
       "      <td>1.450024</td>\n",
       "      <td>0.175373</td>\n",
       "      <td>0.177064</td>\n",
       "      <td>0.176527</td>\n",
       "      <td>0.175538</td>\n",
       "      <td>1.869446</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer1.1.conv2</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460854</td>\n",
       "      <td>0.991088</td>\n",
       "      <td>1.451942</td>\n",
       "      <td>0.144063</td>\n",
       "      <td>0.172061</td>\n",
       "      <td>0.163175</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>1.869446</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466453</td>\n",
       "      <td>0.449296</td>\n",
       "      <td>0.915749</td>\n",
       "      <td>0.168451</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.283578</td>\n",
       "      <td>0.283652</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer2.0.conv2</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476136</td>\n",
       "      <td>0.615542</td>\n",
       "      <td>1.091678</td>\n",
       "      <td>0.145632</td>\n",
       "      <td>0.273928</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.218212</td>\n",
       "      <td>1.691050</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520618</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.913070</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.491844</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>0.303460</td>\n",
       "      <td>1.233255</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541578</td>\n",
       "      <td>1.024398</td>\n",
       "      <td>1.565976</td>\n",
       "      <td>0.184247</td>\n",
       "      <td>0.242309</td>\n",
       "      <td>0.222229</td>\n",
       "      <td>0.220613</td>\n",
       "      <td>1.869446</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562176</td>\n",
       "      <td>0.472083</td>\n",
       "      <td>1.034259</td>\n",
       "      <td>0.135138</td>\n",
       "      <td>0.346153</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>0.232097</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566720</td>\n",
       "      <td>1.013517</td>\n",
       "      <td>1.580237</td>\n",
       "      <td>0.148735</td>\n",
       "      <td>0.185033</td>\n",
       "      <td>0.172016</td>\n",
       "      <td>0.169039</td>\n",
       "      <td>1.869446</td>\n",
       "      <td>2.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568173</td>\n",
       "      <td>0.436040</td>\n",
       "      <td>1.004213</td>\n",
       "      <td>0.138006</td>\n",
       "      <td>0.379804</td>\n",
       "      <td>0.242997</td>\n",
       "      <td>0.242941</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520618</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.913070</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.491844</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>0.303460</td>\n",
       "      <td>1.233255</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572709</td>\n",
       "      <td>0.428942</td>\n",
       "      <td>1.001651</td>\n",
       "      <td>0.134412</td>\n",
       "      <td>0.385454</td>\n",
       "      <td>0.241917</td>\n",
       "      <td>0.248589</td>\n",
       "      <td>1.238774</td>\n",
       "      <td>1.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568173</td>\n",
       "      <td>0.436040</td>\n",
       "      <td>1.004213</td>\n",
       "      <td>0.138006</td>\n",
       "      <td>0.379804</td>\n",
       "      <td>0.242997</td>\n",
       "      <td>0.242941</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587275</td>\n",
       "      <td>0.436429</td>\n",
       "      <td>1.023704</td>\n",
       "      <td>0.150264</td>\n",
       "      <td>0.394449</td>\n",
       "      <td>0.254366</td>\n",
       "      <td>0.259951</td>\n",
       "      <td>1.128550</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569450</td>\n",
       "      <td>0.442437</td>\n",
       "      <td>1.011886</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.416754</td>\n",
       "      <td>0.268095</td>\n",
       "      <td>0.275864</td>\n",
       "      <td>1.236068</td>\n",
       "      <td>1.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610509</td>\n",
       "      <td>0.447638</td>\n",
       "      <td>1.058147</td>\n",
       "      <td>0.137449</td>\n",
       "      <td>0.390608</td>\n",
       "      <td>0.244545</td>\n",
       "      <td>0.248327</td>\n",
       "      <td>1.216643</td>\n",
       "      <td>1.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466453</td>\n",
       "      <td>0.449296</td>\n",
       "      <td>0.915749</td>\n",
       "      <td>0.168451</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.283578</td>\n",
       "      <td>0.283652</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647275</td>\n",
       "      <td>0.463666</td>\n",
       "      <td>1.110941</td>\n",
       "      <td>0.145704</td>\n",
       "      <td>0.430655</td>\n",
       "      <td>0.264632</td>\n",
       "      <td>0.272580</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637451</td>\n",
       "      <td>0.463958</td>\n",
       "      <td>1.101410</td>\n",
       "      <td>0.127387</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.225420</td>\n",
       "      <td>0.232378</td>\n",
       "      <td>1.191200</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623354</td>\n",
       "      <td>0.468859</td>\n",
       "      <td>1.092213</td>\n",
       "      <td>0.136362</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.228375</td>\n",
       "      <td>0.245418</td>\n",
       "      <td>1.216579</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520618</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.913070</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.491844</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>0.303460</td>\n",
       "      <td>1.233255</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728152</td>\n",
       "      <td>0.608869</td>\n",
       "      <td>1.337021</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>0.403403</td>\n",
       "      <td>0.285662</td>\n",
       "      <td>0.305380</td>\n",
       "      <td>1.212119</td>\n",
       "      <td>1.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466453</td>\n",
       "      <td>0.449296</td>\n",
       "      <td>0.915749</td>\n",
       "      <td>0.168451</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.283578</td>\n",
       "      <td>0.283652</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662219</td>\n",
       "      <td>0.511493</td>\n",
       "      <td>1.173712</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>0.421317</td>\n",
       "      <td>0.272683</td>\n",
       "      <td>0.278067</td>\n",
       "      <td>1.398639</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794290</td>\n",
       "      <td>0.666102</td>\n",
       "      <td>1.460392</td>\n",
       "      <td>0.142823</td>\n",
       "      <td>0.426034</td>\n",
       "      <td>0.271999</td>\n",
       "      <td>0.298120</td>\n",
       "      <td>1.034387</td>\n",
       "      <td>1.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer2.0.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857269</td>\n",
       "      <td>0.745971</td>\n",
       "      <td>1.603240</td>\n",
       "      <td>0.154129</td>\n",
       "      <td>0.403831</td>\n",
       "      <td>0.270313</td>\n",
       "      <td>0.286691</td>\n",
       "      <td>1.095275</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807085</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>1.466955</td>\n",
       "      <td>0.131059</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.269919</td>\n",
       "      <td>0.295756</td>\n",
       "      <td>1.029400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569450</td>\n",
       "      <td>0.442437</td>\n",
       "      <td>1.011886</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.416754</td>\n",
       "      <td>0.268095</td>\n",
       "      <td>0.275864</td>\n",
       "      <td>1.236068</td>\n",
       "      <td>1.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647275</td>\n",
       "      <td>0.463666</td>\n",
       "      <td>1.110941</td>\n",
       "      <td>0.145704</td>\n",
       "      <td>0.430655</td>\n",
       "      <td>0.264632</td>\n",
       "      <td>0.272580</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680090</td>\n",
       "      <td>0.507544</td>\n",
       "      <td>1.187634</td>\n",
       "      <td>0.153959</td>\n",
       "      <td>0.411680</td>\n",
       "      <td>0.264098</td>\n",
       "      <td>0.272012</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894262</td>\n",
       "      <td>0.812904</td>\n",
       "      <td>1.707166</td>\n",
       "      <td>0.157067</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.263526</td>\n",
       "      <td>1.176586</td>\n",
       "      <td>1.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910302</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>1.715971</td>\n",
       "      <td>0.141861</td>\n",
       "      <td>0.400772</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>0.262489</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619749</td>\n",
       "      <td>0.487173</td>\n",
       "      <td>1.106922</td>\n",
       "      <td>0.147856</td>\n",
       "      <td>0.410292</td>\n",
       "      <td>0.263358</td>\n",
       "      <td>0.271576</td>\n",
       "      <td>1.385012</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902048</td>\n",
       "      <td>0.856621</td>\n",
       "      <td>1.758669</td>\n",
       "      <td>0.146422</td>\n",
       "      <td>0.383903</td>\n",
       "      <td>0.262096</td>\n",
       "      <td>0.260953</td>\n",
       "      <td>1.421627</td>\n",
       "      <td>1.425532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.905222</td>\n",
       "      <td>0.809608</td>\n",
       "      <td>1.714830</td>\n",
       "      <td>0.148032</td>\n",
       "      <td>0.388751</td>\n",
       "      <td>0.261680</td>\n",
       "      <td>0.261636</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.270270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           metric                  layer  batch_size layer_type_baseline  \\\n",
       "0    forward_time                  conv1          32        TritonConv2d   \n",
       "1    forward_time         layer1.1.conv1         128        TritonConv2d   \n",
       "2    forward_time         layer1.1.conv2         128        TritonConv2d   \n",
       "3    forward_time         layer3.1.conv2          64        TritonConv2d   \n",
       "4    forward_time         layer2.0.conv2         192        TritonConv2d   \n",
       "5    forward_time         layer4.0.conv1         128        TritonConv2d   \n",
       "6    forward_time         layer1.0.conv2         128        TritonConv2d   \n",
       "7    forward_time         layer3.1.conv1          64        TritonConv2d   \n",
       "8    forward_time         layer1.0.conv1         128        TritonConv2d   \n",
       "9    forward_time         layer3.0.conv2          64        TritonConv2d   \n",
       "10  backward_time         layer4.0.conv1         128        TritonConv2d   \n",
       "11  backward_time         layer3.0.conv1         192        TritonConv2d   \n",
       "12  backward_time         layer3.0.conv2          64        TritonConv2d   \n",
       "13  backward_time         layer3.0.conv1          64        TritonConv2d   \n",
       "14  backward_time         layer4.0.conv1         160        TritonConv2d   \n",
       "15  backward_time         layer3.0.conv1         160        TritonConv2d   \n",
       "16  backward_time         layer3.1.conv2          64        TritonConv2d   \n",
       "17  backward_time         layer4.0.conv2          64        TritonConv2d   \n",
       "18  backward_time         layer3.0.conv1         128        TritonConv2d   \n",
       "19  backward_time         layer4.0.conv1          32        TritonConv2d   \n",
       "20   speedup_step         layer4.0.conv1         128        TritonConv2d   \n",
       "21   speedup_step         layer4.0.conv1          96        TritonConv2d   \n",
       "22   speedup_step         layer3.1.conv2          64        TritonConv2d   \n",
       "23   speedup_step         layer4.0.conv2         128        TritonConv2d   \n",
       "24   speedup_step  layer4.0.downsample.0          32        TritonConv2d   \n",
       "25   speedup_step         layer2.0.conv1          32        TritonConv2d   \n",
       "26   speedup_step  layer2.0.downsample.0          32        TritonConv2d   \n",
       "27   speedup_step         layer4.0.conv1         160        TritonConv2d   \n",
       "28   speedup_step         layer4.0.conv2          64        TritonConv2d   \n",
       "29   speedup_step         layer4.0.conv2          96        TritonConv2d   \n",
       "30   speedup_step         layer3.1.conv1          32        TritonConv2d   \n",
       "31   speedup_step         layer1.1.conv1          32        TritonConv2d   \n",
       "32   speedup_step         layer3.0.conv2         160        TritonConv2d   \n",
       "33   speedup_step         layer4.1.conv1         160        TritonConv2d   \n",
       "34   speedup_step         layer3.1.conv1         128        TritonConv2d   \n",
       "\n",
       "   kernel_size_baseline stride_baseline padding_baseline dilation_baseline  \\\n",
       "0                (7, 7)          (2, 2)           (3, 3)            (1, 1)   \n",
       "1                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "2                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "3                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "4                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "5                (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "6                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "7                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "8                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "9                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "10               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "11               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "12               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "13               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "14               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "15               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "16               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "17               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "18               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "19               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "20               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "21               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "22               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "23               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "24               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "25               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "26               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "27               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "28               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "29               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "30               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "31               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "32               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "33               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "34               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "\n",
       "    channel_keep_ratio_baseline  input_keep_ratio_baseline  ...  \\\n",
       "0                           1.0                        1.0  ...   \n",
       "1                           1.0                        1.0  ...   \n",
       "2                           1.0                        1.0  ...   \n",
       "3                           1.0                        1.0  ...   \n",
       "4                           1.0                        1.0  ...   \n",
       "5                           1.0                        1.0  ...   \n",
       "6                           1.0                        1.0  ...   \n",
       "7                           1.0                        1.0  ...   \n",
       "8                           1.0                        1.0  ...   \n",
       "9                           1.0                        1.0  ...   \n",
       "10                          1.0                        1.0  ...   \n",
       "11                          1.0                        1.0  ...   \n",
       "12                          1.0                        1.0  ...   \n",
       "13                          1.0                        1.0  ...   \n",
       "14                          1.0                        1.0  ...   \n",
       "15                          1.0                        1.0  ...   \n",
       "16                          1.0                        1.0  ...   \n",
       "17                          1.0                        1.0  ...   \n",
       "18                          1.0                        1.0  ...   \n",
       "19                          1.0                        1.0  ...   \n",
       "20                          1.0                        1.0  ...   \n",
       "21                          1.0                        1.0  ...   \n",
       "22                          1.0                        1.0  ...   \n",
       "23                          1.0                        1.0  ...   \n",
       "24                          1.0                        1.0  ...   \n",
       "25                          1.0                        1.0  ...   \n",
       "26                          1.0                        1.0  ...   \n",
       "27                          1.0                        1.0  ...   \n",
       "28                          1.0                        1.0  ...   \n",
       "29                          1.0                        1.0  ...   \n",
       "30                          1.0                        1.0  ...   \n",
       "31                          1.0                        1.0  ...   \n",
       "32                          1.0                        1.0  ...   \n",
       "33                          1.0                        1.0  ...   \n",
       "34                          1.0                        1.0  ...   \n",
       "\n",
       "    grad_block_size_baseline  avg_forward_ms_baseline  \\\n",
       "0                        NaN                 0.442019   \n",
       "1                        NaN                 0.460432   \n",
       "2                        NaN                 0.460854   \n",
       "3                        NaN                 0.466453   \n",
       "4                        NaN                 0.476136   \n",
       "5                        NaN                 0.520618   \n",
       "6                        NaN                 0.541578   \n",
       "7                        NaN                 0.562176   \n",
       "8                        NaN                 0.566720   \n",
       "9                        NaN                 0.568173   \n",
       "10                       NaN                 0.520618   \n",
       "11                       NaN                 0.572709   \n",
       "12                       NaN                 0.568173   \n",
       "13                       NaN                 0.587275   \n",
       "14                       NaN                 0.569450   \n",
       "15                       NaN                 0.610509   \n",
       "16                       NaN                 0.466453   \n",
       "17                       NaN                 0.647275   \n",
       "18                       NaN                 0.637451   \n",
       "19                       NaN                 0.623354   \n",
       "20                       NaN                 0.520618   \n",
       "21                       NaN                 0.728152   \n",
       "22                       NaN                 0.466453   \n",
       "23                       NaN                 0.662219   \n",
       "24                       NaN                 0.794290   \n",
       "25                       NaN                 0.857269   \n",
       "26                       NaN                 0.807085   \n",
       "27                       NaN                 0.569450   \n",
       "28                       NaN                 0.647275   \n",
       "29                       NaN                 0.680090   \n",
       "30                       NaN                 0.894262   \n",
       "31                       NaN                 0.910302   \n",
       "32                       NaN                 0.619749   \n",
       "33                       NaN                 0.902048   \n",
       "34                       NaN                 0.905222   \n",
       "\n",
       "    avg_backward_ms_baseline  avg_step_ms_baseline  speedup_forward  \\\n",
       "0                   0.776563              1.218582         0.187880   \n",
       "1                   0.989592              1.450024         0.175373   \n",
       "2                   0.991088              1.451942         0.144063   \n",
       "3                   0.449296              0.915749         0.168451   \n",
       "4                   0.615542              1.091678         0.145632   \n",
       "5                   0.392453              0.913070         0.163873   \n",
       "6                   1.024398              1.565976         0.184247   \n",
       "7                   0.472083              1.034259         0.135138   \n",
       "8                   1.013517              1.580237         0.148735   \n",
       "9                   0.436040              1.004213         0.138006   \n",
       "10                  0.392453              0.913070         0.163873   \n",
       "11                  0.428942              1.001651         0.134412   \n",
       "12                  0.436040              1.004213         0.138006   \n",
       "13                  0.436429              1.023704         0.150264   \n",
       "14                  0.442437              1.011886         0.152594   \n",
       "15                  0.447638              1.058147         0.137449   \n",
       "16                  0.449296              0.915749         0.168451   \n",
       "17                  0.463666              1.110941         0.145704   \n",
       "18                  0.463958              1.101410         0.127387   \n",
       "19                  0.468859              1.092213         0.136362   \n",
       "20                  0.392453              0.913070         0.163873   \n",
       "21                  0.608869              1.337021         0.187209   \n",
       "22                  0.449296              0.915749         0.168451   \n",
       "23                  0.511493              1.173712         0.157879   \n",
       "24                  0.666102              1.460392         0.142823   \n",
       "25                  0.745971              1.603240         0.154129   \n",
       "26                  0.659870              1.466955         0.131059   \n",
       "27                  0.442437              1.011886         0.152594   \n",
       "28                  0.463666              1.110941         0.145704   \n",
       "29                  0.507544              1.187634         0.153959   \n",
       "30                  0.812904              1.707166         0.157067   \n",
       "31                  0.805669              1.715971         0.141861   \n",
       "32                  0.487173              1.106922         0.147856   \n",
       "33                  0.856621              1.758669         0.146422   \n",
       "34                  0.809608              1.714830         0.148032   \n",
       "\n",
       "    speedup_backward  speedup_step  throughput_ratio  mem_alloc_ratio  \\\n",
       "0           0.207099      0.200128          0.198495         1.298929   \n",
       "1           0.177064      0.176527          0.175538         1.869446   \n",
       "2           0.172061      0.163175          0.163142         1.869446   \n",
       "3           0.403102      0.283578          0.283652         1.204192   \n",
       "4           0.273928      0.217972          0.218212         1.691050   \n",
       "5           0.491844      0.304840          0.303460         1.233255   \n",
       "6           0.242309      0.222229          0.220613         1.869446   \n",
       "7           0.346153      0.231455          0.232097         1.204192   \n",
       "8           0.185033      0.172016          0.169039         1.869446   \n",
       "9           0.379804      0.242997          0.242941         1.204192   \n",
       "10          0.491844      0.304840          0.303460         1.233255   \n",
       "11          0.385454      0.241917          0.248589         1.238774   \n",
       "12          0.379804      0.242997          0.242941         1.204192   \n",
       "13          0.394449      0.254366          0.259951         1.128550   \n",
       "14          0.416754      0.268095          0.275864         1.236068   \n",
       "15          0.390608      0.244545          0.248327         1.216643   \n",
       "16          0.403102      0.283578          0.283652         1.204192   \n",
       "17          0.430655      0.264632          0.272580         1.364370   \n",
       "18          0.360112      0.225420          0.232378         1.191200   \n",
       "19          0.350707      0.228375          0.245418         1.216579   \n",
       "20          0.491844      0.304840          0.303460         1.233255   \n",
       "21          0.403403      0.285662          0.305380         1.212119   \n",
       "22          0.403102      0.283578          0.283652         1.204192   \n",
       "23          0.421317      0.272683          0.278067         1.398639   \n",
       "24          0.426034      0.271999          0.298120         1.034387   \n",
       "25          0.403831      0.270313          0.286691         1.095275   \n",
       "26          0.439757      0.269919          0.295756         1.029400   \n",
       "27          0.416754      0.268095          0.275864         1.236068   \n",
       "28          0.430655      0.264632          0.272580         1.364370   \n",
       "29          0.411680      0.264098          0.272012         1.391945   \n",
       "30          0.380567      0.263492          0.263526         1.176586   \n",
       "31          0.400772      0.263423          0.262489         1.270461   \n",
       "32          0.410292      0.263358          0.271576         1.385012   \n",
       "33          0.383903      0.262096          0.260953         1.421627   \n",
       "34          0.388751      0.261680          0.261636         1.318840   \n",
       "\n",
       "    mem_reserved_ratio  \n",
       "0             1.323529  \n",
       "1             1.000000  \n",
       "2             1.000000  \n",
       "3             1.000000  \n",
       "4             1.500000  \n",
       "5             1.000000  \n",
       "6             1.000000  \n",
       "7             1.285714  \n",
       "8             2.027027  \n",
       "9             1.333333  \n",
       "10            1.000000  \n",
       "11            1.022727  \n",
       "12            1.333333  \n",
       "13            1.285714  \n",
       "14            1.022222  \n",
       "15            1.305556  \n",
       "16            1.000000  \n",
       "17            1.232558  \n",
       "18            1.333333  \n",
       "19            1.333333  \n",
       "20            1.000000  \n",
       "21            1.046512  \n",
       "22            1.000000  \n",
       "23            1.444444  \n",
       "24            1.030303  \n",
       "25            1.029412  \n",
       "26            1.000000  \n",
       "27            1.022222  \n",
       "28            1.232558  \n",
       "29            1.255814  \n",
       "30            1.294118  \n",
       "31            1.000000  \n",
       "32            1.600000  \n",
       "33            1.425532  \n",
       "34            1.270270  \n",
       "\n",
       "[35 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_forward_top = conv_layer_compare_df.sort_values(\"avg_forward_ms_baseline\").head(10).assign(metric=\"forward_time\")\n",
    "conv_backward_top = conv_layer_compare_df.sort_values(\"avg_backward_ms_baseline\").head(10).assign(metric=\"backward_time\")\n",
    "conv_speedup_top = conv_layer_compare_df.sort_values(\"speedup_step\", ascending=False).head(15).assign(metric=\"speedup_step\")\n",
    "\n",
    "conv_layer_best_df = pd.concat(\n",
    "    [conv_forward_top, conv_backward_top, conv_speedup_top],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "conv_layer_best_df = conv_layer_best_df[[\n",
    "    \"metric\",\n",
    "    \"layer\",\n",
    "    \"batch_size\",\n",
    "    \"layer_type_baseline\",\n",
    "    \"kernel_size_baseline\",\n",
    "    \"stride_baseline\",\n",
    "    \"padding_baseline\",\n",
    "    \"dilation_baseline\",\n",
    "    \"channel_keep_ratio_baseline\",\n",
    "    \"input_keep_ratio_baseline\",\n",
    "    \"block_size_baseline\",\n",
    "    \"grad_block_size_baseline\",\n",
    "    \"avg_forward_ms_baseline\",\n",
    "    \"avg_backward_ms_baseline\",\n",
    "    \"avg_step_ms_baseline\",\n",
    "    \"speedup_forward\",\n",
    "    \"speedup_backward\",\n",
    "    \"speedup_step\",\n",
    "    \"throughput_ratio\",\n",
    "    \"mem_alloc_ratio\",\n",
    "    \"mem_reserved_ratio\",\n",
    "]]\n",
    "conv_layer_best_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
