{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34dffa7c",
   "metadata": {},
   "source": [
    "# ResNet18 Baseline Conv2d Benchmark\n",
    "\n",
    "Сравнение nn.Conv2d и кастомной img2col→GEMM свёртки (Baseline TritonConv2d) на ResNet18 с разными batch size и сценариями спарсификации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319e97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4154eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from conv_gemm.baseline_layers.triton_conv2d import TritonConv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da3ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_root\": \"/mnt/d/VSCode-Projects/conv2d-img2col-gemm/data\",\n",
      "  \"num_classes\": 10,\n",
      "  \"batch_sizes\": [\n",
      "    32,\n",
      "    64,\n",
      "    96,\n",
      "    128,\n",
      "    160,\n",
      "    192,\n",
      "    256\n",
      "  ],\n",
      "  \"num_workers\": 4,\n",
      "  \"train_subset\": 8192,\n",
      "  \"lr\": 0.001,\n",
      "  \"momentum\": 0.9,\n",
      "  \"weight_decay\": 0.0005,\n",
      "  \"warmup_steps\": 5,\n",
      "  \"model_warmup_steps\": 3,\n",
      "  \"benchmark_steps\": 40,\n",
      "  \"baseline_conv\": {\n",
      "    \"BLOCK_M\": 64,\n",
      "    \"BLOCK_N\": 64,\n",
      "    \"BLOCK_K\": 64,\n",
      "    \"NUM_WARPS\": 4,\n",
      "    \"NUM_STAGES\": 2\n",
      "  },\n",
      "  \"sparsity_bench\": {\n",
      "    \"modes\": [\n",
      "      \"channel\",\n",
      "      \"block\",\n",
      "      \"input\"\n",
      "    ],\n",
      "    \"keep_ratios\": [\n",
      "      0.75,\n",
      "      0.6,\n",
      "      0.5,\n",
      "      0.25\n",
      "    ],\n",
      "    \"block_size\": 4,\n",
      "    \"batch_size\": 128\n",
      "  },\n",
      "  \"conv_layer_bench\": {\n",
      "    \"warmup_steps\": 5,\n",
      "    \"bench_steps\": 20\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type != \"cuda\":\n",
    "    raise RuntimeError(\"CUDA GPU is required for this benchmark\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "data_root = Path(\"../data\").resolve()\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"data_root\": str(data_root),\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_sizes\": [32, 64, 96, 128, 160, 192, 256],\n",
    "    \"num_workers\": 4,\n",
    "    \"train_subset\": 8192,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"warmup_steps\": 5,\n",
    "    \"model_warmup_steps\": 3,\n",
    "    \"benchmark_steps\": 40,\n",
    "    \"baseline_conv\": {\n",
    "        \"BLOCK_M\": 64,\n",
    "        \"BLOCK_N\": 64,\n",
    "        \"BLOCK_K\": 64,\n",
    "        \"NUM_WARPS\": 4,\n",
    "        \"NUM_STAGES\": 2,\n",
    "    },\n",
    "    \"sparsity_bench\": {\n",
    "        \"modes\": [\"channel\", \"block\", \"input\"],\n",
    "        \"keep_ratios\": [0.75, 0.6, 0.5, 0.25],\n",
    "        \"block_size\": 4,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "    \"conv_layer_bench\": {\n",
    "        \"warmup_steps\": 5,\n",
    "        \"bench_steps\": 20,\n",
    "    },\n",
    "}\n",
    "print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e44fbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{32: 256, 64: 128, 96: 85, 128: 64, 160: 51, 192: 42, 256: 32}\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(\n",
    "    root=config[\"data_root\"], train=True, download=True, transform=transform_train\n",
    ")\n",
    "if config[\"train_subset\"] is not None and config[\"train_subset\"] < len(full_train):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    subset_idx = torch.randperm(len(full_train), generator=g)[: config[\"train_subset\"]]\n",
    "    train_dataset = torch.utils.data.Subset(full_train, subset_idx)\n",
    "else:\n",
    "    train_dataset = full_train\n",
    "\n",
    "\n",
    "def make_loader(batch_size: int) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "train_loaders: Dict[int, DataLoader] = {}\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    train_loaders[bs] = make_loader(bs)\n",
    "\n",
    "print({bs: len(loader) for bs, loader in train_loaders.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbd874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triton_conv(src: nn.Conv2d, cfg: dict) -> TritonConv2d:\n",
    "    if src.groups != 1:\n",
    "        raise ValueError(\"Baseline TritonConv2d currently supports groups=1 only\")\n",
    "    layer = TritonConv2d(\n",
    "        in_channels=src.in_channels,\n",
    "        out_channels=src.out_channels,\n",
    "        kernel_size=src.kernel_size,\n",
    "        stride=src.stride,\n",
    "        padding=src.padding,\n",
    "        dilation=src.dilation,\n",
    "        bias=(src.bias is not None),\n",
    "        # **cfg,\n",
    "    ).to(src.weight.device)\n",
    "    with torch.no_grad():\n",
    "        layer.weight.copy_(src.weight.detach().to(layer.weight.dtype))\n",
    "        if layer.bias is not None and src.bias is not None:\n",
    "            layer.bias.copy_(src.bias.detach().to(layer.bias.dtype))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def replace_convs_with_baseline(module: nn.Module, cfg: dict):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            setattr(module, name, make_triton_conv(child, cfg))\n",
    "        else:\n",
    "            replace_convs_with_baseline(child, cfg)\n",
    "\n",
    "\n",
    "def build_model_pair(config: dict):\n",
    "    reference = torchvision.models.resnet18(num_classes=config[\"num_classes\"])\n",
    "    baseline = copy.deepcopy(reference)\n",
    "    replace_convs_with_baseline(baseline, config[\"baseline_conv\"])\n",
    "    return reference.half(), baseline.half()\n",
    "\n",
    "\n",
    "def apply_sparsity_to_model(model: nn.Module, mode: str, keep_ratio: float, block_size: int = 4):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, TritonConv2d):\n",
    "            layer.clear_sparsity()\n",
    "            if keep_ratio >= 1.0:\n",
    "                continue\n",
    "            if mode == \"channel\":\n",
    "                layer.set_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_channel_sparsity(keep_ratio)\n",
    "            elif mode == \"block\":\n",
    "                layer.set_block_sparsity(keep_ratio, block_size=block_size)\n",
    "                layer.set_backward_block_sparsity(keep_ratio, block_size=block_size)\n",
    "            elif mode == \"input\":\n",
    "                layer.set_input_channel_sparsity(keep_ratio)\n",
    "                layer.set_backward_input_channel_sparsity(keep_ratio)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sparsity mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968c84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model: nn.Module, label: str, loader: DataLoader, config: dict):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    warmup = config[\"warmup_steps\"]\n",
    "    total_steps = config[\"benchmark_steps\"]\n",
    "    model_warmup = config.get(\"model_warmup_steps\", 0)\n",
    "    records = []\n",
    "\n",
    "    if model_warmup > 0:\n",
    "        warmup_iter = iter(loader)\n",
    "        for _ in range(model_warmup):\n",
    "            try:\n",
    "                images, targets = next(warmup_iter)\n",
    "            except StopIteration:\n",
    "                warmup_iter = iter(loader)\n",
    "                images, targets = next(warmup_iter)\n",
    "\n",
    "            images = images.half().to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        # Extra GPU warmup to drop JIT/cudnn noise from timed iterations\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    data_iter = iter(loader)\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            images, targets = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(loader)\n",
    "            images, targets = next(data_iter)\n",
    "\n",
    "        images = images.half().to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        fwd_end = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        fwd_start.record()\n",
    "        outputs = model(images)\n",
    "        fwd_end.record()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        bwd_start.record()\n",
    "        loss.backward()\n",
    "        bwd_end.record()\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_ms = fwd_start.elapsed_time(fwd_end)\n",
    "        bwd_ms = bwd_start.elapsed_time(bwd_end)\n",
    "        step_ms = fwd_ms + bwd_ms\n",
    "        mem_alloc = torch.cuda.max_memory_allocated(device) / 1024 ** 2\n",
    "        mem_reserved = torch.cuda.max_memory_reserved(device) / 1024 ** 2\n",
    "\n",
    "        if step >= warmup:\n",
    "            records.append({\n",
    "                \"label\": label,\n",
    "                \"step\": step,\n",
    "                \"loss\": float(loss.item()),\n",
    "                \"fwd_ms\": fwd_ms,\n",
    "                \"bwd_ms\": bwd_ms,\n",
    "                \"step_ms\": step_ms,\n",
    "                \"throughput_sps\": images.size(0) / (step_ms / 1000.0),\n",
    "                \"max_mem_alloc_mb\": mem_alloc,\n",
    "                \"max_mem_reserved_mb\": mem_reserved,\n",
    "            })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No data recorded for benchmark\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    summary = {\n",
    "        \"label\": label,\n",
    "        \"avg_forward_ms\": df[\"fwd_ms\"].mean(),\n",
    "        \"avg_backward_ms\": df[\"bwd_ms\"].mean(),\n",
    "        \"avg_step_ms\": df[\"step_ms\"].mean(),\n",
    "        \"samples_per_s\": df[\"throughput_sps\"].mean(),\n",
    "        \"max_mem_alloc_mb\": df[\"max_mem_alloc_mb\"].max(),\n",
    "        \"max_mem_reserved_mb\": df[\"max_mem_reserved_mb\"].max(),\n",
    "    }\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e811c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conv_module(module: nn.Module) -> bool:\n",
    "    return isinstance(module, (nn.Conv2d, TritonConv2d))\n",
    "\n",
    "\n",
    "def collect_conv_input_shapes(model: nn.Module, sample: torch.Tensor) -> Dict[str, torch.Size]:\n",
    "    shapes: Dict[str, torch.Size] = {}\n",
    "    handles = []\n",
    "\n",
    "    def make_hook(layer_name: str):\n",
    "        def _hook(mod, inp):\n",
    "            shapes.setdefault(layer_name, inp[0].shape)\n",
    "            return None  # do not override inputs\n",
    "        return _hook\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if is_conv_module(module):\n",
    "            handles.append(module.register_forward_pre_hook(make_hook(name)))\n",
    "    with torch.no_grad():\n",
    "        model(sample)\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def conv_metadata(name: str, module: nn.Module) -> Dict[str, object]:\n",
    "    meta = {\n",
    "        \"layer\": name,\n",
    "        \"layer_type\": type(module).__name__,\n",
    "        \"in_channels\": getattr(module, \"in_channels\", None),\n",
    "        \"out_channels\": getattr(module, \"out_channels\", None),\n",
    "        \"kernel_size\": tuple(getattr(module, \"kernel_size\", [])) if hasattr(module, \"kernel_size\") else None,\n",
    "        \"stride\": tuple(getattr(module, \"stride\", [])) if hasattr(module, \"stride\") else None,\n",
    "        \"padding\": tuple(getattr(module, \"padding\", [])) if hasattr(module, \"padding\") else None,\n",
    "        \"dilation\": tuple(getattr(module, \"dilation\", [])) if hasattr(module, \"dilation\") else None,\n",
    "    }\n",
    "    if isinstance(module, TritonConv2d):\n",
    "        keep_out = float(module.channel_mask.float().mean().item()) if hasattr(module, \"channel_mask\") else 1.0\n",
    "        keep_in = float(module.input_channel_mask.float().mean().item()) if hasattr(module, \"input_channel_mask\") else 1.0\n",
    "        meta.update({\n",
    "            \"channel_keep_ratio\": keep_out,\n",
    "            \"input_keep_ratio\": keep_in,\n",
    "            \"block_size\": getattr(module, \"block_size\", None),\n",
    "            \"grad_block_size\": getattr(module, \"grad_block_size\", None),\n",
    "        })\n",
    "    return meta\n",
    "\n",
    "\n",
    "def benchmark_single_conv(module: nn.Module, input_shape: torch.Size, device: torch.device, warmup: int, steps: int) -> Dict[str, float]:\n",
    "    x = torch.randn(input_shape, device=device, dtype=torch.float16, requires_grad=True)\n",
    "    layer = copy.deepcopy(module).to(device)\n",
    "    layer.train()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    for _ in range(warmup):\n",
    "        layer.zero_grad(set_to_none=True)\n",
    "        out = layer(x)\n",
    "        loss = out.float().sum()\n",
    "        loss.backward()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    records: List[Dict[str, float]] = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        layer.zero_grad(set_to_none=True)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        fwd_end = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_start = torch.cuda.Event(enable_timing=True)\n",
    "        bwd_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        fwd_start.record()\n",
    "        out = layer(x)\n",
    "        fwd_end.record()\n",
    "\n",
    "        loss = out.float().sum()\n",
    "\n",
    "        bwd_start.record()\n",
    "        loss.backward()\n",
    "        bwd_end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        fwd_ms = fwd_start.elapsed_time(fwd_end)\n",
    "        bwd_ms = bwd_start.elapsed_time(bwd_end)\n",
    "        step_ms = fwd_ms + bwd_ms\n",
    "        records.append({\n",
    "            \"avg_forward_ms\": fwd_ms,\n",
    "            \"avg_backward_ms\": bwd_ms,\n",
    "            \"avg_step_ms\": step_ms,\n",
    "            \"throughput_sps\": input_shape[0] / (step_ms / 1000.0),\n",
    "            \"max_mem_alloc_mb\": torch.cuda.max_memory_allocated(device) / 1024 ** 2,\n",
    "            \"max_mem_reserved_mb\": torch.cuda.max_memory_reserved(device) / 1024 ** 2,\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No data recorded for conv benchmark\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return {\n",
    "        \"avg_forward_ms\": df[\"avg_forward_ms\"].mean(),\n",
    "        \"avg_backward_ms\": df[\"avg_backward_ms\"].mean(),\n",
    "        \"avg_step_ms\": df[\"avg_step_ms\"].mean(),\n",
    "        \"throughput_sps\": df[\"throughput_sps\"].mean(),\n",
    "        \"max_mem_alloc_mb\": df[\"max_mem_alloc_mb\"].max(),\n",
    "        \"max_mem_reserved_mb\": df[\"max_mem_reserved_mb\"].max(),\n",
    "    }\n",
    "\n",
    "\n",
    "def benchmark_conv_layers(torch_model: nn.Module, baseline_model: nn.Module, batch_size: int, config: dict):\n",
    "    bench_cfg = config.get(\"conv_layer_bench\", {\"warmup_steps\": 3, \"bench_steps\": 10})\n",
    "    warmup = bench_cfg.get(\"warmup_steps\", 3)\n",
    "    steps = bench_cfg.get(\"bench_steps\", 10)\n",
    "\n",
    "    sample = torch.randn(batch_size, 3, 32, 32, device=device, dtype=torch.float16)\n",
    "    torch_model = torch_model.to(device).eval()\n",
    "    baseline_model = baseline_model.to(device).eval()\n",
    "\n",
    "    input_shapes = collect_conv_input_shapes(torch_model, sample)\n",
    "    torch_conv_map = dict(torch_model.named_modules())\n",
    "    baseline_conv_map = dict(baseline_model.named_modules())\n",
    "\n",
    "    rows: List[Dict[str, object]] = []\n",
    "    for name, inp_shape in input_shapes.items():\n",
    "        torch_layer = torch_conv_map.get(name)\n",
    "        baseline_layer = baseline_conv_map.get(name)\n",
    "        if not (is_conv_module(torch_layer) and is_conv_module(baseline_layer)):\n",
    "            continue\n",
    "\n",
    "        for variant, layer in [(\"nn.Conv2d\", torch_layer), (\"Baseline TritonConv2d\", baseline_layer)]:\n",
    "            summary = benchmark_single_conv(layer, inp_shape, device, warmup, steps)\n",
    "            meta = conv_metadata(name, layer)\n",
    "            meta.update({\n",
    "                \"variant\": variant,\n",
    "                \"batch_size\": batch_size,\n",
    "            })\n",
    "            meta.update(summary)\n",
    "            rows.append(meta)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037f8b1",
   "metadata": {},
   "source": [
    "Таблица `summary_df` показывает средние метрики по каждому batch size: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `samples_per_s`, а также пики памяти (`max_mem_alloc_mb`, `max_mem_reserved_mb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f25b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch size 32 ===\n",
      "=== Batch size 64 ===\n",
      "=== Batch size 96 ===\n",
      "=== Batch size 128 ===\n",
      "=== Batch size 160 ===\n",
      "=== Batch size 192 ===\n",
      "=== Batch size 256 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>nn.Conv2d (bs=32)</td>\n",
       "      <td>7.778965</td>\n",
       "      <td>6.274370</td>\n",
       "      <td>14.053335</td>\n",
       "      <td>2353.629652</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>Baseline TritonConv2d (bs=32)</td>\n",
       "      <td>45.730244</td>\n",
       "      <td>18.656490</td>\n",
       "      <td>64.386734</td>\n",
       "      <td>503.617131</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>nn.Conv2d (bs=64)</td>\n",
       "      <td>8.038720</td>\n",
       "      <td>6.581922</td>\n",
       "      <td>14.620642</td>\n",
       "      <td>4572.664194</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>64</th>\n",
       "      <td>Baseline TritonConv2d (bs=64)</td>\n",
       "      <td>43.745434</td>\n",
       "      <td>18.876972</td>\n",
       "      <td>62.622406</td>\n",
       "      <td>1029.017290</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>nn.Conv2d (bs=96)</td>\n",
       "      <td>8.269396</td>\n",
       "      <td>6.013748</td>\n",
       "      <td>14.283144</td>\n",
       "      <td>6799.590031</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>96</th>\n",
       "      <td>Baseline TritonConv2d (bs=96)</td>\n",
       "      <td>41.662605</td>\n",
       "      <td>21.079979</td>\n",
       "      <td>62.742584</td>\n",
       "      <td>1538.861629</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>nn.Conv2d (bs=128)</td>\n",
       "      <td>9.351014</td>\n",
       "      <td>6.526245</td>\n",
       "      <td>15.877258</td>\n",
       "      <td>8238.250459</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>128</th>\n",
       "      <td>Baseline TritonConv2d (bs=128)</td>\n",
       "      <td>42.343821</td>\n",
       "      <td>25.119656</td>\n",
       "      <td>67.463477</td>\n",
       "      <td>1904.794747</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>nn.Conv2d (bs=160)</td>\n",
       "      <td>9.560735</td>\n",
       "      <td>7.603258</td>\n",
       "      <td>17.163994</td>\n",
       "      <td>9408.253630</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>160</th>\n",
       "      <td>Baseline TritonConv2d (bs=160)</td>\n",
       "      <td>45.031539</td>\n",
       "      <td>28.718870</td>\n",
       "      <td>73.750409</td>\n",
       "      <td>2197.614342</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>nn.Conv2d (bs=192)</td>\n",
       "      <td>8.512421</td>\n",
       "      <td>8.360785</td>\n",
       "      <td>16.873207</td>\n",
       "      <td>11492.926501</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>192</th>\n",
       "      <td>Baseline TritonConv2d (bs=192)</td>\n",
       "      <td>40.830962</td>\n",
       "      <td>35.307957</td>\n",
       "      <td>76.138919</td>\n",
       "      <td>2529.765482</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn.Conv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>nn.Conv2d (bs=256)</td>\n",
       "      <td>9.572772</td>\n",
       "      <td>10.040291</td>\n",
       "      <td>19.613062</td>\n",
       "      <td>13442.939432</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline TritonConv2d</th>\n",
       "      <th>256</th>\n",
       "      <td>Baseline TritonConv2d (bs=256)</td>\n",
       "      <td>46.241049</td>\n",
       "      <td>50.099462</td>\n",
       "      <td>96.340511</td>\n",
       "      <td>2679.841985</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           label  \\\n",
       "variant               batch_size                                   \n",
       "nn.Conv2d             32                       nn.Conv2d (bs=32)   \n",
       "Baseline TritonConv2d 32           Baseline TritonConv2d (bs=32)   \n",
       "nn.Conv2d             64                       nn.Conv2d (bs=64)   \n",
       "Baseline TritonConv2d 64           Baseline TritonConv2d (bs=64)   \n",
       "nn.Conv2d             96                       nn.Conv2d (bs=96)   \n",
       "Baseline TritonConv2d 96           Baseline TritonConv2d (bs=96)   \n",
       "nn.Conv2d             128                     nn.Conv2d (bs=128)   \n",
       "Baseline TritonConv2d 128         Baseline TritonConv2d (bs=128)   \n",
       "nn.Conv2d             160                     nn.Conv2d (bs=160)   \n",
       "Baseline TritonConv2d 160         Baseline TritonConv2d (bs=160)   \n",
       "nn.Conv2d             192                     nn.Conv2d (bs=192)   \n",
       "Baseline TritonConv2d 192         Baseline TritonConv2d (bs=192)   \n",
       "nn.Conv2d             256                     nn.Conv2d (bs=256)   \n",
       "Baseline TritonConv2d 256         Baseline TritonConv2d (bs=256)   \n",
       "\n",
       "                                  avg_forward_ms  avg_backward_ms  \\\n",
       "variant               batch_size                                    \n",
       "nn.Conv2d             32                7.778965         6.274370   \n",
       "Baseline TritonConv2d 32               45.730244        18.656490   \n",
       "nn.Conv2d             64                8.038720         6.581922   \n",
       "Baseline TritonConv2d 64               43.745434        18.876972   \n",
       "nn.Conv2d             96                8.269396         6.013748   \n",
       "Baseline TritonConv2d 96               41.662605        21.079979   \n",
       "nn.Conv2d             128               9.351014         6.526245   \n",
       "Baseline TritonConv2d 128              42.343821        25.119656   \n",
       "nn.Conv2d             160               9.560735         7.603258   \n",
       "Baseline TritonConv2d 160              45.031539        28.718870   \n",
       "nn.Conv2d             192               8.512421         8.360785   \n",
       "Baseline TritonConv2d 192              40.830962        35.307957   \n",
       "nn.Conv2d             256               9.572772        10.040291   \n",
       "Baseline TritonConv2d 256              46.241049        50.099462   \n",
       "\n",
       "                                  avg_step_ms  samples_per_s  \\\n",
       "variant               batch_size                               \n",
       "nn.Conv2d             32            14.053335    2353.629652   \n",
       "Baseline TritonConv2d 32            64.386734     503.617131   \n",
       "nn.Conv2d             64            14.620642    4572.664194   \n",
       "Baseline TritonConv2d 64            62.622406    1029.017290   \n",
       "nn.Conv2d             96            14.283144    6799.590031   \n",
       "Baseline TritonConv2d 96            62.742584    1538.861629   \n",
       "nn.Conv2d             128           15.877258    8238.250459   \n",
       "Baseline TritonConv2d 128           67.463477    1904.794747   \n",
       "nn.Conv2d             160           17.163994    9408.253630   \n",
       "Baseline TritonConv2d 160           73.750409    2197.614342   \n",
       "nn.Conv2d             192           16.873207   11492.926501   \n",
       "Baseline TritonConv2d 192           76.138919    2529.765482   \n",
       "nn.Conv2d             256           19.613062   13442.939432   \n",
       "Baseline TritonConv2d 256           96.340511    2679.841985   \n",
       "\n",
       "                                  max_mem_alloc_mb  max_mem_reserved_mb  \n",
       "variant               batch_size                                         \n",
       "nn.Conv2d             32                127.072266                138.0  \n",
       "Baseline TritonConv2d 32                154.655273                182.0  \n",
       "nn.Conv2d             64                127.260254                138.0  \n",
       "Baseline TritonConv2d 64                169.953613                204.0  \n",
       "nn.Conv2d             96                127.573730                144.0  \n",
       "Baseline TritonConv2d 96                195.142090                238.0  \n",
       "nn.Conv2d             128               132.817871                168.0  \n",
       "Baseline TritonConv2d 128               213.830078                312.0  \n",
       "nn.Conv2d             160               140.381836                162.0  \n",
       "Baseline TritonConv2d 160               235.769043                284.0  \n",
       "nn.Conv2d             192               148.069824                160.0  \n",
       "Baseline TritonConv2d 192               260.832031                328.0  \n",
       "nn.Conv2d             256               162.446289                196.0  \n",
       "Baseline TritonConv2d 256               300.833496                500.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_summaries = []\n",
    "batch_details = []\n",
    "conv_layer_rows = []\n",
    "\n",
    "for bs, loader in train_loaders.items():\n",
    "    print(f\"=== Batch size {bs} ===\")\n",
    "    torch_model, baseline_model = build_model_pair(config)\n",
    "\n",
    "    # per-layer bench (forward FP16, backward FP32)\n",
    "    conv_layer_rows.extend(benchmark_conv_layers(torch_model, baseline_model, bs, config))\n",
    "\n",
    "    torch_df, torch_summary = run_benchmark(torch_model, f\"nn.Conv2d (bs={bs})\", loader, config)\n",
    "    torch_summary.update({\"variant\": \"nn.Conv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(torch_summary)\n",
    "    batch_details.append(torch_df.assign(variant=\"nn.Conv2d\", batch_size=bs))\n",
    "\n",
    "    baseline_df, baseline_summary = run_benchmark(baseline_model, f\"Baseline TritonConv2d (bs={bs})\", loader, config)\n",
    "    baseline_summary.update({\"variant\": \"Baseline TritonConv2d\", \"batch_size\": bs})\n",
    "    batch_summaries.append(baseline_summary)\n",
    "    batch_details.append(baseline_df.assign(variant=\"Baseline TritonConv2d\", batch_size=bs))\n",
    "\n",
    "summary_df = pd.DataFrame(batch_summaries).set_index([\"variant\", \"batch_size\"])\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b90a09",
   "metadata": {},
   "source": [
    "Вывод `detail_df.groupby(...).describe()` содержит count/mean/std/min/25%/50%/75%/max для метрик `step_ms`, `fwd_ms`, `bwd_ms`, `max_mem_alloc_mb` отдельно по каждому `(variant, batch_size)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e564a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">step_ms</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fwd_ms</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bwd_ms</th>\n",
       "      <th colspan=\"8\" halign=\"left\">max_mem_alloc_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Baseline TritonConv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>64.386734</td>\n",
       "      <td>7.714205</td>\n",
       "      <td>53.815456</td>\n",
       "      <td>57.372768</td>\n",
       "      <td>62.656929</td>\n",
       "      <td>68.443359</td>\n",
       "      <td>82.406975</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.730244</td>\n",
       "      <td>...</td>\n",
       "      <td>21.241857</td>\n",
       "      <td>39.800831</td>\n",
       "      <td>35.0</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>154.655273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>62.622406</td>\n",
       "      <td>5.438710</td>\n",
       "      <td>55.743107</td>\n",
       "      <td>58.467583</td>\n",
       "      <td>61.369698</td>\n",
       "      <td>65.310529</td>\n",
       "      <td>76.923553</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.745434</td>\n",
       "      <td>...</td>\n",
       "      <td>18.515968</td>\n",
       "      <td>30.216192</td>\n",
       "      <td>35.0</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>169.953613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>62.742584</td>\n",
       "      <td>5.100138</td>\n",
       "      <td>57.877247</td>\n",
       "      <td>59.487199</td>\n",
       "      <td>60.230850</td>\n",
       "      <td>63.796144</td>\n",
       "      <td>78.579872</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.662605</td>\n",
       "      <td>...</td>\n",
       "      <td>20.440576</td>\n",
       "      <td>32.645119</td>\n",
       "      <td>35.0</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>195.142090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>67.463477</td>\n",
       "      <td>4.368278</td>\n",
       "      <td>61.957441</td>\n",
       "      <td>63.979456</td>\n",
       "      <td>66.749025</td>\n",
       "      <td>70.167774</td>\n",
       "      <td>77.208542</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.343821</td>\n",
       "      <td>...</td>\n",
       "      <td>25.134592</td>\n",
       "      <td>35.337215</td>\n",
       "      <td>35.0</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>213.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>73.750409</td>\n",
       "      <td>9.086172</td>\n",
       "      <td>64.520256</td>\n",
       "      <td>67.379122</td>\n",
       "      <td>70.951519</td>\n",
       "      <td>78.539248</td>\n",
       "      <td>104.960350</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.031539</td>\n",
       "      <td>...</td>\n",
       "      <td>28.389888</td>\n",
       "      <td>43.011070</td>\n",
       "      <td>35.0</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>235.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>76.138919</td>\n",
       "      <td>4.620434</td>\n",
       "      <td>71.011902</td>\n",
       "      <td>73.222321</td>\n",
       "      <td>74.886974</td>\n",
       "      <td>76.544800</td>\n",
       "      <td>93.375553</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.830962</td>\n",
       "      <td>...</td>\n",
       "      <td>34.584576</td>\n",
       "      <td>45.238274</td>\n",
       "      <td>35.0</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>260.832031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>96.340511</td>\n",
       "      <td>9.653058</td>\n",
       "      <td>87.935680</td>\n",
       "      <td>89.920609</td>\n",
       "      <td>93.105152</td>\n",
       "      <td>98.683104</td>\n",
       "      <td>127.200932</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.241049</td>\n",
       "      <td>...</td>\n",
       "      <td>49.689089</td>\n",
       "      <td>58.495998</td>\n",
       "      <td>35.0</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>300.833496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">nn.Conv2d</th>\n",
       "      <th>32</th>\n",
       "      <td>35.0</td>\n",
       "      <td>14.053335</td>\n",
       "      <td>2.677401</td>\n",
       "      <td>10.188448</td>\n",
       "      <td>12.031408</td>\n",
       "      <td>13.859904</td>\n",
       "      <td>15.608224</td>\n",
       "      <td>20.778144</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.778965</td>\n",
       "      <td>...</td>\n",
       "      <td>7.471616</td>\n",
       "      <td>12.185600</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>127.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>35.0</td>\n",
       "      <td>14.620642</td>\n",
       "      <td>3.887574</td>\n",
       "      <td>11.221376</td>\n",
       "      <td>12.570896</td>\n",
       "      <td>13.617663</td>\n",
       "      <td>15.037680</td>\n",
       "      <td>29.330273</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.038720</td>\n",
       "      <td>...</td>\n",
       "      <td>6.107136</td>\n",
       "      <td>20.396032</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>127.260254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>14.283144</td>\n",
       "      <td>1.578264</td>\n",
       "      <td>10.919808</td>\n",
       "      <td>13.200880</td>\n",
       "      <td>14.309408</td>\n",
       "      <td>14.829072</td>\n",
       "      <td>18.125888</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.269396</td>\n",
       "      <td>...</td>\n",
       "      <td>6.769664</td>\n",
       "      <td>9.326592</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>127.573730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>35.0</td>\n",
       "      <td>15.877258</td>\n",
       "      <td>2.680861</td>\n",
       "      <td>13.221248</td>\n",
       "      <td>14.104784</td>\n",
       "      <td>15.274944</td>\n",
       "      <td>16.528032</td>\n",
       "      <td>25.321600</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.351014</td>\n",
       "      <td>...</td>\n",
       "      <td>6.833152</td>\n",
       "      <td>10.984448</td>\n",
       "      <td>35.0</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>132.817871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>35.0</td>\n",
       "      <td>17.163994</td>\n",
       "      <td>1.717691</td>\n",
       "      <td>14.544320</td>\n",
       "      <td>16.042448</td>\n",
       "      <td>16.916928</td>\n",
       "      <td>18.008320</td>\n",
       "      <td>21.525152</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.560735</td>\n",
       "      <td>...</td>\n",
       "      <td>8.176128</td>\n",
       "      <td>10.800128</td>\n",
       "      <td>35.0</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>140.381836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>35.0</td>\n",
       "      <td>16.873207</td>\n",
       "      <td>1.638931</td>\n",
       "      <td>12.755616</td>\n",
       "      <td>16.145168</td>\n",
       "      <td>17.073472</td>\n",
       "      <td>17.801824</td>\n",
       "      <td>19.877792</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.512421</td>\n",
       "      <td>...</td>\n",
       "      <td>9.443840</td>\n",
       "      <td>9.819136</td>\n",
       "      <td>35.0</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>148.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>35.0</td>\n",
       "      <td>19.613062</td>\n",
       "      <td>3.810852</td>\n",
       "      <td>14.842657</td>\n",
       "      <td>17.015600</td>\n",
       "      <td>18.250175</td>\n",
       "      <td>20.747136</td>\n",
       "      <td>31.040959</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.572772</td>\n",
       "      <td>...</td>\n",
       "      <td>10.231296</td>\n",
       "      <td>16.565248</td>\n",
       "      <td>35.0</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>162.446289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 step_ms                                  \\\n",
       "                                   count       mean       std        min   \n",
       "variant               batch_size                                           \n",
       "Baseline TritonConv2d 32            35.0  64.386734  7.714205  53.815456   \n",
       "                      64            35.0  62.622406  5.438710  55.743107   \n",
       "                      96            35.0  62.742584  5.100138  57.877247   \n",
       "                      128           35.0  67.463477  4.368278  61.957441   \n",
       "                      160           35.0  73.750409  9.086172  64.520256   \n",
       "                      192           35.0  76.138919  4.620434  71.011902   \n",
       "                      256           35.0  96.340511  9.653058  87.935680   \n",
       "nn.Conv2d             32            35.0  14.053335  2.677401  10.188448   \n",
       "                      64            35.0  14.620642  3.887574  11.221376   \n",
       "                      96            35.0  14.283144  1.578264  10.919808   \n",
       "                      128           35.0  15.877258  2.680861  13.221248   \n",
       "                      160           35.0  17.163994  1.717691  14.544320   \n",
       "                      192           35.0  16.873207  1.638931  12.755616   \n",
       "                      256           35.0  19.613062  3.810852  14.842657   \n",
       "\n",
       "                                                                               \\\n",
       "                                        25%        50%        75%         max   \n",
       "variant               batch_size                                                \n",
       "Baseline TritonConv2d 32          57.372768  62.656929  68.443359   82.406975   \n",
       "                      64          58.467583  61.369698  65.310529   76.923553   \n",
       "                      96          59.487199  60.230850  63.796144   78.579872   \n",
       "                      128         63.979456  66.749025  70.167774   77.208542   \n",
       "                      160         67.379122  70.951519  78.539248  104.960350   \n",
       "                      192         73.222321  74.886974  76.544800   93.375553   \n",
       "                      256         89.920609  93.105152  98.683104  127.200932   \n",
       "nn.Conv2d             32          12.031408  13.859904  15.608224   20.778144   \n",
       "                      64          12.570896  13.617663  15.037680   29.330273   \n",
       "                      96          13.200880  14.309408  14.829072   18.125888   \n",
       "                      128         14.104784  15.274944  16.528032   25.321600   \n",
       "                      160         16.042448  16.916928  18.008320   21.525152   \n",
       "                      192         16.145168  17.073472  17.801824   19.877792   \n",
       "                      256         17.015600  18.250175  20.747136   31.040959   \n",
       "\n",
       "                                 fwd_ms             ...     bwd_ms             \\\n",
       "                                  count       mean  ...        75%        max   \n",
       "variant               batch_size                    ...                         \n",
       "Baseline TritonConv2d 32           35.0  45.730244  ...  21.241857  39.800831   \n",
       "                      64           35.0  43.745434  ...  18.515968  30.216192   \n",
       "                      96           35.0  41.662605  ...  20.440576  32.645119   \n",
       "                      128          35.0  42.343821  ...  25.134592  35.337215   \n",
       "                      160          35.0  45.031539  ...  28.389888  43.011070   \n",
       "                      192          35.0  40.830962  ...  34.584576  45.238274   \n",
       "                      256          35.0  46.241049  ...  49.689089  58.495998   \n",
       "nn.Conv2d             32           35.0   7.778965  ...   7.471616  12.185600   \n",
       "                      64           35.0   8.038720  ...   6.107136  20.396032   \n",
       "                      96           35.0   8.269396  ...   6.769664   9.326592   \n",
       "                      128          35.0   9.351014  ...   6.833152  10.984448   \n",
       "                      160          35.0   9.560735  ...   8.176128  10.800128   \n",
       "                      192          35.0   8.512421  ...   9.443840   9.819136   \n",
       "                      256          35.0   9.572772  ...  10.231296  16.565248   \n",
       "\n",
       "                                 max_mem_alloc_mb                   \\\n",
       "                                            count        mean  std   \n",
       "variant               batch_size                                     \n",
       "Baseline TritonConv2d 32                     35.0  154.655273  0.0   \n",
       "                      64                     35.0  169.953613  0.0   \n",
       "                      96                     35.0  195.142090  0.0   \n",
       "                      128                    35.0  213.830078  0.0   \n",
       "                      160                    35.0  235.769043  0.0   \n",
       "                      192                    35.0  260.832031  0.0   \n",
       "                      256                    35.0  300.833496  0.0   \n",
       "nn.Conv2d             32                     35.0  127.072266  0.0   \n",
       "                      64                     35.0  127.260254  0.0   \n",
       "                      96                     35.0  127.573730  0.0   \n",
       "                      128                    35.0  132.817871  0.0   \n",
       "                      160                    35.0  140.381836  0.0   \n",
       "                      192                    35.0  148.069824  0.0   \n",
       "                      256                    35.0  162.446289  0.0   \n",
       "\n",
       "                                                                      \\\n",
       "                                         min         25%         50%   \n",
       "variant               batch_size                                       \n",
       "Baseline TritonConv2d 32          154.655273  154.655273  154.655273   \n",
       "                      64          169.953613  169.953613  169.953613   \n",
       "                      96          195.142090  195.142090  195.142090   \n",
       "                      128         213.830078  213.830078  213.830078   \n",
       "                      160         235.769043  235.769043  235.769043   \n",
       "                      192         260.832031  260.832031  260.832031   \n",
       "                      256         300.833496  300.833496  300.833496   \n",
       "nn.Conv2d             32          127.072266  127.072266  127.072266   \n",
       "                      64          127.260254  127.260254  127.260254   \n",
       "                      96          127.573730  127.573730  127.573730   \n",
       "                      128         132.817871  132.817871  132.817871   \n",
       "                      160         140.381836  140.381836  140.381836   \n",
       "                      192         148.069824  148.069824  148.069824   \n",
       "                      256         162.446289  162.446289  162.446289   \n",
       "\n",
       "                                                          \n",
       "                                         75%         max  \n",
       "variant               batch_size                          \n",
       "Baseline TritonConv2d 32          154.655273  154.655273  \n",
       "                      64          169.953613  169.953613  \n",
       "                      96          195.142090  195.142090  \n",
       "                      128         213.830078  213.830078  \n",
       "                      160         235.769043  235.769043  \n",
       "                      192         260.832031  260.832031  \n",
       "                      256         300.833496  300.833496  \n",
       "nn.Conv2d             32          127.072266  127.072266  \n",
       "                      64          127.260254  127.260254  \n",
       "                      96          127.573730  127.573730  \n",
       "                      128         132.817871  132.817871  \n",
       "                      160         140.381836  140.381836  \n",
       "                      192         148.069824  148.069824  \n",
       "                      256         162.446289  162.446289  \n",
       "\n",
       "[14 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_df = pd.concat(batch_details, ignore_index=True)\n",
    "metrics = [\"step_ms\", \"fwd_ms\", \"bwd_ms\", \"max_mem_alloc_mb\"]\n",
    "detail_df.groupby([\"variant\", \"batch_size\"])[metrics].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d04038a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 variant  batch_size                           label  \\\n",
       " 0              nn.Conv2d          32               nn.Conv2d (bs=32)   \n",
       " 1              nn.Conv2d          64               nn.Conv2d (bs=64)   \n",
       " 2              nn.Conv2d          96               nn.Conv2d (bs=96)   \n",
       " 3  Baseline TritonConv2d         192  Baseline TritonConv2d (bs=192)   \n",
       " 4  Baseline TritonConv2d          96   Baseline TritonConv2d (bs=96)   \n",
       " 5  Baseline TritonConv2d         128  Baseline TritonConv2d (bs=128)   \n",
       " \n",
       "    avg_forward_ms  avg_backward_ms  avg_step_ms  samples_per_s  \\\n",
       " 0        7.778965         6.274370    14.053335    2353.629652   \n",
       " 1        8.038720         6.581922    14.620642    4572.664194   \n",
       " 2        8.269396         6.013748    14.283144    6799.590031   \n",
       " 3       40.830962        35.307957    76.138919    2529.765482   \n",
       " 4       41.662605        21.079979    62.742584    1538.861629   \n",
       " 5       42.343821        25.119656    67.463477    1904.794747   \n",
       " \n",
       "    max_mem_alloc_mb  max_mem_reserved_mb  \n",
       " 0        127.072266                138.0  \n",
       " 1        127.260254                138.0  \n",
       " 2        127.573730                144.0  \n",
       " 3        260.832031                328.0  \n",
       " 4        195.142090                238.0  \n",
       " 5        213.830078                312.0  ,\n",
       "                  variant  batch_size                          label  \\\n",
       " 0              nn.Conv2d          96              nn.Conv2d (bs=96)   \n",
       " 1              nn.Conv2d          32              nn.Conv2d (bs=32)   \n",
       " 2              nn.Conv2d         128             nn.Conv2d (bs=128)   \n",
       " 3  Baseline TritonConv2d          32  Baseline TritonConv2d (bs=32)   \n",
       " 4  Baseline TritonConv2d          64  Baseline TritonConv2d (bs=64)   \n",
       " 5  Baseline TritonConv2d          96  Baseline TritonConv2d (bs=96)   \n",
       " \n",
       "    avg_forward_ms  avg_backward_ms  avg_step_ms  samples_per_s  \\\n",
       " 0        8.269396         6.013748    14.283144    6799.590031   \n",
       " 1        7.778965         6.274370    14.053335    2353.629652   \n",
       " 2        9.351014         6.526245    15.877258    8238.250459   \n",
       " 3       45.730244        18.656490    64.386734     503.617131   \n",
       " 4       43.745434        18.876972    62.622406    1029.017290   \n",
       " 5       41.662605        21.079979    62.742584    1538.861629   \n",
       " \n",
       "    max_mem_alloc_mb  max_mem_reserved_mb  \n",
       " 0        127.573730                144.0  \n",
       " 1        127.072266                138.0  \n",
       " 2        132.817871                168.0  \n",
       " 3        154.655273                182.0  \n",
       " 4        169.953613                204.0  \n",
       " 5        195.142090                238.0  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_bs_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_forward_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "backward_bs_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_backward_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "forward_bs_top, backward_bs_top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f51d43",
   "metadata": {},
   "source": [
    "Per-layer metrics: forward/backward time and memory for each batch size and variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79bbdf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>in_channels</th>\n",
       "      <th>out_channels</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>stride</th>\n",
       "      <th>padding</th>\n",
       "      <th>dilation</th>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>throughput_sps</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>channel_keep_ratio</th>\n",
       "      <th>input_keep_ratio</th>\n",
       "      <th>block_size</th>\n",
       "      <th>grad_block_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.137830</td>\n",
       "      <td>0.625101</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>45026.716191</td>\n",
       "      <td>57.075684</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>1.727437</td>\n",
       "      <td>1.455002</td>\n",
       "      <td>3.182438</td>\n",
       "      <td>10089.058649</td>\n",
       "      <td>74.058594</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.197837</td>\n",
       "      <td>0.647936</td>\n",
       "      <td>0.845773</td>\n",
       "      <td>41442.751906</td>\n",
       "      <td>54.921387</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>2.420838</td>\n",
       "      <td>1.333709</td>\n",
       "      <td>3.754547</td>\n",
       "      <td>9043.330822</td>\n",
       "      <td>70.132812</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.608973</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>45770.083699</td>\n",
       "      <td>54.921387</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>1.783552</td>\n",
       "      <td>1.002085</td>\n",
       "      <td>2.785637</td>\n",
       "      <td>93776.683330</td>\n",
       "      <td>69.257812</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.277398</td>\n",
       "      <td>0.615270</td>\n",
       "      <td>0.892669</td>\n",
       "      <td>290090.643948</td>\n",
       "      <td>77.257324</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>1.790870</td>\n",
       "      <td>1.448704</td>\n",
       "      <td>3.239574</td>\n",
       "      <td>79458.781348</td>\n",
       "      <td>114.757812</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.619878</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>290782.575864</td>\n",
       "      <td>77.257324</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>1.953534</td>\n",
       "      <td>1.504051</td>\n",
       "      <td>3.457586</td>\n",
       "      <td>75538.523168</td>\n",
       "      <td>114.757812</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     layer    layer_type  in_channels  out_channels  \\\n",
       "0                    conv1        Conv2d            3            64   \n",
       "1                    conv1  TritonConv2d            3            64   \n",
       "2           layer1.0.conv1        Conv2d           64            64   \n",
       "3           layer1.0.conv1  TritonConv2d           64            64   \n",
       "4           layer1.0.conv2        Conv2d           64            64   \n",
       "..                     ...           ...          ...           ...   \n",
       "275  layer4.0.downsample.0  TritonConv2d          256           512   \n",
       "276         layer4.1.conv1        Conv2d          512           512   \n",
       "277         layer4.1.conv1  TritonConv2d          512           512   \n",
       "278         layer4.1.conv2        Conv2d          512           512   \n",
       "279         layer4.1.conv2  TritonConv2d          512           512   \n",
       "\n",
       "    kernel_size  stride padding dilation                variant  batch_size  \\\n",
       "0        (7, 7)  (2, 2)  (3, 3)   (1, 1)              nn.Conv2d          32   \n",
       "1        (7, 7)  (2, 2)  (3, 3)   (1, 1)  Baseline TritonConv2d          32   \n",
       "2        (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d          32   \n",
       "3        (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d          32   \n",
       "4        (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d          32   \n",
       "..          ...     ...     ...      ...                    ...         ...   \n",
       "275      (1, 1)  (2, 2)  (0, 0)   (1, 1)  Baseline TritonConv2d         256   \n",
       "276      (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d         256   \n",
       "277      (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d         256   \n",
       "278      (3, 3)  (1, 1)  (1, 1)   (1, 1)              nn.Conv2d         256   \n",
       "279      (3, 3)  (1, 1)  (1, 1)   (1, 1)  Baseline TritonConv2d         256   \n",
       "\n",
       "     avg_forward_ms  avg_backward_ms  avg_step_ms  throughput_sps  \\\n",
       "0          0.137830         0.625101     0.762931    45026.716191   \n",
       "1          1.727437         1.455002     3.182438    10089.058649   \n",
       "2          0.197837         0.647936     0.845773    41442.751906   \n",
       "3          2.420838         1.333709     3.754547     9043.330822   \n",
       "4          0.160666         0.608973     0.769638    45770.083699   \n",
       "..              ...              ...          ...             ...   \n",
       "275        1.783552         1.002085     2.785637    93776.683330   \n",
       "276        0.277398         0.615270     0.892669   290090.643948   \n",
       "277        1.790870         1.448704     3.239574    79458.781348   \n",
       "278        0.266803         0.619878     0.886682   290782.575864   \n",
       "279        1.953534         1.504051     3.457586    75538.523168   \n",
       "\n",
       "     max_mem_alloc_mb  max_mem_reserved_mb  channel_keep_ratio  \\\n",
       "0           57.075684                 68.0                 NaN   \n",
       "1           74.058594                 90.0                 1.0   \n",
       "2           54.921387                 68.0                 NaN   \n",
       "3           70.132812                 90.0                 1.0   \n",
       "4           54.921387                 90.0                 NaN   \n",
       "..                ...                  ...                 ...   \n",
       "275         69.257812                 82.0                 1.0   \n",
       "276         77.257324                102.0                 NaN   \n",
       "277        114.757812                142.0                 1.0   \n",
       "278         77.257324                142.0                 NaN   \n",
       "279        114.757812                142.0                 1.0   \n",
       "\n",
       "     input_keep_ratio  block_size  grad_block_size  \n",
       "0                 NaN         NaN              NaN  \n",
       "1                 1.0         NaN              NaN  \n",
       "2                 NaN         NaN              NaN  \n",
       "3                 1.0         NaN              NaN  \n",
       "4                 NaN         NaN              NaN  \n",
       "..                ...         ...              ...  \n",
       "275               1.0         NaN              NaN  \n",
       "276               NaN         NaN              NaN  \n",
       "277               1.0         NaN              NaN  \n",
       "278               NaN         NaN              NaN  \n",
       "279               1.0         NaN              NaN  \n",
       "\n",
       "[280 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_df = pd.DataFrame(conv_layer_rows)\n",
    "conv_layer_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef96d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>layer_type_torch</th>\n",
       "      <th>in_channels_torch</th>\n",
       "      <th>out_channels_torch</th>\n",
       "      <th>kernel_size_torch</th>\n",
       "      <th>stride_torch</th>\n",
       "      <th>padding_torch</th>\n",
       "      <th>dilation_torch</th>\n",
       "      <th>variant_torch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>block_size_baseline</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>0.429622</td>\n",
       "      <td>0.239732</td>\n",
       "      <td>0.224068</td>\n",
       "      <td>1.297551</td>\n",
       "      <td>1.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081722</td>\n",
       "      <td>0.485815</td>\n",
       "      <td>0.225266</td>\n",
       "      <td>0.218213</td>\n",
       "      <td>1.276967</td>\n",
       "      <td>1.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.085013</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.257949</td>\n",
       "      <td>0.242236</td>\n",
       "      <td>1.276967</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091507</td>\n",
       "      <td>0.434048</td>\n",
       "      <td>0.211179</td>\n",
       "      <td>0.218649</td>\n",
       "      <td>1.276967</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087876</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.194277</td>\n",
       "      <td>0.191248</td>\n",
       "      <td>1.276967</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103661</td>\n",
       "      <td>0.545160</td>\n",
       "      <td>0.259775</td>\n",
       "      <td>0.255342</td>\n",
       "      <td>1.284700</td>\n",
       "      <td>1.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.440092</td>\n",
       "      <td>0.272823</td>\n",
       "      <td>0.276642</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>0.479819</td>\n",
       "      <td>0.226478</td>\n",
       "      <td>0.221775</td>\n",
       "      <td>1.065385</td>\n",
       "      <td>1.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154896</td>\n",
       "      <td>0.424704</td>\n",
       "      <td>0.275551</td>\n",
       "      <td>0.273910</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.392157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136575</td>\n",
       "      <td>0.412139</td>\n",
       "      <td>0.256445</td>\n",
       "      <td>0.259777</td>\n",
       "      <td>1.485397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     layer layer_type_torch  in_channels_torch  \\\n",
       "0                    conv1           Conv2d                  3   \n",
       "1           layer1.0.conv1           Conv2d                 64   \n",
       "2           layer1.0.conv2           Conv2d                 64   \n",
       "3           layer1.1.conv1           Conv2d                 64   \n",
       "4           layer1.1.conv2           Conv2d                 64   \n",
       "..                     ...              ...                ...   \n",
       "135         layer4.0.conv1           Conv2d                256   \n",
       "136         layer4.0.conv2           Conv2d                512   \n",
       "137  layer4.0.downsample.0           Conv2d                256   \n",
       "138         layer4.1.conv1           Conv2d                512   \n",
       "139         layer4.1.conv2           Conv2d                512   \n",
       "\n",
       "     out_channels_torch kernel_size_torch stride_torch padding_torch  \\\n",
       "0                    64            (7, 7)       (2, 2)        (3, 3)   \n",
       "1                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "2                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "3                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "4                    64            (3, 3)       (1, 1)        (1, 1)   \n",
       "..                  ...               ...          ...           ...   \n",
       "135                 512            (3, 3)       (2, 2)        (1, 1)   \n",
       "136                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "137                 512            (1, 1)       (2, 2)        (0, 0)   \n",
       "138                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "139                 512            (3, 3)       (1, 1)        (1, 1)   \n",
       "\n",
       "    dilation_torch variant_torch  batch_size  ...  \\\n",
       "0           (1, 1)     nn.Conv2d          32  ...   \n",
       "1           (1, 1)     nn.Conv2d          32  ...   \n",
       "2           (1, 1)     nn.Conv2d          32  ...   \n",
       "3           (1, 1)     nn.Conv2d          32  ...   \n",
       "4           (1, 1)     nn.Conv2d          32  ...   \n",
       "..             ...           ...         ...  ...   \n",
       "135         (1, 1)     nn.Conv2d         256  ...   \n",
       "136         (1, 1)     nn.Conv2d         256  ...   \n",
       "137         (1, 1)     nn.Conv2d         256  ...   \n",
       "138         (1, 1)     nn.Conv2d         256  ...   \n",
       "139         (1, 1)     nn.Conv2d         256  ...   \n",
       "\n",
       "     channel_keep_ratio_baseline  input_keep_ratio_baseline  \\\n",
       "0                            1.0                        1.0   \n",
       "1                            1.0                        1.0   \n",
       "2                            1.0                        1.0   \n",
       "3                            1.0                        1.0   \n",
       "4                            1.0                        1.0   \n",
       "..                           ...                        ...   \n",
       "135                          1.0                        1.0   \n",
       "136                          1.0                        1.0   \n",
       "137                          1.0                        1.0   \n",
       "138                          1.0                        1.0   \n",
       "139                          1.0                        1.0   \n",
       "\n",
       "     block_size_baseline  grad_block_size_baseline  speedup_forward  \\\n",
       "0                    NaN                       NaN         0.079789   \n",
       "1                    NaN                       NaN         0.081722   \n",
       "2                    NaN                       NaN         0.085013   \n",
       "3                    NaN                       NaN         0.091507   \n",
       "4                    NaN                       NaN         0.087876   \n",
       "..                   ...                       ...              ...   \n",
       "135                  NaN                       NaN         0.103661   \n",
       "136                  NaN                       NaN         0.146154   \n",
       "137                  NaN                       NaN         0.084140   \n",
       "138                  NaN                       NaN         0.154896   \n",
       "139                  NaN                       NaN         0.136575   \n",
       "\n",
       "     speedup_backward  speedup_step  throughput_ratio  mem_alloc_ratio  \\\n",
       "0            0.429622      0.239732          0.224068         1.297551   \n",
       "1            0.485815      0.225266          0.218213         1.276967   \n",
       "2            0.556757      0.257949          0.242236         1.276967   \n",
       "3            0.434048      0.211179          0.218649         1.276967   \n",
       "4            0.356348      0.194277          0.191248         1.276967   \n",
       "..                ...           ...               ...              ...   \n",
       "135          0.545160      0.259775          0.255342         1.284700   \n",
       "136          0.440092      0.272823          0.276642         1.485397   \n",
       "137          0.479819      0.226478          0.221775         1.065385   \n",
       "138          0.424704      0.275551          0.273910         1.485397   \n",
       "139          0.412139      0.256445          0.259777         1.485397   \n",
       "\n",
       "     mem_reserved_ratio  \n",
       "0              1.323529  \n",
       "1              1.323529  \n",
       "2              1.000000  \n",
       "3              1.000000  \n",
       "4              1.000000  \n",
       "..                  ...  \n",
       "135            1.282051  \n",
       "136            1.408163  \n",
       "137            1.051282  \n",
       "138            1.392157  \n",
       "139            1.000000  \n",
       "\n",
       "[140 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_conv_df = conv_layer_df[conv_layer_df[\"variant\"] == \"nn.Conv2d\"]\n",
    "baseline_conv_df = conv_layer_df[conv_layer_df[\"variant\"] == \"Baseline TritonConv2d\"]\n",
    "\n",
    "conv_layer_compare_df = torch_conv_df.merge(\n",
    "    baseline_conv_df,\n",
    "    on=[\"layer\", \"batch_size\"],\n",
    "    suffixes=(\"_torch\", \"_baseline\"),\n",
    ")\n",
    "\n",
    "conv_layer_compare_df[\"speedup_forward\"] = conv_layer_compare_df[\"avg_forward_ms_torch\"] / conv_layer_compare_df[\"avg_forward_ms_baseline\"]\n",
    "conv_layer_compare_df[\"speedup_backward\"] = conv_layer_compare_df[\"avg_backward_ms_torch\"] / conv_layer_compare_df[\"avg_backward_ms_baseline\"]\n",
    "conv_layer_compare_df[\"speedup_step\"] = conv_layer_compare_df[\"avg_step_ms_torch\"] / conv_layer_compare_df[\"avg_step_ms_baseline\"]\n",
    "conv_layer_compare_df[\"throughput_ratio\"] = conv_layer_compare_df[\"throughput_sps_baseline\"] / conv_layer_compare_df[\"throughput_sps_torch\"]\n",
    "conv_layer_compare_df[\"mem_alloc_ratio\"] = conv_layer_compare_df[\"max_mem_alloc_mb_baseline\"] / conv_layer_compare_df[\"max_mem_alloc_mb_torch\"]\n",
    "conv_layer_compare_df[\"mem_reserved_ratio\"] = conv_layer_compare_df[\"max_mem_reserved_mb_baseline\"] / conv_layer_compare_df[\"max_mem_reserved_mb_torch\"]\n",
    "conv_layer_compare_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea76a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>kernel_size_torch</th>\n",
       "      <th>stride_torch</th>\n",
       "      <th>padding_torch</th>\n",
       "      <th>dilation_torch</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>block_size_baseline</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_backward_ms_torch</th>\n",
       "      <th>avg_backward_ms_baseline</th>\n",
       "      <th>avg_step_ms_torch</th>\n",
       "      <th>avg_step_ms_baseline</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layer3.0.downsample.0</td>\n",
       "      <td>96</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018408</td>\n",
       "      <td>1.554226</td>\n",
       "      <td>1.286645</td>\n",
       "      <td>3.819518</td>\n",
       "      <td>0.244453</td>\n",
       "      <td>0.118412</td>\n",
       "      <td>0.655251</td>\n",
       "      <td>0.336860</td>\n",
       "      <td>1.041670</td>\n",
       "      <td>1.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>1.164186</td>\n",
       "      <td>0.974746</td>\n",
       "      <td>3.010253</td>\n",
       "      <td>0.320859</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.610168</td>\n",
       "      <td>0.323809</td>\n",
       "      <td>1.366681</td>\n",
       "      <td>1.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer2.0.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>1.199565</td>\n",
       "      <td>1.005773</td>\n",
       "      <td>3.204506</td>\n",
       "      <td>0.291829</td>\n",
       "      <td>0.132307</td>\n",
       "      <td>0.617312</td>\n",
       "      <td>0.313862</td>\n",
       "      <td>1.095275</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>96</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636006</td>\n",
       "      <td>1.042944</td>\n",
       "      <td>0.874394</td>\n",
       "      <td>2.826803</td>\n",
       "      <td>0.289148</td>\n",
       "      <td>0.133636</td>\n",
       "      <td>0.609818</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>1.261351</td>\n",
       "      <td>1.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer2.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663757</td>\n",
       "      <td>1.089843</td>\n",
       "      <td>0.827085</td>\n",
       "      <td>2.734746</td>\n",
       "      <td>0.269417</td>\n",
       "      <td>0.099293</td>\n",
       "      <td>0.609039</td>\n",
       "      <td>0.302436</td>\n",
       "      <td>1.259493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672614</td>\n",
       "      <td>1.287987</td>\n",
       "      <td>0.974950</td>\n",
       "      <td>3.261133</td>\n",
       "      <td>0.298090</td>\n",
       "      <td>0.153225</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.298961</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617267</td>\n",
       "      <td>1.039155</td>\n",
       "      <td>0.805069</td>\n",
       "      <td>2.706739</td>\n",
       "      <td>0.280809</td>\n",
       "      <td>0.112619</td>\n",
       "      <td>0.594009</td>\n",
       "      <td>0.297431</td>\n",
       "      <td>1.128550</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.982170</td>\n",
       "      <td>0.811469</td>\n",
       "      <td>2.745037</td>\n",
       "      <td>0.295681</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.295613</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>layer2.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634098</td>\n",
       "      <td>1.049856</td>\n",
       "      <td>0.796813</td>\n",
       "      <td>2.724454</td>\n",
       "      <td>0.268399</td>\n",
       "      <td>0.097167</td>\n",
       "      <td>0.603985</td>\n",
       "      <td>0.292467</td>\n",
       "      <td>1.259493</td>\n",
       "      <td>1.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557926</td>\n",
       "      <td>1.016166</td>\n",
       "      <td>0.841062</td>\n",
       "      <td>2.879590</td>\n",
       "      <td>0.291464</td>\n",
       "      <td>0.151944</td>\n",
       "      <td>0.549050</td>\n",
       "      <td>0.292077</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706355</td>\n",
       "      <td>1.324032</td>\n",
       "      <td>0.884582</td>\n",
       "      <td>3.037747</td>\n",
       "      <td>0.262721</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.533488</td>\n",
       "      <td>0.291197</td>\n",
       "      <td>1.450585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558131</td>\n",
       "      <td>0.997069</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>2.865818</td>\n",
       "      <td>0.288463</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.559772</td>\n",
       "      <td>0.288050</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586701</td>\n",
       "      <td>1.139251</td>\n",
       "      <td>0.843520</td>\n",
       "      <td>2.954394</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>0.141487</td>\n",
       "      <td>0.514988</td>\n",
       "      <td>0.285514</td>\n",
       "      <td>1.366681</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634522</td>\n",
       "      <td>1.247795</td>\n",
       "      <td>0.925594</td>\n",
       "      <td>3.320013</td>\n",
       "      <td>0.281945</td>\n",
       "      <td>0.140464</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.278792</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544518</td>\n",
       "      <td>1.285734</td>\n",
       "      <td>0.802258</td>\n",
       "      <td>2.898278</td>\n",
       "      <td>0.277370</td>\n",
       "      <td>0.159834</td>\n",
       "      <td>0.423508</td>\n",
       "      <td>0.276805</td>\n",
       "      <td>1.421627</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    layer  batch_size kernel_size_torch stride_torch  \\\n",
       "0   layer3.0.downsample.0          96            (1, 1)       (2, 2)   \n",
       "1          layer4.1.conv1          32            (3, 3)       (1, 1)   \n",
       "2          layer2.0.conv1          32            (3, 3)       (2, 2)   \n",
       "3          layer3.1.conv1          96            (3, 3)       (1, 1)   \n",
       "4          layer2.1.conv2          64            (3, 3)       (1, 1)   \n",
       "5          layer4.1.conv2          96            (3, 3)       (1, 1)   \n",
       "6          layer3.0.conv1          64            (3, 3)       (2, 2)   \n",
       "7          layer4.0.conv2          64            (3, 3)       (1, 1)   \n",
       "8          layer2.0.conv2          64            (3, 3)       (1, 1)   \n",
       "9          layer4.1.conv2          64            (3, 3)       (1, 1)   \n",
       "10         layer1.1.conv1          64            (3, 3)       (1, 1)   \n",
       "11         layer4.1.conv1          64            (3, 3)       (1, 1)   \n",
       "12         layer4.1.conv2          32            (3, 3)       (1, 1)   \n",
       "13         layer4.0.conv2          96            (3, 3)       (1, 1)   \n",
       "14         layer4.0.conv2         160            (3, 3)       (1, 1)   \n",
       "\n",
       "   padding_torch dilation_torch  channel_keep_ratio_baseline  \\\n",
       "0         (0, 0)         (1, 1)                          1.0   \n",
       "1         (1, 1)         (1, 1)                          1.0   \n",
       "2         (1, 1)         (1, 1)                          1.0   \n",
       "3         (1, 1)         (1, 1)                          1.0   \n",
       "4         (1, 1)         (1, 1)                          1.0   \n",
       "5         (1, 1)         (1, 1)                          1.0   \n",
       "6         (1, 1)         (1, 1)                          1.0   \n",
       "7         (1, 1)         (1, 1)                          1.0   \n",
       "8         (1, 1)         (1, 1)                          1.0   \n",
       "9         (1, 1)         (1, 1)                          1.0   \n",
       "10        (1, 1)         (1, 1)                          1.0   \n",
       "11        (1, 1)         (1, 1)                          1.0   \n",
       "12        (1, 1)         (1, 1)                          1.0   \n",
       "13        (1, 1)         (1, 1)                          1.0   \n",
       "14        (1, 1)         (1, 1)                          1.0   \n",
       "\n",
       "    input_keep_ratio_baseline  block_size_baseline  grad_block_size_baseline  \\\n",
       "0                         1.0                  NaN                       NaN   \n",
       "1                         1.0                  NaN                       NaN   \n",
       "2                         1.0                  NaN                       NaN   \n",
       "3                         1.0                  NaN                       NaN   \n",
       "4                         1.0                  NaN                       NaN   \n",
       "5                         1.0                  NaN                       NaN   \n",
       "6                         1.0                  NaN                       NaN   \n",
       "7                         1.0                  NaN                       NaN   \n",
       "8                         1.0                  NaN                       NaN   \n",
       "9                         1.0                  NaN                       NaN   \n",
       "10                        1.0                  NaN                       NaN   \n",
       "11                        1.0                  NaN                       NaN   \n",
       "12                        1.0                  NaN                       NaN   \n",
       "13                        1.0                  NaN                       NaN   \n",
       "14                        1.0                  NaN                       NaN   \n",
       "\n",
       "    ...  avg_backward_ms_torch  avg_backward_ms_baseline  avg_step_ms_torch  \\\n",
       "0   ...               1.018408                  1.554226           1.286645   \n",
       "1   ...               0.710349                  1.164186           0.974746   \n",
       "2   ...               0.740506                  1.199565           1.005773   \n",
       "3   ...               0.636006                  1.042944           0.874394   \n",
       "4   ...               0.663757                  1.089843           0.827085   \n",
       "5   ...               0.672614                  1.287987           0.974950   \n",
       "6   ...               0.617267                  1.039155           0.805069   \n",
       "7   ...               0.560742                  0.982170           0.811469   \n",
       "8   ...               0.634098                  1.049856           0.796813   \n",
       "9   ...               0.557926                  1.016166           0.841062   \n",
       "10  ...               0.706355                  1.324032           0.884582   \n",
       "11  ...               0.558131                  0.997069           0.825498   \n",
       "12  ...               0.586701                  1.139251           0.843520   \n",
       "13  ...               0.634522                  1.247795           0.925594   \n",
       "14  ...               0.544518                  1.285734           0.802258   \n",
       "\n",
       "    avg_step_ms_baseline  throughput_ratio  speedup_forward  speedup_backward  \\\n",
       "0               3.819518          0.244453         0.118412          0.655251   \n",
       "1               3.010253          0.320859         0.143222          0.610168   \n",
       "2               3.204506          0.291829         0.132307          0.617312   \n",
       "3               2.826803          0.289148         0.133636          0.609818   \n",
       "4               2.734746          0.269417         0.099293          0.609039   \n",
       "5               3.261133          0.298090         0.153225          0.522221   \n",
       "6               2.706739          0.280809         0.112619          0.594009   \n",
       "7               2.745037          0.295681         0.142226          0.570922   \n",
       "8               2.724454          0.268399         0.097167          0.603985   \n",
       "9               2.879590          0.291464         0.151944          0.549050   \n",
       "10              3.037747          0.262721         0.104000          0.533488   \n",
       "11              2.865818          0.288463         0.143072          0.559772   \n",
       "12              2.954394          0.285038         0.141487          0.514988   \n",
       "13              3.320013          0.281945         0.140464          0.508514   \n",
       "14              2.898278          0.277370         0.159834          0.423508   \n",
       "\n",
       "    speedup_step  mem_alloc_ratio  mem_reserved_ratio  \n",
       "0       0.336860         1.041670            1.058824  \n",
       "1       0.323809         1.366681            1.227273  \n",
       "2       0.313862         1.095275            1.029412  \n",
       "3       0.309322         1.261351            1.277778  \n",
       "4       0.302436         1.259493            1.000000  \n",
       "5       0.298961         1.391945            1.000000  \n",
       "6       0.297431         1.128550            1.285714  \n",
       "7       0.295613         1.364370            1.232558  \n",
       "8       0.292467         1.259493            1.352941  \n",
       "9       0.292077         1.364370            1.000000  \n",
       "10      0.291197         1.450585            1.000000  \n",
       "11      0.288050         1.364370            1.222222  \n",
       "12      0.285514         1.366681            1.000000  \n",
       "13      0.278792         1.391945            1.255814  \n",
       "14      0.276805         1.421627            1.444444  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_ranking_df = conv_layer_compare_df[[\n",
    "    \"layer\",\n",
    "    \"batch_size\",\n",
    "    \"kernel_size_torch\",\n",
    "    \"stride_torch\",\n",
    "    \"padding_torch\",\n",
    "    \"dilation_torch\",\n",
    "    \"channel_keep_ratio_baseline\",\n",
    "    \"input_keep_ratio_baseline\",\n",
    "    \"block_size_baseline\",\n",
    "    \"grad_block_size_baseline\",\n",
    "    \"avg_forward_ms_torch\",\n",
    "    \"avg_forward_ms_baseline\",\n",
    "    \"avg_backward_ms_torch\",\n",
    "    \"avg_backward_ms_baseline\",\n",
    "    \"avg_step_ms_torch\",\n",
    "    \"avg_step_ms_baseline\",\n",
    "    \"throughput_ratio\",\n",
    "    \"speedup_forward\",\n",
    "    \"speedup_backward\",\n",
    "    \"speedup_step\",\n",
    "    \"mem_alloc_ratio\",\n",
    "    \"mem_reserved_ratio\",\n",
    "]].sort_values(\"speedup_step\", ascending=False).reset_index(drop=True)\n",
    "conv_layer_ranking_df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd2b6d",
   "metadata": {},
   "source": [
    "`baseline_vs_torch_df` сравнивает nn.Conv2d и Baseline TritonConv2d: пары столбцов с абсолютными значениями (forward/backward/step время, throughput, память) и коэффициенты ускорения (`speedup_*`, `throughput_ratio`, `mem_*_ratio`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2d81011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>torch_forward_ms</th>\n",
       "      <th>baseline_forward_ms</th>\n",
       "      <th>torch_backward_ms</th>\n",
       "      <th>baseline_backward_ms</th>\n",
       "      <th>torch_step_ms</th>\n",
       "      <th>baseline_step_ms</th>\n",
       "      <th>torch_samples_per_s</th>\n",
       "      <th>baseline_samples_per_s</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>torch_mem_alloc_mb</th>\n",
       "      <th>baseline_mem_alloc_mb</th>\n",
       "      <th>torch_mem_reserved_mb</th>\n",
       "      <th>baseline_mem_reserved_mb</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.778965</td>\n",
       "      <td>45.730244</td>\n",
       "      <td>6.274370</td>\n",
       "      <td>18.656490</td>\n",
       "      <td>14.053335</td>\n",
       "      <td>64.386734</td>\n",
       "      <td>2353.629652</td>\n",
       "      <td>503.617131</td>\n",
       "      <td>0.170105</td>\n",
       "      <td>0.336310</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.213975</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>138.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.217066</td>\n",
       "      <td>1.318841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8.038720</td>\n",
       "      <td>43.745434</td>\n",
       "      <td>6.581922</td>\n",
       "      <td>18.876972</td>\n",
       "      <td>14.620642</td>\n",
       "      <td>62.622406</td>\n",
       "      <td>4572.664194</td>\n",
       "      <td>1029.017290</td>\n",
       "      <td>0.183761</td>\n",
       "      <td>0.348675</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.225037</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>138.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.335481</td>\n",
       "      <td>1.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.269396</td>\n",
       "      <td>41.662605</td>\n",
       "      <td>6.013748</td>\n",
       "      <td>21.079979</td>\n",
       "      <td>14.283144</td>\n",
       "      <td>62.742584</td>\n",
       "      <td>6799.590031</td>\n",
       "      <td>1538.861629</td>\n",
       "      <td>0.198485</td>\n",
       "      <td>0.285282</td>\n",
       "      <td>0.227647</td>\n",
       "      <td>0.226317</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>144.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.529642</td>\n",
       "      <td>1.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9.351014</td>\n",
       "      <td>42.343821</td>\n",
       "      <td>6.526245</td>\n",
       "      <td>25.119656</td>\n",
       "      <td>15.877258</td>\n",
       "      <td>67.463477</td>\n",
       "      <td>8238.250459</td>\n",
       "      <td>1904.794747</td>\n",
       "      <td>0.220835</td>\n",
       "      <td>0.259806</td>\n",
       "      <td>0.235346</td>\n",
       "      <td>0.231214</td>\n",
       "      <td>132.817871</td>\n",
       "      <td>213.830078</td>\n",
       "      <td>168.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1.609950</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.560735</td>\n",
       "      <td>45.031539</td>\n",
       "      <td>7.603258</td>\n",
       "      <td>28.718870</td>\n",
       "      <td>17.163994</td>\n",
       "      <td>73.750409</td>\n",
       "      <td>9408.253630</td>\n",
       "      <td>2197.614342</td>\n",
       "      <td>0.212312</td>\n",
       "      <td>0.264748</td>\n",
       "      <td>0.232731</td>\n",
       "      <td>0.233584</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>162.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1.679484</td>\n",
       "      <td>1.753086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>8.512421</td>\n",
       "      <td>40.830962</td>\n",
       "      <td>8.360785</td>\n",
       "      <td>35.307957</td>\n",
       "      <td>16.873207</td>\n",
       "      <td>76.138919</td>\n",
       "      <td>11492.926501</td>\n",
       "      <td>2529.765482</td>\n",
       "      <td>0.208480</td>\n",
       "      <td>0.236796</td>\n",
       "      <td>0.221611</td>\n",
       "      <td>0.220115</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>160.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1.761548</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>9.572772</td>\n",
       "      <td>46.241049</td>\n",
       "      <td>10.040291</td>\n",
       "      <td>50.099462</td>\n",
       "      <td>19.613062</td>\n",
       "      <td>96.340511</td>\n",
       "      <td>13442.939432</td>\n",
       "      <td>2679.841985</td>\n",
       "      <td>0.207019</td>\n",
       "      <td>0.200407</td>\n",
       "      <td>0.203581</td>\n",
       "      <td>0.199349</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>196.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.851895</td>\n",
       "      <td>2.551020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            torch_forward_ms  baseline_forward_ms  torch_backward_ms  \\\n",
       "batch_size                                                             \n",
       "32                  7.778965            45.730244           6.274370   \n",
       "64                  8.038720            43.745434           6.581922   \n",
       "96                  8.269396            41.662605           6.013748   \n",
       "128                 9.351014            42.343821           6.526245   \n",
       "160                 9.560735            45.031539           7.603258   \n",
       "192                 8.512421            40.830962           8.360785   \n",
       "256                 9.572772            46.241049          10.040291   \n",
       "\n",
       "            baseline_backward_ms  torch_step_ms  baseline_step_ms  \\\n",
       "batch_size                                                          \n",
       "32                     18.656490      14.053335         64.386734   \n",
       "64                     18.876972      14.620642         62.622406   \n",
       "96                     21.079979      14.283144         62.742584   \n",
       "128                    25.119656      15.877258         67.463477   \n",
       "160                    28.718870      17.163994         73.750409   \n",
       "192                    35.307957      16.873207         76.138919   \n",
       "256                    50.099462      19.613062         96.340511   \n",
       "\n",
       "            torch_samples_per_s  baseline_samples_per_s  speedup_forward  \\\n",
       "batch_size                                                                 \n",
       "32                  2353.629652              503.617131         0.170105   \n",
       "64                  4572.664194             1029.017290         0.183761   \n",
       "96                  6799.590031             1538.861629         0.198485   \n",
       "128                 8238.250459             1904.794747         0.220835   \n",
       "160                 9408.253630             2197.614342         0.212312   \n",
       "192                11492.926501             2529.765482         0.208480   \n",
       "256                13442.939432             2679.841985         0.207019   \n",
       "\n",
       "            speedup_backward  speedup_step  throughput_ratio  \\\n",
       "batch_size                                                     \n",
       "32                  0.336310      0.218264          0.213975   \n",
       "64                  0.348675      0.233473          0.225037   \n",
       "96                  0.285282      0.227647          0.226317   \n",
       "128                 0.259806      0.235346          0.231214   \n",
       "160                 0.264748      0.232731          0.233584   \n",
       "192                 0.236796      0.221611          0.220115   \n",
       "256                 0.200407      0.203581          0.199349   \n",
       "\n",
       "            torch_mem_alloc_mb  baseline_mem_alloc_mb  torch_mem_reserved_mb  \\\n",
       "batch_size                                                                     \n",
       "32                  127.072266             154.655273                  138.0   \n",
       "64                  127.260254             169.953613                  138.0   \n",
       "96                  127.573730             195.142090                  144.0   \n",
       "128                 132.817871             213.830078                  168.0   \n",
       "160                 140.381836             235.769043                  162.0   \n",
       "192                 148.069824             260.832031                  160.0   \n",
       "256                 162.446289             300.833496                  196.0   \n",
       "\n",
       "            baseline_mem_reserved_mb  mem_alloc_ratio  mem_reserved_ratio  \n",
       "batch_size                                                                 \n",
       "32                             182.0         1.217066            1.318841  \n",
       "64                             204.0         1.335481            1.478261  \n",
       "96                             238.0         1.529642            1.652778  \n",
       "128                            312.0         1.609950            1.857143  \n",
       "160                            284.0         1.679484            1.753086  \n",
       "192                            328.0         1.761548            2.050000  \n",
       "256                            500.0         1.851895            2.551020  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_compare_rows = []\n",
    "for bs in config[\"batch_sizes\"]:\n",
    "    torch_row = summary_df.loc[(\"nn.Conv2d\", bs)]\n",
    "    baseline_row = summary_df.loc[(\"Baseline TritonConv2d\", bs)]\n",
    "    comparison = {\n",
    "        \"batch_size\": bs,\n",
    "        \"torch_forward_ms\": torch_row[\"avg_forward_ms\"],\n",
    "        \"baseline_forward_ms\": baseline_row[\"avg_forward_ms\"],\n",
    "        \"torch_backward_ms\": torch_row[\"avg_backward_ms\"],\n",
    "        \"baseline_backward_ms\": baseline_row[\"avg_backward_ms\"],\n",
    "        \"torch_step_ms\": torch_row[\"avg_step_ms\"],\n",
    "        \"baseline_step_ms\": baseline_row[\"avg_step_ms\"],\n",
    "        \"torch_samples_per_s\": torch_row[\"samples_per_s\"],\n",
    "        \"baseline_samples_per_s\": baseline_row[\"samples_per_s\"],\n",
    "        \"speedup_forward\": torch_row[\"avg_forward_ms\"] / baseline_row[\"avg_forward_ms\"],\n",
    "        \"speedup_backward\": torch_row[\"avg_backward_ms\"] / baseline_row[\"avg_backward_ms\"],\n",
    "        \"speedup_step\": torch_row[\"avg_step_ms\"] / baseline_row[\"avg_step_ms\"],\n",
    "        \"throughput_ratio\": baseline_row[\"samples_per_s\"] / torch_row[\"samples_per_s\"],\n",
    "        \"torch_mem_alloc_mb\": torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"baseline_mem_alloc_mb\": baseline_row[\"max_mem_alloc_mb\"],\n",
    "        \"torch_mem_reserved_mb\": torch_row[\"max_mem_reserved_mb\"],\n",
    "        \"baseline_mem_reserved_mb\": baseline_row[\"max_mem_reserved_mb\"],\n",
    "        \"mem_alloc_ratio\": baseline_row[\"max_mem_alloc_mb\"] / torch_row[\"max_mem_alloc_mb\"],\n",
    "        \"mem_reserved_ratio\": baseline_row[\"max_mem_reserved_mb\"] / torch_row[\"max_mem_reserved_mb\"],\n",
    "    }\n",
    "    baseline_compare_rows.append(comparison)\n",
    "\n",
    "baseline_vs_torch_df = pd.DataFrame(baseline_compare_rows).set_index(\"batch_size\")\n",
    "baseline_vs_torch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91f8b1",
   "metadata": {},
   "source": [
    "Таблица `summary_df` показывает средние метрики по каждому batch size: `avg_forward_ms`, `avg_backward_ms`, `avg_step_ms`, `samples_per_s`, а также пики памяти (`max_mem_alloc_mb`, `max_mem_reserved_mb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9fee49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>58.122840</td>\n",
       "      <td>24.471259</td>\n",
       "      <td>82.594099</td>\n",
       "      <td>1554.019946</td>\n",
       "      <td>214.039062</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Block sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>60.420029</td>\n",
       "      <td>27.095655</td>\n",
       "      <td>87.515684</td>\n",
       "      <td>1469.793185</td>\n",
       "      <td>214.513184</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Channel sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>62.082142</td>\n",
       "      <td>25.897778</td>\n",
       "      <td>87.979921</td>\n",
       "      <td>1468.674844</td>\n",
       "      <td>214.404297</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>62.456207</td>\n",
       "      <td>25.723875</td>\n",
       "      <td>88.180081</td>\n",
       "      <td>1466.526397</td>\n",
       "      <td>214.426270</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>60.679336</td>\n",
       "      <td>27.183104</td>\n",
       "      <td>87.862440</td>\n",
       "      <td>1465.291647</td>\n",
       "      <td>190.521484</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Input sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>60.569348</td>\n",
       "      <td>28.613808</td>\n",
       "      <td>89.183155</td>\n",
       "      <td>1446.018527</td>\n",
       "      <td>201.649414</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Channel sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>63.347620</td>\n",
       "      <td>27.655227</td>\n",
       "      <td>91.002846</td>\n",
       "      <td>1422.986126</td>\n",
       "      <td>214.039062</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Channel sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>63.753130</td>\n",
       "      <td>27.683518</td>\n",
       "      <td>91.436648</td>\n",
       "      <td>1408.948505</td>\n",
       "      <td>214.426270</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Input sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>64.828435</td>\n",
       "      <td>27.167012</td>\n",
       "      <td>91.995447</td>\n",
       "      <td>1402.890584</td>\n",
       "      <td>172.675293</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Channel sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>64.197925</td>\n",
       "      <td>29.116798</td>\n",
       "      <td>93.314724</td>\n",
       "      <td>1394.383639</td>\n",
       "      <td>214.482422</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Input sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>68.120581</td>\n",
       "      <td>27.982263</td>\n",
       "      <td>96.102843</td>\n",
       "      <td>1352.638373</td>\n",
       "      <td>194.496094</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Block sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>65.903150</td>\n",
       "      <td>29.955073</td>\n",
       "      <td>95.858223</td>\n",
       "      <td>1347.069712</td>\n",
       "      <td>214.404297</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label  avg_forward_ms  avg_backward_ms  \\\n",
       "0     Block sparsity (keep=0.50, bs=128)       58.122840        24.471259   \n",
       "1     Block sparsity (keep=0.60, bs=128)       60.420029        27.095655   \n",
       "2   Channel sparsity (keep=0.75, bs=128)       62.082142        25.897778   \n",
       "3     Block sparsity (keep=0.25, bs=128)       62.456207        25.723875   \n",
       "4     Input sparsity (keep=0.50, bs=128)       60.679336        27.183104   \n",
       "5     Input sparsity (keep=0.75, bs=128)       60.569348        28.613808   \n",
       "6   Channel sparsity (keep=0.50, bs=128)       63.347620        27.655227   \n",
       "7   Channel sparsity (keep=0.25, bs=128)       63.753130        27.683518   \n",
       "8     Input sparsity (keep=0.25, bs=128)       64.828435        27.167012   \n",
       "9   Channel sparsity (keep=0.60, bs=128)       64.197925        29.116798   \n",
       "10    Input sparsity (keep=0.60, bs=128)       68.120581        27.982263   \n",
       "11    Block sparsity (keep=0.75, bs=128)       65.903150        29.955073   \n",
       "\n",
       "    avg_step_ms  samples_per_s  max_mem_alloc_mb  max_mem_reserved_mb  \\\n",
       "0     82.594099    1554.019946        214.039062                506.0   \n",
       "1     87.515684    1469.793185        214.513184                506.0   \n",
       "2     87.979921    1468.674844        214.404297                506.0   \n",
       "3     88.180081    1466.526397        214.426270                506.0   \n",
       "4     87.862440    1465.291647        190.521484                506.0   \n",
       "5     89.183155    1446.018527        201.649414                506.0   \n",
       "6     91.002846    1422.986126        214.039062                506.0   \n",
       "7     91.436648    1408.948505        214.426270                506.0   \n",
       "8     91.995447    1402.890584        172.675293                506.0   \n",
       "9     93.314724    1394.383639        214.482422                506.0   \n",
       "10    96.102843    1352.638373        194.496094                506.0   \n",
       "11    95.858223    1347.069712        214.404297                506.0   \n",
       "\n",
       "              variant     mode  keep_ratio  batch_size  \n",
       "0     Sparsity::block    block        0.50         128  \n",
       "1     Sparsity::block    block        0.60         128  \n",
       "2   Sparsity::channel  channel        0.75         128  \n",
       "3     Sparsity::block    block        0.25         128  \n",
       "4     Sparsity::input    input        0.50         128  \n",
       "5     Sparsity::input    input        0.75         128  \n",
       "6   Sparsity::channel  channel        0.50         128  \n",
       "7   Sparsity::channel  channel        0.25         128  \n",
       "8     Sparsity::input    input        0.25         128  \n",
       "9   Sparsity::channel  channel        0.60         128  \n",
       "10    Sparsity::input    input        0.60         128  \n",
       "11    Sparsity::block    block        0.75         128  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_cfg = config[\"sparsity_bench\"]\n",
    "sparsity_bs = sparsity_cfg[\"batch_size\"]\n",
    "if sparsity_bs not in train_loaders:\n",
    "    train_loaders[sparsity_bs] = make_loader(sparsity_bs)\n",
    "sparsity_loader = train_loaders[sparsity_bs]\n",
    "\n",
    "sparsity_summaries = []\n",
    "sparsity_details = []\n",
    "\n",
    "for mode in sparsity_cfg[\"modes\"]:\n",
    "    for ratio in sparsity_cfg[\"keep_ratios\"]:\n",
    "        _, baseline_model = build_model_pair(config)\n",
    "        apply_sparsity_to_model(\n",
    "            baseline_model,\n",
    "            mode,\n",
    "            keep_ratio=ratio,\n",
    "            block_size=sparsity_cfg.get(\"block_size\", 4),\n",
    "        )\n",
    "        label = f\"{mode.capitalize()} sparsity (keep={ratio:.2f}, bs={sparsity_bs})\"\n",
    "        bench_df, bench_summary = run_benchmark(baseline_model, label, sparsity_loader, config)\n",
    "        bench_summary.update({\n",
    "            \"variant\": f\"Sparsity::{mode}\",\n",
    "            \"mode\": mode,\n",
    "            \"keep_ratio\": ratio,\n",
    "            \"batch_size\": sparsity_bs,\n",
    "        })\n",
    "        sparsity_summaries.append(bench_summary)\n",
    "        sparsity_details.append(\n",
    "            bench_df.assign(variant=f\"Sparsity::{mode}\", mode=mode, keep_ratio=ratio, batch_size=sparsity_bs)\n",
    "        )\n",
    "\n",
    "sparsity_summary_df = pd.DataFrame(sparsity_summaries).sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d37f9",
   "metadata": {},
   "source": [
    "`sparsity_compare_df` добавляет к тем же сценариям относительные значения относительно эталонного nn.Conv2d (`speedup_*_vs_torch`, `throughput_ratio_vs_torch`, `mem_*_ratio_vs_torch`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e7be95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>speedup_forward_vs_torch</th>\n",
       "      <th>speedup_backward_vs_torch</th>\n",
       "      <th>speedup_step_vs_torch</th>\n",
       "      <th>throughput_ratio_vs_torch</th>\n",
       "      <th>mem_alloc_ratio_vs_torch</th>\n",
       "      <th>mem_reserved_ratio_vs_torch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>58.122840</td>\n",
       "      <td>24.471259</td>\n",
       "      <td>82.594099</td>\n",
       "      <td>1554.019946</td>\n",
       "      <td>214.039062</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.160884</td>\n",
       "      <td>0.266690</td>\n",
       "      <td>0.192232</td>\n",
       "      <td>0.188635</td>\n",
       "      <td>1.611523</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Block sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>60.420029</td>\n",
       "      <td>27.095655</td>\n",
       "      <td>87.515684</td>\n",
       "      <td>1469.793185</td>\n",
       "      <td>214.513184</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>0.240859</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>0.178411</td>\n",
       "      <td>1.615093</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Channel sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>62.082142</td>\n",
       "      <td>25.897778</td>\n",
       "      <td>87.979921</td>\n",
       "      <td>1468.674844</td>\n",
       "      <td>214.404297</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.150623</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.180465</td>\n",
       "      <td>0.178275</td>\n",
       "      <td>1.614273</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>62.456207</td>\n",
       "      <td>25.723875</td>\n",
       "      <td>88.180081</td>\n",
       "      <td>1466.526397</td>\n",
       "      <td>214.426270</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.149721</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>0.180055</td>\n",
       "      <td>0.178014</td>\n",
       "      <td>1.614438</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>60.679336</td>\n",
       "      <td>27.183104</td>\n",
       "      <td>87.862440</td>\n",
       "      <td>1465.291647</td>\n",
       "      <td>190.521484</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.154105</td>\n",
       "      <td>0.240085</td>\n",
       "      <td>0.180706</td>\n",
       "      <td>0.177864</td>\n",
       "      <td>1.434457</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Input sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>60.569348</td>\n",
       "      <td>28.613808</td>\n",
       "      <td>89.183155</td>\n",
       "      <td>1446.018527</td>\n",
       "      <td>201.649414</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.154385</td>\n",
       "      <td>0.228080</td>\n",
       "      <td>0.178030</td>\n",
       "      <td>0.175525</td>\n",
       "      <td>1.518240</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Channel sparsity (keep=0.50, bs=128)</td>\n",
       "      <td>63.347620</td>\n",
       "      <td>27.655227</td>\n",
       "      <td>91.002846</td>\n",
       "      <td>1422.986126</td>\n",
       "      <td>214.039062</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.174470</td>\n",
       "      <td>0.172729</td>\n",
       "      <td>1.611523</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Channel sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>63.753130</td>\n",
       "      <td>27.683518</td>\n",
       "      <td>91.436648</td>\n",
       "      <td>1408.948505</td>\n",
       "      <td>214.426270</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.235745</td>\n",
       "      <td>0.173642</td>\n",
       "      <td>0.171025</td>\n",
       "      <td>1.614438</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Input sparsity (keep=0.25, bs=128)</td>\n",
       "      <td>64.828435</td>\n",
       "      <td>27.167012</td>\n",
       "      <td>91.995447</td>\n",
       "      <td>1402.890584</td>\n",
       "      <td>172.675293</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>0.240227</td>\n",
       "      <td>0.172587</td>\n",
       "      <td>0.170290</td>\n",
       "      <td>1.300091</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Channel sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>64.197925</td>\n",
       "      <td>29.116798</td>\n",
       "      <td>93.314724</td>\n",
       "      <td>1394.383639</td>\n",
       "      <td>214.482422</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.145659</td>\n",
       "      <td>0.224140</td>\n",
       "      <td>0.170147</td>\n",
       "      <td>0.169257</td>\n",
       "      <td>1.614861</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Input sparsity (keep=0.60, bs=128)</td>\n",
       "      <td>68.120581</td>\n",
       "      <td>27.982263</td>\n",
       "      <td>96.102843</td>\n",
       "      <td>1352.638373</td>\n",
       "      <td>194.496094</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>128</td>\n",
       "      <td>0.137271</td>\n",
       "      <td>0.233228</td>\n",
       "      <td>0.165211</td>\n",
       "      <td>0.164190</td>\n",
       "      <td>1.464382</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Block sparsity (keep=0.75, bs=128)</td>\n",
       "      <td>65.903150</td>\n",
       "      <td>29.955073</td>\n",
       "      <td>95.858223</td>\n",
       "      <td>1347.069712</td>\n",
       "      <td>214.404297</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>128</td>\n",
       "      <td>0.141890</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.165633</td>\n",
       "      <td>0.163514</td>\n",
       "      <td>1.614273</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label  avg_forward_ms  avg_backward_ms  \\\n",
       "0     Block sparsity (keep=0.50, bs=128)       58.122840        24.471259   \n",
       "1     Block sparsity (keep=0.60, bs=128)       60.420029        27.095655   \n",
       "2   Channel sparsity (keep=0.75, bs=128)       62.082142        25.897778   \n",
       "3     Block sparsity (keep=0.25, bs=128)       62.456207        25.723875   \n",
       "4     Input sparsity (keep=0.50, bs=128)       60.679336        27.183104   \n",
       "5     Input sparsity (keep=0.75, bs=128)       60.569348        28.613808   \n",
       "6   Channel sparsity (keep=0.50, bs=128)       63.347620        27.655227   \n",
       "7   Channel sparsity (keep=0.25, bs=128)       63.753130        27.683518   \n",
       "8     Input sparsity (keep=0.25, bs=128)       64.828435        27.167012   \n",
       "9   Channel sparsity (keep=0.60, bs=128)       64.197925        29.116798   \n",
       "10    Input sparsity (keep=0.60, bs=128)       68.120581        27.982263   \n",
       "11    Block sparsity (keep=0.75, bs=128)       65.903150        29.955073   \n",
       "\n",
       "    avg_step_ms  samples_per_s  max_mem_alloc_mb  max_mem_reserved_mb  \\\n",
       "0     82.594099    1554.019946        214.039062                506.0   \n",
       "1     87.515684    1469.793185        214.513184                506.0   \n",
       "2     87.979921    1468.674844        214.404297                506.0   \n",
       "3     88.180081    1466.526397        214.426270                506.0   \n",
       "4     87.862440    1465.291647        190.521484                506.0   \n",
       "5     89.183155    1446.018527        201.649414                506.0   \n",
       "6     91.002846    1422.986126        214.039062                506.0   \n",
       "7     91.436648    1408.948505        214.426270                506.0   \n",
       "8     91.995447    1402.890584        172.675293                506.0   \n",
       "9     93.314724    1394.383639        214.482422                506.0   \n",
       "10    96.102843    1352.638373        194.496094                506.0   \n",
       "11    95.858223    1347.069712        214.404297                506.0   \n",
       "\n",
       "              variant     mode  keep_ratio  batch_size  \\\n",
       "0     Sparsity::block    block        0.50         128   \n",
       "1     Sparsity::block    block        0.60         128   \n",
       "2   Sparsity::channel  channel        0.75         128   \n",
       "3     Sparsity::block    block        0.25         128   \n",
       "4     Sparsity::input    input        0.50         128   \n",
       "5     Sparsity::input    input        0.75         128   \n",
       "6   Sparsity::channel  channel        0.50         128   \n",
       "7   Sparsity::channel  channel        0.25         128   \n",
       "8     Sparsity::input    input        0.25         128   \n",
       "9   Sparsity::channel  channel        0.60         128   \n",
       "10    Sparsity::input    input        0.60         128   \n",
       "11    Sparsity::block    block        0.75         128   \n",
       "\n",
       "    speedup_forward_vs_torch  speedup_backward_vs_torch  \\\n",
       "0                   0.160884                   0.266690   \n",
       "1                   0.154767                   0.240859   \n",
       "2                   0.150623                   0.252000   \n",
       "3                   0.149721                   0.253704   \n",
       "4                   0.154105                   0.240085   \n",
       "5                   0.154385                   0.228080   \n",
       "6                   0.147614                   0.235986   \n",
       "7                   0.146675                   0.235745   \n",
       "8                   0.144242                   0.240227   \n",
       "9                   0.145659                   0.224140   \n",
       "10                  0.137271                   0.233228   \n",
       "11                  0.141890                   0.217868   \n",
       "\n",
       "    speedup_step_vs_torch  throughput_ratio_vs_torch  \\\n",
       "0                0.192232                   0.188635   \n",
       "1                0.181422                   0.178411   \n",
       "2                0.180465                   0.178275   \n",
       "3                0.180055                   0.178014   \n",
       "4                0.180706                   0.177864   \n",
       "5                0.178030                   0.175525   \n",
       "6                0.174470                   0.172729   \n",
       "7                0.173642                   0.171025   \n",
       "8                0.172587                   0.170290   \n",
       "9                0.170147                   0.169257   \n",
       "10               0.165211                   0.164190   \n",
       "11               0.165633                   0.163514   \n",
       "\n",
       "    mem_alloc_ratio_vs_torch  mem_reserved_ratio_vs_torch  \n",
       "0                   1.611523                     3.011905  \n",
       "1                   1.615093                     3.011905  \n",
       "2                   1.614273                     3.011905  \n",
       "3                   1.614438                     3.011905  \n",
       "4                   1.434457                     3.011905  \n",
       "5                   1.518240                     3.011905  \n",
       "6                   1.611523                     3.011905  \n",
       "7                   1.614438                     3.011905  \n",
       "8                   1.300091                     3.011905  \n",
       "9                   1.614861                     3.011905  \n",
       "10                  1.464382                     3.011905  \n",
       "11                  1.614273                     3.011905  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_reference = summary_df.loc[(\"nn.Conv2d\", sparsity_bs)]\n",
    "\n",
    "sparsity_compare_df = sparsity_summary_df.copy()\n",
    "sparsity_compare_df[\"speedup_forward_vs_torch\"] = sparsity_reference[\"avg_forward_ms\"] / sparsity_compare_df[\"avg_forward_ms\"]\n",
    "sparsity_compare_df[\"speedup_backward_vs_torch\"] = sparsity_reference[\"avg_backward_ms\"] / sparsity_compare_df[\"avg_backward_ms\"]\n",
    "sparsity_compare_df[\"speedup_step_vs_torch\"] = sparsity_reference[\"avg_step_ms\"] / sparsity_compare_df[\"avg_step_ms\"]\n",
    "sparsity_compare_df[\"throughput_ratio_vs_torch\"] = sparsity_compare_df[\"samples_per_s\"] / sparsity_reference[\"samples_per_s\"]\n",
    "sparsity_compare_df[\"mem_alloc_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_alloc_mb\"] / sparsity_reference[\"max_mem_alloc_mb\"]\n",
    "sparsity_compare_df[\"mem_reserved_ratio_vs_torch\"] = sparsity_compare_df[\"max_mem_reserved_mb\"] / sparsity_reference[\"max_mem_reserved_mb\"]\n",
    "sparsity_compare_df = sparsity_compare_df.sort_values(\"samples_per_s\", ascending=False).reset_index(drop=True)\n",
    "sparsity_compare_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c83ece",
   "metadata": {},
   "source": [
    "`ranking_df` — упорядоченный рейтинг сценариев спарсификации: показывает `mode`, `keep_ratio`, абсолютный throughput и его отношение к торчу, а также ускорения forward/backward/step и изменение памяти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba124c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>mode</th>\n",
       "      <th>keep_ratio</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>throughput_ratio_vs_torch</th>\n",
       "      <th>speedup_forward_vs_torch</th>\n",
       "      <th>speedup_backward_vs_torch</th>\n",
       "      <th>speedup_step_vs_torch</th>\n",
       "      <th>mem_alloc_ratio_vs_torch</th>\n",
       "      <th>mem_reserved_ratio_vs_torch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1554.019946</td>\n",
       "      <td>0.188635</td>\n",
       "      <td>0.160884</td>\n",
       "      <td>0.266690</td>\n",
       "      <td>0.192232</td>\n",
       "      <td>1.611523</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1469.793185</td>\n",
       "      <td>0.178411</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>0.240859</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>1.615093</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1468.674844</td>\n",
       "      <td>0.178275</td>\n",
       "      <td>0.150623</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.180465</td>\n",
       "      <td>1.614273</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1466.526397</td>\n",
       "      <td>0.178014</td>\n",
       "      <td>0.149721</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>0.180055</td>\n",
       "      <td>1.614438</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1465.291647</td>\n",
       "      <td>0.177864</td>\n",
       "      <td>0.154105</td>\n",
       "      <td>0.240085</td>\n",
       "      <td>0.180706</td>\n",
       "      <td>1.434457</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1446.018527</td>\n",
       "      <td>0.175525</td>\n",
       "      <td>0.154385</td>\n",
       "      <td>0.228080</td>\n",
       "      <td>0.178030</td>\n",
       "      <td>1.518240</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1422.986126</td>\n",
       "      <td>0.172729</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.174470</td>\n",
       "      <td>1.611523</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1408.948505</td>\n",
       "      <td>0.171025</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.235745</td>\n",
       "      <td>0.173642</td>\n",
       "      <td>1.614438</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1402.890584</td>\n",
       "      <td>0.170290</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>0.240227</td>\n",
       "      <td>0.172587</td>\n",
       "      <td>1.300091</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sparsity::channel</td>\n",
       "      <td>channel</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1394.383639</td>\n",
       "      <td>0.169257</td>\n",
       "      <td>0.145659</td>\n",
       "      <td>0.224140</td>\n",
       "      <td>0.170147</td>\n",
       "      <td>1.614861</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparsity::input</td>\n",
       "      <td>input</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1352.638373</td>\n",
       "      <td>0.164190</td>\n",
       "      <td>0.137271</td>\n",
       "      <td>0.233228</td>\n",
       "      <td>0.165211</td>\n",
       "      <td>1.464382</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparsity::block</td>\n",
       "      <td>block</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1347.069712</td>\n",
       "      <td>0.163514</td>\n",
       "      <td>0.141890</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.165633</td>\n",
       "      <td>1.614273</td>\n",
       "      <td>3.011905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variant     mode  keep_ratio  samples_per_s  \\\n",
       "0     Sparsity::block    block        0.50    1554.019946   \n",
       "1     Sparsity::block    block        0.60    1469.793185   \n",
       "2   Sparsity::channel  channel        0.75    1468.674844   \n",
       "3     Sparsity::block    block        0.25    1466.526397   \n",
       "4     Sparsity::input    input        0.50    1465.291647   \n",
       "5     Sparsity::input    input        0.75    1446.018527   \n",
       "6   Sparsity::channel  channel        0.50    1422.986126   \n",
       "7   Sparsity::channel  channel        0.25    1408.948505   \n",
       "8     Sparsity::input    input        0.25    1402.890584   \n",
       "9   Sparsity::channel  channel        0.60    1394.383639   \n",
       "10    Sparsity::input    input        0.60    1352.638373   \n",
       "11    Sparsity::block    block        0.75    1347.069712   \n",
       "\n",
       "    throughput_ratio_vs_torch  speedup_forward_vs_torch  \\\n",
       "0                    0.188635                  0.160884   \n",
       "1                    0.178411                  0.154767   \n",
       "2                    0.178275                  0.150623   \n",
       "3                    0.178014                  0.149721   \n",
       "4                    0.177864                  0.154105   \n",
       "5                    0.175525                  0.154385   \n",
       "6                    0.172729                  0.147614   \n",
       "7                    0.171025                  0.146675   \n",
       "8                    0.170290                  0.144242   \n",
       "9                    0.169257                  0.145659   \n",
       "10                   0.164190                  0.137271   \n",
       "11                   0.163514                  0.141890   \n",
       "\n",
       "    speedup_backward_vs_torch  speedup_step_vs_torch  \\\n",
       "0                    0.266690               0.192232   \n",
       "1                    0.240859               0.181422   \n",
       "2                    0.252000               0.180465   \n",
       "3                    0.253704               0.180055   \n",
       "4                    0.240085               0.180706   \n",
       "5                    0.228080               0.178030   \n",
       "6                    0.235986               0.174470   \n",
       "7                    0.235745               0.173642   \n",
       "8                    0.240227               0.172587   \n",
       "9                    0.224140               0.170147   \n",
       "10                   0.233228               0.165211   \n",
       "11                   0.217868               0.165633   \n",
       "\n",
       "    mem_alloc_ratio_vs_torch  mem_reserved_ratio_vs_torch  \n",
       "0                   1.611523                     3.011905  \n",
       "1                   1.615093                     3.011905  \n",
       "2                   1.614273                     3.011905  \n",
       "3                   1.614438                     3.011905  \n",
       "4                   1.434457                     3.011905  \n",
       "5                   1.518240                     3.011905  \n",
       "6                   1.611523                     3.011905  \n",
       "7                   1.614438                     3.011905  \n",
       "8                   1.300091                     3.011905  \n",
       "9                   1.614861                     3.011905  \n",
       "10                  1.464382                     3.011905  \n",
       "11                  1.614273                     3.011905  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_df = sparsity_compare_df[[\n",
    "    \"variant\",\n",
    "    \"mode\",\n",
    "    \"keep_ratio\",\n",
    "    \"samples_per_s\",\n",
    "    \"throughput_ratio_vs_torch\",\n",
    "    \"speedup_forward_vs_torch\",\n",
    "    \"speedup_backward_vs_torch\",\n",
    "    \"speedup_step_vs_torch\",\n",
    "    \"mem_alloc_ratio_vs_torch\",\n",
    "    \"mem_reserved_ratio_vs_torch\",\n",
    "]].copy()\n",
    "ranking_df = ranking_df.sort_values(\"throughput_ratio_vs_torch\", ascending=False).reset_index(drop=True)\n",
    "ranking_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915c106",
   "metadata": {},
   "source": [
    "Final rankings for model batch sizes and per-layer convs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bae397",
   "metadata": {},
   "source": [
    "Model batch-size rankings (step/throughput/memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30b30e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_step_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"avg_step_ms\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "model_throughput_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"samples_per_s\", ascending=False)\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "model_memory_top = (\n",
    "    summary_df.reset_index()\n",
    "    .sort_values(\"max_mem_alloc_mb\")\n",
    "    .groupby(\"variant\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4782383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>variant</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>avg_forward_ms</th>\n",
       "      <th>avg_backward_ms</th>\n",
       "      <th>avg_step_ms</th>\n",
       "      <th>samples_per_s</th>\n",
       "      <th>max_mem_alloc_mb</th>\n",
       "      <th>max_mem_reserved_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>7.778965</td>\n",
       "      <td>6.274370</td>\n",
       "      <td>14.053335</td>\n",
       "      <td>2353.629652</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>8.269396</td>\n",
       "      <td>6.013748</td>\n",
       "      <td>14.283144</td>\n",
       "      <td>6799.590031</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>8.038720</td>\n",
       "      <td>6.581922</td>\n",
       "      <td>14.620642</td>\n",
       "      <td>4572.664194</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>43.745434</td>\n",
       "      <td>18.876972</td>\n",
       "      <td>62.622406</td>\n",
       "      <td>1029.017290</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>41.662605</td>\n",
       "      <td>21.079979</td>\n",
       "      <td>62.742584</td>\n",
       "      <td>1538.861629</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fastest_step</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>45.730244</td>\n",
       "      <td>18.656490</td>\n",
       "      <td>64.386734</td>\n",
       "      <td>503.617131</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>9.572772</td>\n",
       "      <td>10.040291</td>\n",
       "      <td>19.613062</td>\n",
       "      <td>13442.939432</td>\n",
       "      <td>162.446289</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>192</td>\n",
       "      <td>8.512421</td>\n",
       "      <td>8.360785</td>\n",
       "      <td>16.873207</td>\n",
       "      <td>11492.926501</td>\n",
       "      <td>148.069824</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>160</td>\n",
       "      <td>9.560735</td>\n",
       "      <td>7.603258</td>\n",
       "      <td>17.163994</td>\n",
       "      <td>9408.253630</td>\n",
       "      <td>140.381836</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>256</td>\n",
       "      <td>46.241049</td>\n",
       "      <td>50.099462</td>\n",
       "      <td>96.340511</td>\n",
       "      <td>2679.841985</td>\n",
       "      <td>300.833496</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>192</td>\n",
       "      <td>40.830962</td>\n",
       "      <td>35.307957</td>\n",
       "      <td>76.138919</td>\n",
       "      <td>2529.765482</td>\n",
       "      <td>260.832031</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>highest_throughput</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>160</td>\n",
       "      <td>45.031539</td>\n",
       "      <td>28.718870</td>\n",
       "      <td>73.750409</td>\n",
       "      <td>2197.614342</td>\n",
       "      <td>235.769043</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>7.778965</td>\n",
       "      <td>6.274370</td>\n",
       "      <td>14.053335</td>\n",
       "      <td>2353.629652</td>\n",
       "      <td>127.072266</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>8.038720</td>\n",
       "      <td>6.581922</td>\n",
       "      <td>14.620642</td>\n",
       "      <td>4572.664194</td>\n",
       "      <td>127.260254</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>nn.Conv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>8.269396</td>\n",
       "      <td>6.013748</td>\n",
       "      <td>14.283144</td>\n",
       "      <td>6799.590031</td>\n",
       "      <td>127.573730</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>32</td>\n",
       "      <td>45.730244</td>\n",
       "      <td>18.656490</td>\n",
       "      <td>64.386734</td>\n",
       "      <td>503.617131</td>\n",
       "      <td>154.655273</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>64</td>\n",
       "      <td>43.745434</td>\n",
       "      <td>18.876972</td>\n",
       "      <td>62.622406</td>\n",
       "      <td>1029.017290</td>\n",
       "      <td>169.953613</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lowest_mem_alloc</td>\n",
       "      <td>Baseline TritonConv2d</td>\n",
       "      <td>96</td>\n",
       "      <td>41.662605</td>\n",
       "      <td>21.079979</td>\n",
       "      <td>62.742584</td>\n",
       "      <td>1538.861629</td>\n",
       "      <td>195.142090</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric                variant  batch_size  avg_forward_ms  \\\n",
       "0         fastest_step              nn.Conv2d          32        7.778965   \n",
       "1         fastest_step              nn.Conv2d          96        8.269396   \n",
       "2         fastest_step              nn.Conv2d          64        8.038720   \n",
       "3         fastest_step  Baseline TritonConv2d          64       43.745434   \n",
       "4         fastest_step  Baseline TritonConv2d          96       41.662605   \n",
       "5         fastest_step  Baseline TritonConv2d          32       45.730244   \n",
       "6   highest_throughput              nn.Conv2d         256        9.572772   \n",
       "7   highest_throughput              nn.Conv2d         192        8.512421   \n",
       "8   highest_throughput              nn.Conv2d         160        9.560735   \n",
       "9   highest_throughput  Baseline TritonConv2d         256       46.241049   \n",
       "10  highest_throughput  Baseline TritonConv2d         192       40.830962   \n",
       "11  highest_throughput  Baseline TritonConv2d         160       45.031539   \n",
       "12    lowest_mem_alloc              nn.Conv2d          32        7.778965   \n",
       "13    lowest_mem_alloc              nn.Conv2d          64        8.038720   \n",
       "14    lowest_mem_alloc              nn.Conv2d          96        8.269396   \n",
       "15    lowest_mem_alloc  Baseline TritonConv2d          32       45.730244   \n",
       "16    lowest_mem_alloc  Baseline TritonConv2d          64       43.745434   \n",
       "17    lowest_mem_alloc  Baseline TritonConv2d          96       41.662605   \n",
       "\n",
       "    avg_backward_ms  avg_step_ms  samples_per_s  max_mem_alloc_mb  \\\n",
       "0          6.274370    14.053335    2353.629652        127.072266   \n",
       "1          6.013748    14.283144    6799.590031        127.573730   \n",
       "2          6.581922    14.620642    4572.664194        127.260254   \n",
       "3         18.876972    62.622406    1029.017290        169.953613   \n",
       "4         21.079979    62.742584    1538.861629        195.142090   \n",
       "5         18.656490    64.386734     503.617131        154.655273   \n",
       "6         10.040291    19.613062   13442.939432        162.446289   \n",
       "7          8.360785    16.873207   11492.926501        148.069824   \n",
       "8          7.603258    17.163994    9408.253630        140.381836   \n",
       "9         50.099462    96.340511    2679.841985        300.833496   \n",
       "10        35.307957    76.138919    2529.765482        260.832031   \n",
       "11        28.718870    73.750409    2197.614342        235.769043   \n",
       "12         6.274370    14.053335    2353.629652        127.072266   \n",
       "13         6.581922    14.620642    4572.664194        127.260254   \n",
       "14         6.013748    14.283144    6799.590031        127.573730   \n",
       "15        18.656490    64.386734     503.617131        154.655273   \n",
       "16        18.876972    62.622406    1029.017290        169.953613   \n",
       "17        21.079979    62.742584    1538.861629        195.142090   \n",
       "\n",
       "    max_mem_reserved_mb  \n",
       "0                 138.0  \n",
       "1                 144.0  \n",
       "2                 138.0  \n",
       "3                 204.0  \n",
       "4                 238.0  \n",
       "5                 182.0  \n",
       "6                 196.0  \n",
       "7                 160.0  \n",
       "8                 162.0  \n",
       "9                 500.0  \n",
       "10                328.0  \n",
       "11                284.0  \n",
       "12                138.0  \n",
       "13                138.0  \n",
       "14                144.0  \n",
       "15                182.0  \n",
       "16                204.0  \n",
       "17                238.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rankings_df = pd.concat(\n",
    "    [\n",
    "        model_step_top.assign(metric=\"fastest_step\"),\n",
    "        model_throughput_top.assign(metric=\"highest_throughput\"),\n",
    "        model_memory_top.assign(metric=\"lowest_mem_alloc\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "model_rankings_df = model_rankings_df[[\n",
    "    \"metric\",\n",
    "    \"variant\",\n",
    "    \"batch_size\",\n",
    "    \"avg_forward_ms\",\n",
    "    \"avg_backward_ms\",\n",
    "    \"avg_step_ms\",\n",
    "    \"samples_per_s\",\n",
    "    \"max_mem_alloc_mb\",\n",
    "    \"max_mem_reserved_mb\",\n",
    "]]\n",
    "model_rankings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6a67c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>layer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layer_type_baseline</th>\n",
       "      <th>kernel_size_baseline</th>\n",
       "      <th>stride_baseline</th>\n",
       "      <th>padding_baseline</th>\n",
       "      <th>dilation_baseline</th>\n",
       "      <th>channel_keep_ratio_baseline</th>\n",
       "      <th>input_keep_ratio_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>grad_block_size_baseline</th>\n",
       "      <th>avg_forward_ms_baseline</th>\n",
       "      <th>avg_backward_ms_baseline</th>\n",
       "      <th>avg_step_ms_baseline</th>\n",
       "      <th>speedup_forward</th>\n",
       "      <th>speedup_backward</th>\n",
       "      <th>speedup_step</th>\n",
       "      <th>throughput_ratio</th>\n",
       "      <th>mem_alloc_ratio</th>\n",
       "      <th>mem_reserved_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.575014</td>\n",
       "      <td>1.020466</td>\n",
       "      <td>2.595480</td>\n",
       "      <td>0.125610</td>\n",
       "      <td>0.463853</td>\n",
       "      <td>0.258597</td>\n",
       "      <td>0.254855</td>\n",
       "      <td>1.236068</td>\n",
       "      <td>1.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.595597</td>\n",
       "      <td>1.034035</td>\n",
       "      <td>2.629632</td>\n",
       "      <td>0.112117</td>\n",
       "      <td>0.476036</td>\n",
       "      <td>0.255219</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.314286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.598261</td>\n",
       "      <td>1.326693</td>\n",
       "      <td>2.924954</td>\n",
       "      <td>0.157996</td>\n",
       "      <td>0.414635</td>\n",
       "      <td>0.274401</td>\n",
       "      <td>0.274209</td>\n",
       "      <td>1.438632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.608602</td>\n",
       "      <td>0.943414</td>\n",
       "      <td>2.552016</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.509982</td>\n",
       "      <td>0.263862</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>1.262721</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.612544</td>\n",
       "      <td>1.285734</td>\n",
       "      <td>2.898278</td>\n",
       "      <td>0.159834</td>\n",
       "      <td>0.423508</td>\n",
       "      <td>0.276805</td>\n",
       "      <td>0.277370</td>\n",
       "      <td>1.421627</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.630259</td>\n",
       "      <td>1.117392</td>\n",
       "      <td>2.747651</td>\n",
       "      <td>0.122892</td>\n",
       "      <td>0.448633</td>\n",
       "      <td>0.255362</td>\n",
       "      <td>0.254346</td>\n",
       "      <td>1.385012</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.631949</td>\n",
       "      <td>1.227008</td>\n",
       "      <td>2.858957</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>0.420113</td>\n",
       "      <td>0.250810</td>\n",
       "      <td>0.249756</td>\n",
       "      <td>1.423320</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.632819</td>\n",
       "      <td>0.980786</td>\n",
       "      <td>2.613605</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.483247</td>\n",
       "      <td>0.253453</td>\n",
       "      <td>0.249666</td>\n",
       "      <td>1.238774</td>\n",
       "      <td>1.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.637384</td>\n",
       "      <td>2.000333</td>\n",
       "      <td>3.637717</td>\n",
       "      <td>0.098311</td>\n",
       "      <td>0.234201</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>0.171005</td>\n",
       "      <td>1.904320</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>forward_time</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640090</td>\n",
       "      <td>1.037774</td>\n",
       "      <td>2.677864</td>\n",
       "      <td>0.105050</td>\n",
       "      <td>0.466574</td>\n",
       "      <td>0.245154</td>\n",
       "      <td>0.243783</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.653658</td>\n",
       "      <td>0.938434</td>\n",
       "      <td>2.592091</td>\n",
       "      <td>0.114806</td>\n",
       "      <td>0.529870</td>\n",
       "      <td>0.265075</td>\n",
       "      <td>0.258992</td>\n",
       "      <td>1.197596</td>\n",
       "      <td>1.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.608602</td>\n",
       "      <td>0.943414</td>\n",
       "      <td>2.552016</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.509982</td>\n",
       "      <td>0.263862</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>1.262721</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.673574</td>\n",
       "      <td>0.952218</td>\n",
       "      <td>2.625792</td>\n",
       "      <td>0.090403</td>\n",
       "      <td>0.443655</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>0.216794</td>\n",
       "      <td>1.105143</td>\n",
       "      <td>1.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.726003</td>\n",
       "      <td>0.960205</td>\n",
       "      <td>2.686208</td>\n",
       "      <td>0.086203</td>\n",
       "      <td>0.482840</td>\n",
       "      <td>0.227984</td>\n",
       "      <td>0.227677</td>\n",
       "      <td>1.132036</td>\n",
       "      <td>1.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.downsample.0</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.687042</td>\n",
       "      <td>0.960302</td>\n",
       "      <td>2.647344</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.435436</td>\n",
       "      <td>0.221405</td>\n",
       "      <td>0.221482</td>\n",
       "      <td>1.073033</td>\n",
       "      <td>1.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>192</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.632819</td>\n",
       "      <td>0.980786</td>\n",
       "      <td>2.613605</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.483247</td>\n",
       "      <td>0.253453</td>\n",
       "      <td>0.249666</td>\n",
       "      <td>1.238774</td>\n",
       "      <td>1.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.762867</td>\n",
       "      <td>0.982170</td>\n",
       "      <td>2.745037</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.295613</td>\n",
       "      <td>0.295681</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>128</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.726515</td>\n",
       "      <td>0.983093</td>\n",
       "      <td>2.709608</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.483464</td>\n",
       "      <td>0.239219</td>\n",
       "      <td>0.228523</td>\n",
       "      <td>1.046095</td>\n",
       "      <td>1.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.658624</td>\n",
       "      <td>0.983859</td>\n",
       "      <td>2.642483</td>\n",
       "      <td>0.115635</td>\n",
       "      <td>0.526181</td>\n",
       "      <td>0.268491</td>\n",
       "      <td>0.265963</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>backward_time</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.680435</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>2.668800</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>0.473322</td>\n",
       "      <td>0.242571</td>\n",
       "      <td>0.241396</td>\n",
       "      <td>1.204192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.0.downsample.0</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.265293</td>\n",
       "      <td>1.554226</td>\n",
       "      <td>3.819518</td>\n",
       "      <td>0.118412</td>\n",
       "      <td>0.655251</td>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.244453</td>\n",
       "      <td>1.041670</td>\n",
       "      <td>1.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.846067</td>\n",
       "      <td>1.164186</td>\n",
       "      <td>3.010253</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.610168</td>\n",
       "      <td>0.323809</td>\n",
       "      <td>0.320859</td>\n",
       "      <td>1.366681</td>\n",
       "      <td>1.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer2.0.conv1</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.004941</td>\n",
       "      <td>1.199565</td>\n",
       "      <td>3.204506</td>\n",
       "      <td>0.132307</td>\n",
       "      <td>0.617312</td>\n",
       "      <td>0.313862</td>\n",
       "      <td>0.291829</td>\n",
       "      <td>1.095275</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.783859</td>\n",
       "      <td>1.042944</td>\n",
       "      <td>2.826803</td>\n",
       "      <td>0.133636</td>\n",
       "      <td>0.609818</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.289148</td>\n",
       "      <td>1.261351</td>\n",
       "      <td>1.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer2.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.644902</td>\n",
       "      <td>1.089843</td>\n",
       "      <td>2.734746</td>\n",
       "      <td>0.099293</td>\n",
       "      <td>0.609039</td>\n",
       "      <td>0.302436</td>\n",
       "      <td>0.269417</td>\n",
       "      <td>1.259493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.973146</td>\n",
       "      <td>1.287987</td>\n",
       "      <td>3.261133</td>\n",
       "      <td>0.153225</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.298961</td>\n",
       "      <td>0.298090</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.667584</td>\n",
       "      <td>1.039155</td>\n",
       "      <td>2.706739</td>\n",
       "      <td>0.112619</td>\n",
       "      <td>0.594009</td>\n",
       "      <td>0.297431</td>\n",
       "      <td>0.280809</td>\n",
       "      <td>1.128550</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.762867</td>\n",
       "      <td>0.982170</td>\n",
       "      <td>2.745037</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.295613</td>\n",
       "      <td>0.295681</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer2.0.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.674598</td>\n",
       "      <td>1.049856</td>\n",
       "      <td>2.724454</td>\n",
       "      <td>0.097167</td>\n",
       "      <td>0.603985</td>\n",
       "      <td>0.292467</td>\n",
       "      <td>0.268399</td>\n",
       "      <td>1.259493</td>\n",
       "      <td>1.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.863424</td>\n",
       "      <td>1.016166</td>\n",
       "      <td>2.879590</td>\n",
       "      <td>0.151944</td>\n",
       "      <td>0.549050</td>\n",
       "      <td>0.292077</td>\n",
       "      <td>0.291464</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713715</td>\n",
       "      <td>1.324032</td>\n",
       "      <td>3.037747</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.533488</td>\n",
       "      <td>0.291197</td>\n",
       "      <td>0.262721</td>\n",
       "      <td>1.450585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>64</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.868749</td>\n",
       "      <td>0.997069</td>\n",
       "      <td>2.865818</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.559772</td>\n",
       "      <td>0.288050</td>\n",
       "      <td>0.288463</td>\n",
       "      <td>1.364370</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>32</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.815142</td>\n",
       "      <td>1.139251</td>\n",
       "      <td>2.954394</td>\n",
       "      <td>0.141487</td>\n",
       "      <td>0.514988</td>\n",
       "      <td>0.285514</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>1.366681</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>96</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.072218</td>\n",
       "      <td>1.247795</td>\n",
       "      <td>3.320013</td>\n",
       "      <td>0.140464</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.278792</td>\n",
       "      <td>0.281945</td>\n",
       "      <td>1.391945</td>\n",
       "      <td>1.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>speedup_step</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>160</td>\n",
       "      <td>TritonConv2d</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.612544</td>\n",
       "      <td>1.285734</td>\n",
       "      <td>2.898278</td>\n",
       "      <td>0.159834</td>\n",
       "      <td>0.423508</td>\n",
       "      <td>0.276805</td>\n",
       "      <td>0.277370</td>\n",
       "      <td>1.421627</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           metric                  layer  batch_size layer_type_baseline  \\\n",
       "0    forward_time         layer4.0.conv1         160        TritonConv2d   \n",
       "1    forward_time         layer3.0.conv2         128        TritonConv2d   \n",
       "2    forward_time         layer4.1.conv2         192        TritonConv2d   \n",
       "3    forward_time         layer4.0.conv1         192        TritonConv2d   \n",
       "4    forward_time         layer4.0.conv2         160        TritonConv2d   \n",
       "5    forward_time         layer3.0.conv2         160        TritonConv2d   \n",
       "6    forward_time         layer3.1.conv2         192        TritonConv2d   \n",
       "7    forward_time         layer3.0.conv1         192        TritonConv2d   \n",
       "8    forward_time         layer1.1.conv1         128        TritonConv2d   \n",
       "9    forward_time         layer3.1.conv1         128        TritonConv2d   \n",
       "10  backward_time         layer4.0.conv1          64        TritonConv2d   \n",
       "11  backward_time         layer4.0.conv1         192        TritonConv2d   \n",
       "12  backward_time  layer2.0.downsample.0         128        TritonConv2d   \n",
       "13  backward_time  layer2.0.downsample.0         192        TritonConv2d   \n",
       "14  backward_time  layer3.0.downsample.0         192        TritonConv2d   \n",
       "15  backward_time         layer3.0.conv1         192        TritonConv2d   \n",
       "16  backward_time         layer4.0.conv2          64        TritonConv2d   \n",
       "17  backward_time  layer4.0.downsample.0         128        TritonConv2d   \n",
       "18  backward_time         layer3.1.conv1          64        TritonConv2d   \n",
       "19  backward_time         layer3.1.conv2          64        TritonConv2d   \n",
       "20   speedup_step  layer3.0.downsample.0          96        TritonConv2d   \n",
       "21   speedup_step         layer4.1.conv1          32        TritonConv2d   \n",
       "22   speedup_step         layer2.0.conv1          32        TritonConv2d   \n",
       "23   speedup_step         layer3.1.conv1          96        TritonConv2d   \n",
       "24   speedup_step         layer2.1.conv2          64        TritonConv2d   \n",
       "25   speedup_step         layer4.1.conv2          96        TritonConv2d   \n",
       "26   speedup_step         layer3.0.conv1          64        TritonConv2d   \n",
       "27   speedup_step         layer4.0.conv2          64        TritonConv2d   \n",
       "28   speedup_step         layer2.0.conv2          64        TritonConv2d   \n",
       "29   speedup_step         layer4.1.conv2          64        TritonConv2d   \n",
       "30   speedup_step         layer1.1.conv1          64        TritonConv2d   \n",
       "31   speedup_step         layer4.1.conv1          64        TritonConv2d   \n",
       "32   speedup_step         layer4.1.conv2          32        TritonConv2d   \n",
       "33   speedup_step         layer4.0.conv2          96        TritonConv2d   \n",
       "34   speedup_step         layer4.0.conv2         160        TritonConv2d   \n",
       "\n",
       "   kernel_size_baseline stride_baseline padding_baseline dilation_baseline  \\\n",
       "0                (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "1                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "2                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "3                (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "4                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "5                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "6                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "7                (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "8                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "9                (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "10               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "11               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "12               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "13               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "14               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "15               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "16               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "17               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "18               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "19               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "20               (1, 1)          (2, 2)           (0, 0)            (1, 1)   \n",
       "21               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "22               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "23               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "24               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "25               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "26               (3, 3)          (2, 2)           (1, 1)            (1, 1)   \n",
       "27               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "28               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "29               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "30               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "31               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "32               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "33               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "34               (3, 3)          (1, 1)           (1, 1)            (1, 1)   \n",
       "\n",
       "    channel_keep_ratio_baseline  input_keep_ratio_baseline  ...  \\\n",
       "0                           1.0                        1.0  ...   \n",
       "1                           1.0                        1.0  ...   \n",
       "2                           1.0                        1.0  ...   \n",
       "3                           1.0                        1.0  ...   \n",
       "4                           1.0                        1.0  ...   \n",
       "5                           1.0                        1.0  ...   \n",
       "6                           1.0                        1.0  ...   \n",
       "7                           1.0                        1.0  ...   \n",
       "8                           1.0                        1.0  ...   \n",
       "9                           1.0                        1.0  ...   \n",
       "10                          1.0                        1.0  ...   \n",
       "11                          1.0                        1.0  ...   \n",
       "12                          1.0                        1.0  ...   \n",
       "13                          1.0                        1.0  ...   \n",
       "14                          1.0                        1.0  ...   \n",
       "15                          1.0                        1.0  ...   \n",
       "16                          1.0                        1.0  ...   \n",
       "17                          1.0                        1.0  ...   \n",
       "18                          1.0                        1.0  ...   \n",
       "19                          1.0                        1.0  ...   \n",
       "20                          1.0                        1.0  ...   \n",
       "21                          1.0                        1.0  ...   \n",
       "22                          1.0                        1.0  ...   \n",
       "23                          1.0                        1.0  ...   \n",
       "24                          1.0                        1.0  ...   \n",
       "25                          1.0                        1.0  ...   \n",
       "26                          1.0                        1.0  ...   \n",
       "27                          1.0                        1.0  ...   \n",
       "28                          1.0                        1.0  ...   \n",
       "29                          1.0                        1.0  ...   \n",
       "30                          1.0                        1.0  ...   \n",
       "31                          1.0                        1.0  ...   \n",
       "32                          1.0                        1.0  ...   \n",
       "33                          1.0                        1.0  ...   \n",
       "34                          1.0                        1.0  ...   \n",
       "\n",
       "    grad_block_size_baseline  avg_forward_ms_baseline  \\\n",
       "0                        NaN                 1.575014   \n",
       "1                        NaN                 1.595597   \n",
       "2                        NaN                 1.598261   \n",
       "3                        NaN                 1.608602   \n",
       "4                        NaN                 1.612544   \n",
       "5                        NaN                 1.630259   \n",
       "6                        NaN                 1.631949   \n",
       "7                        NaN                 1.632819   \n",
       "8                        NaN                 1.637384   \n",
       "9                        NaN                 1.640090   \n",
       "10                       NaN                 1.653658   \n",
       "11                       NaN                 1.608602   \n",
       "12                       NaN                 1.673574   \n",
       "13                       NaN                 1.726003   \n",
       "14                       NaN                 1.687042   \n",
       "15                       NaN                 1.632819   \n",
       "16                       NaN                 1.762867   \n",
       "17                       NaN                 1.726515   \n",
       "18                       NaN                 1.658624   \n",
       "19                       NaN                 1.680435   \n",
       "20                       NaN                 2.265293   \n",
       "21                       NaN                 1.846067   \n",
       "22                       NaN                 2.004941   \n",
       "23                       NaN                 1.783859   \n",
       "24                       NaN                 1.644902   \n",
       "25                       NaN                 1.973146   \n",
       "26                       NaN                 1.667584   \n",
       "27                       NaN                 1.762867   \n",
       "28                       NaN                 1.674598   \n",
       "29                       NaN                 1.863424   \n",
       "30                       NaN                 1.713715   \n",
       "31                       NaN                 1.868749   \n",
       "32                       NaN                 1.815142   \n",
       "33                       NaN                 2.072218   \n",
       "34                       NaN                 1.612544   \n",
       "\n",
       "    avg_backward_ms_baseline  avg_step_ms_baseline  speedup_forward  \\\n",
       "0                   1.020466              2.595480         0.125610   \n",
       "1                   1.034035              2.629632         0.112117   \n",
       "2                   1.326693              2.924954         0.157996   \n",
       "3                   0.943414              2.552016         0.119517   \n",
       "4                   1.285734              2.898278         0.159834   \n",
       "5                   1.117392              2.747651         0.122892   \n",
       "6                   1.227008              2.858957         0.123518   \n",
       "7                   0.980786              2.613605         0.115423   \n",
       "8                   2.000333              3.637717         0.098311   \n",
       "9                   1.037774              2.677864         0.105050   \n",
       "10                  0.938434              2.592091         0.114806   \n",
       "11                  0.943414              2.552016         0.119517   \n",
       "12                  0.952218              2.625792         0.090403   \n",
       "13                  0.960205              2.686208         0.086203   \n",
       "14                  0.960302              2.647344         0.099574   \n",
       "15                  0.980786              2.613605         0.115423   \n",
       "16                  0.982170              2.745037         0.142226   \n",
       "17                  0.983093              2.709608         0.100144   \n",
       "18                  0.983859              2.642483         0.115635   \n",
       "19                  0.988365              2.668800         0.106852   \n",
       "20                  1.554226              3.819518         0.118412   \n",
       "21                  1.164186              3.010253         0.143222   \n",
       "22                  1.199565              3.204506         0.132307   \n",
       "23                  1.042944              2.826803         0.133636   \n",
       "24                  1.089843              2.734746         0.099293   \n",
       "25                  1.287987              3.261133         0.153225   \n",
       "26                  1.039155              2.706739         0.112619   \n",
       "27                  0.982170              2.745037         0.142226   \n",
       "28                  1.049856              2.724454         0.097167   \n",
       "29                  1.016166              2.879590         0.151944   \n",
       "30                  1.324032              3.037747         0.104000   \n",
       "31                  0.997069              2.865818         0.143072   \n",
       "32                  1.139251              2.954394         0.141487   \n",
       "33                  1.247795              3.320013         0.140464   \n",
       "34                  1.285734              2.898278         0.159834   \n",
       "\n",
       "    speedup_backward  speedup_step  throughput_ratio  mem_alloc_ratio  \\\n",
       "0           0.463853      0.258597          0.254855         1.236068   \n",
       "1           0.476036      0.255219          0.254613         1.318840   \n",
       "2           0.414635      0.274401          0.274209         1.438632   \n",
       "3           0.509982      0.263862          0.262500         1.262721   \n",
       "4           0.423508      0.276805          0.277370         1.421627   \n",
       "5           0.448633      0.255362          0.254346         1.385012   \n",
       "6           0.420113      0.250810          0.249756         1.423320   \n",
       "7           0.483247      0.253453          0.249666         1.238774   \n",
       "8           0.234201      0.173035          0.171005         1.904320   \n",
       "9           0.466574      0.245154          0.243783         1.318840   \n",
       "10          0.529870      0.265075          0.258992         1.197596   \n",
       "11          0.509982      0.263862          0.262500         1.262721   \n",
       "12          0.443655      0.218506          0.216794         1.105143   \n",
       "13          0.482840      0.227984          0.227677         1.132036   \n",
       "14          0.435436      0.221405          0.221482         1.073033   \n",
       "15          0.483247      0.253453          0.249666         1.238774   \n",
       "16          0.570922      0.295613          0.295681         1.364370   \n",
       "17          0.483464      0.239219          0.228523         1.046095   \n",
       "18          0.526181      0.268491          0.265963         1.204192   \n",
       "19          0.473322      0.242571          0.241396         1.204192   \n",
       "20          0.655251      0.336860          0.244453         1.041670   \n",
       "21          0.610168      0.323809          0.320859         1.366681   \n",
       "22          0.617312      0.313862          0.291829         1.095275   \n",
       "23          0.609818      0.309322          0.289148         1.261351   \n",
       "24          0.609039      0.302436          0.269417         1.259493   \n",
       "25          0.522221      0.298961          0.298090         1.391945   \n",
       "26          0.594009      0.297431          0.280809         1.128550   \n",
       "27          0.570922      0.295613          0.295681         1.364370   \n",
       "28          0.603985      0.292467          0.268399         1.259493   \n",
       "29          0.549050      0.292077          0.291464         1.364370   \n",
       "30          0.533488      0.291197          0.262721         1.450585   \n",
       "31          0.559772      0.288050          0.288463         1.364370   \n",
       "32          0.514988      0.285514          0.285038         1.366681   \n",
       "33          0.508514      0.278792          0.281945         1.391945   \n",
       "34          0.423508      0.276805          0.277370         1.421627   \n",
       "\n",
       "    mem_reserved_ratio  \n",
       "0             1.022222  \n",
       "1             1.314286  \n",
       "2             1.000000  \n",
       "3             1.255814  \n",
       "4             1.444444  \n",
       "5             1.600000  \n",
       "6             1.000000  \n",
       "7             1.022727  \n",
       "8             1.000000  \n",
       "9             1.270270  \n",
       "10            1.023256  \n",
       "11            1.255814  \n",
       "12            1.055556  \n",
       "13            1.025000  \n",
       "14            1.046512  \n",
       "15            1.022727  \n",
       "16            1.232558  \n",
       "17            1.028571  \n",
       "18            1.285714  \n",
       "19            1.000000  \n",
       "20            1.058824  \n",
       "21            1.227273  \n",
       "22            1.029412  \n",
       "23            1.277778  \n",
       "24            1.000000  \n",
       "25            1.000000  \n",
       "26            1.285714  \n",
       "27            1.232558  \n",
       "28            1.352941  \n",
       "29            1.000000  \n",
       "30            1.000000  \n",
       "31            1.222222  \n",
       "32            1.000000  \n",
       "33            1.255814  \n",
       "34            1.444444  \n",
       "\n",
       "[35 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_forward_top = conv_layer_compare_df.sort_values(\"avg_forward_ms_baseline\").head(10).assign(metric=\"forward_time\")\n",
    "conv_backward_top = conv_layer_compare_df.sort_values(\"avg_backward_ms_baseline\").head(10).assign(metric=\"backward_time\")\n",
    "conv_speedup_top = conv_layer_compare_df.sort_values(\"speedup_step\", ascending=False).head(15).assign(metric=\"speedup_step\")\n",
    "\n",
    "conv_layer_best_df = pd.concat(\n",
    "    [conv_forward_top, conv_backward_top, conv_speedup_top],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "conv_layer_best_df = conv_layer_best_df[[\n",
    "    \"metric\",\n",
    "    \"layer\",\n",
    "    \"batch_size\",\n",
    "    \"layer_type_baseline\",\n",
    "    \"kernel_size_baseline\",\n",
    "    \"stride_baseline\",\n",
    "    \"padding_baseline\",\n",
    "    \"dilation_baseline\",\n",
    "    \"channel_keep_ratio_baseline\",\n",
    "    \"input_keep_ratio_baseline\",\n",
    "    \"block_size_baseline\",\n",
    "    \"grad_block_size_baseline\",\n",
    "    \"avg_forward_ms_baseline\",\n",
    "    \"avg_backward_ms_baseline\",\n",
    "    \"avg_step_ms_baseline\",\n",
    "    \"speedup_forward\",\n",
    "    \"speedup_backward\",\n",
    "    \"speedup_step\",\n",
    "    \"throughput_ratio\",\n",
    "    \"mem_alloc_ratio\",\n",
    "    \"mem_reserved_ratio\",\n",
    "]]\n",
    "conv_layer_best_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746abfae-4258-4fc7-b243-5a9fcee9d35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
