{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee6c425-96da-45ff-8378-0979c5b65e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768509b8-a5cc-4971-bbb8-c0ab27e3da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from conv_gemm.triton_kernels.int8.col2img_int8_kernel import col2img_int32_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8304dfe-9faf-49da-80d0-f2dec1b8ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2img_int32(\n",
    "    cols_i32: torch.Tensor,\n",
    "    N: int, Cin: int,\n",
    "    H: int, W: int,\n",
    "    Kh: int, Kw: int,\n",
    "    Sh: int, Sw: int,\n",
    "    Ph: int, Pw: int,\n",
    "    Dh: int, Dw: int,\n",
    "    BLOCK_M: int,\n",
    "    BLOCK_K: int,\n",
    "    num_warps: int = 4,\n",
    "    num_stages: int = 2,\n",
    "):\n",
    "\n",
    "    assert cols_i32.is_cuda\n",
    "    assert cols_i32.dtype == torch.int32\n",
    "    cols_i32 = cols_i32.contiguous()\n",
    "\n",
    "    Ho = (H + 2 * Ph - Dh * (Kh - 1) - 1) // Sh + 1\n",
    "    Wo = (W + 2 * Pw - Dw * (Kw - 1) - 1) // Sw + 1\n",
    "    M = N * Ho * Wo\n",
    "    K = Cin * Kh * Kw\n",
    "\n",
    "    assert cols_i32.shape == (M, K), f\"cols shape {cols_i32.shape}, expected {(M, K)}\"\n",
    "\n",
    "    x_i32 = torch.zeros((N, Cin, H, W), device=cols_i32.device, dtype=torch.int32)\n",
    "    sN, sC, sH, sW = x_i32.stride()\n",
    "\n",
    "    grid = (triton.cdiv(M, BLOCK_M), triton.cdiv(K, BLOCK_K))\n",
    "\n",
    "    col2img_int32_kernel[grid](\n",
    "        cols_i32, x_i32,\n",
    "        N, Cin, H, W,\n",
    "        Kh, Kw, Sh, Sw, Ph, Pw, Dh, Dw,\n",
    "        Ho, Wo,\n",
    "        sN, sC, sH, sW,\n",
    "        K,\n",
    "        BLOCK_M=BLOCK_M,\n",
    "        BLOCK_K=BLOCK_K,\n",
    "        num_warps=num_warps,\n",
    "        num_stages=num_stages,\n",
    "    )\n",
    "    return x_i32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d397bef-38a2-4113-bb10-53e3815e5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bench_once_col2img_int32_vs_fold(\n",
    "    N, Cin, H, W,\n",
    "    Kh, Kw,\n",
    "    Sh, Sw,\n",
    "    Ph, Pw,\n",
    "    Dh, Dw,\n",
    "    BLOCK_M,\n",
    "    BLOCK_K,\n",
    "    num_warps,\n",
    "    num_stages,\n",
    "    iters=100,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "\n",
    "    Ho = (H + 2 * Ph - Dh * (Kh - 1) - 1) // Sh + 1\n",
    "    Wo = (W + 2 * Pw - Dw * (Kw - 1) - 1) // Sw + 1\n",
    "    assert Ho > 0 and Wo > 0, f\"Invalid Ho,Wo = {(Ho, Wo)}\"\n",
    "\n",
    "    M = N * Ho * Wo\n",
    "    K = Cin * Kh * Kw\n",
    "\n",
    "    cols_i32 = torch.randint(\n",
    "        low=-128, high=127,\n",
    "        size=(M, K),\n",
    "        device=device,\n",
    "        dtype=torch.int32,\n",
    "    )\n",
    "\n",
    "    # Torch  F.fold \n",
    "    cols_f = cols_i32.float()\n",
    "    cols_fold = cols_f.view(N, Ho * Wo, K).permute(0, 2, 1).contiguous()  # [N, K, L]\n",
    "\n",
    "    def _call_torch():\n",
    "        return F.fold(\n",
    "            cols_fold,\n",
    "            output_size=(H, W),\n",
    "            kernel_size=(Kh, Kw),\n",
    "            dilation=(Dh, Dw),\n",
    "            padding=(Ph, Pw),\n",
    "            stride=(Sh, Sw),\n",
    "        )  \n",
    "\n",
    "\n",
    "    for _ in range(5):\n",
    "        x_ref = _call_torch()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        x_ref = _call_torch()\n",
    "    torch.cuda.synchronize()\n",
    "    t_torch = (time.perf_counter() - t0) / iters\n",
    "\n",
    "    # Triton\n",
    "    def _call_triton():\n",
    "        x_i32 = col2img_int32(\n",
    "            cols_i32,\n",
    "            N, Cin,\n",
    "            H, W,\n",
    "            Kh, Kw,\n",
    "            Sh, Sw,\n",
    "            Ph, Pw,\n",
    "            Dh, Dw,\n",
    "            BLOCK_M=BLOCK_M,\n",
    "            BLOCK_K=BLOCK_K,\n",
    "            num_warps=num_warps,\n",
    "            num_stages=num_stages,\n",
    "        )\n",
    "        return x_i32\n",
    "\n",
    "\n",
    "    for _ in range(5):\n",
    "        x_i32 = _call_triton()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        x_i32 = _call_triton()\n",
    "    torch.cuda.synchronize()\n",
    "    t_triton = (time.perf_counter() - t0) / iters\n",
    "\n",
    "\n",
    "    # bandwidth \n",
    "    bytes_moved = (cols_i32.numel() + x_i32.numel()) * 4.0  # int32\n",
    "    bw_triton = bytes_moved / t_triton / 1e9\n",
    "    bw_torch  = bytes_moved / t_torch  / 1e9\n",
    "\n",
    "    return {\n",
    "        \"N\": N,\n",
    "        \"Cin\": Cin,\n",
    "        \"H\": H,\n",
    "        \"W\": W,\n",
    "        \"Kh\": Kh,\n",
    "        \"Kw\": Kw,\n",
    "        \"M\": M,\n",
    "        \"K\": K,\n",
    "        \"BLOCK_M\": BLOCK_M,\n",
    "        \"BLOCK_N\": 0,  \n",
    "        \"BLOCK_K\": BLOCK_K,\n",
    "        \"num_warps\": num_warps,\n",
    "        \"num_stages\": num_stages,\n",
    "        \"t_triton_ms\": t_triton * 1e3,\n",
    "        \"t_torch_ms\": t_torch * 1e3,\n",
    "        \"speed_vs_torch\": t_torch / t_triton,\n",
    "        \"bw_triton_GBs\": bw_triton,\n",
    "        \"bw_torch_GBs\": bw_torch,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0563971c-96cb-4d86-91d7-9b4d9441e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def tune_col2img_int32_tiles_for_shape(\n",
    "    N, Cin, H, W,\n",
    "    Kh, Kw,\n",
    "    Sh, Sw,\n",
    "    Ph, Pw,\n",
    "    Dh, Dw,\n",
    "    blocks_M=(32, 64, 128),\n",
    "    blocks_K=(32, 64, 128),\n",
    "    warps=(1, 2, 4, 8),\n",
    "    stages=(2, 3, 4),\n",
    "    iters=200,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    records = []\n",
    "    for BM in blocks_M:\n",
    "        for BK in blocks_K:\n",
    "            for Wp in warps:\n",
    "                for S in stages:\n",
    "                    try:\n",
    "                        rec = bench_once_col2img_int32_vs_fold(\n",
    "                            N, Cin, H, W,\n",
    "                            Kh, Kw,\n",
    "                            Sh, Sw,\n",
    "                            Ph, Pw,\n",
    "                            Dh, Dw,\n",
    "                            BLOCK_M=BM,\n",
    "                            BLOCK_K=BK,\n",
    "                            num_warps=Wp,\n",
    "                            num_stages=S,\n",
    "                            iters=iters,\n",
    "                            device=device,\n",
    "                        )\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"[SKIP] BM={BM}, BK={BK}, W={Wp}, S={S}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    print(\n",
    "                        f\"BM={BM}, BK={BK}, W={Wp}, S={S}: \"\n",
    "                        f\"t_triton={rec['t_triton_ms']:.3f} ms, \"\n",
    "                        f\"speed_vs_torch={rec['speed_vs_torch']:.3f}x, \"\n",
    "                    )\n",
    "                    records.append(rec)\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No valid tile configs found for this COL2IMG shape\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca61364-4a50-4bdc-83f8-13ea6f9d7657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM=32, BK=32, W=2, S=2: t_triton=4.030 ms, speed_vs_torch=0.849x, \n",
      "BM=32, BK=32, W=2, S=3: t_triton=2.787 ms, speed_vs_torch=1.334x, \n",
      "BM=32, BK=32, W=4, S=2: t_triton=1.659 ms, speed_vs_torch=1.425x, \n",
      "BM=32, BK=32, W=4, S=3: t_triton=1.681 ms, speed_vs_torch=1.404x, \n",
      "BM=32, BK=32, W=8, S=2: t_triton=1.774 ms, speed_vs_torch=1.328x, \n",
      "BM=32, BK=32, W=8, S=3: t_triton=1.764 ms, speed_vs_torch=1.337x, \n",
      "BM=32, BK=64, W=2, S=2: t_triton=5.503 ms, speed_vs_torch=0.429x, \n",
      "BM=32, BK=64, W=2, S=3: t_triton=4.812 ms, speed_vs_torch=0.490x, \n",
      "BM=32, BK=64, W=4, S=2: t_triton=2.085 ms, speed_vs_torch=1.163x, \n",
      "BM=32, BK=64, W=4, S=3: t_triton=2.021 ms, speed_vs_torch=1.195x, \n",
      "BM=32, BK=64, W=8, S=2: t_triton=1.699 ms, speed_vs_torch=1.388x, \n",
      "BM=32, BK=64, W=8, S=3: t_triton=2.357 ms, speed_vs_torch=1.007x, \n",
      "BM=32, BK=128, W=2, S=2: t_triton=7.052 ms, speed_vs_torch=0.336x, \n",
      "BM=32, BK=128, W=2, S=3: t_triton=7.635 ms, speed_vs_torch=0.308x, \n",
      "BM=32, BK=128, W=4, S=2: t_triton=8.896 ms, speed_vs_torch=0.375x, \n",
      "BM=32, BK=128, W=4, S=3: t_triton=8.315 ms, speed_vs_torch=0.532x, \n",
      "BM=32, BK=128, W=8, S=2: t_triton=3.576 ms, speed_vs_torch=1.234x, \n",
      "BM=32, BK=128, W=8, S=3: t_triton=2.788 ms, speed_vs_torch=1.026x, \n",
      "BM=64, BK=32, W=2, S=2: t_triton=4.827 ms, speed_vs_torch=0.486x, \n",
      "BM=64, BK=32, W=2, S=3: t_triton=4.834 ms, speed_vs_torch=0.485x, \n",
      "BM=64, BK=32, W=4, S=2: t_triton=2.197 ms, speed_vs_torch=1.070x, \n",
      "BM=64, BK=32, W=4, S=3: t_triton=2.070 ms, speed_vs_torch=1.131x, \n",
      "BM=64, BK=32, W=8, S=2: t_triton=1.711 ms, speed_vs_torch=1.389x, \n",
      "BM=64, BK=32, W=8, S=3: t_triton=1.685 ms, speed_vs_torch=1.769x, \n",
      "BM=64, BK=64, W=2, S=2: t_triton=7.945 ms, speed_vs_torch=0.298x, \n",
      "BM=64, BK=64, W=2, S=3: t_triton=12.384 ms, speed_vs_torch=0.379x, \n",
      "BM=64, BK=64, W=4, S=2: t_triton=9.481 ms, speed_vs_torch=0.492x, \n",
      "BM=64, BK=64, W=4, S=3: t_triton=9.548 ms, speed_vs_torch=0.485x, \n",
      "BM=64, BK=64, W=8, S=2: t_triton=4.175 ms, speed_vs_torch=1.107x, \n",
      "BM=64, BK=64, W=8, S=3: t_triton=3.347 ms, speed_vs_torch=1.408x, \n",
      "BM=64, BK=128, W=2, S=2: t_triton=24.886 ms, speed_vs_torch=0.095x, \n",
      "BM=64, BK=128, W=2, S=3: t_triton=24.962 ms, speed_vs_torch=0.094x, \n",
      "BM=64, BK=128, W=4, S=2: t_triton=5.721 ms, speed_vs_torch=0.412x, \n",
      "BM=64, BK=128, W=4, S=3: t_triton=5.739 ms, speed_vs_torch=0.410x, \n",
      "BM=64, BK=128, W=8, S=2: t_triton=5.423 ms, speed_vs_torch=0.434x, \n",
      "BM=64, BK=128, W=8, S=3: t_triton=5.421 ms, speed_vs_torch=0.433x, \n",
      "BM=128, BK=32, W=2, S=2: t_triton=4.978 ms, speed_vs_torch=0.478x, \n",
      "BM=128, BK=32, W=2, S=3: t_triton=4.866 ms, speed_vs_torch=0.496x, \n",
      "BM=128, BK=32, W=4, S=2: t_triton=4.796 ms, speed_vs_torch=0.491x, \n",
      "BM=128, BK=32, W=4, S=3: t_triton=4.848 ms, speed_vs_torch=0.499x, \n",
      "BM=128, BK=32, W=8, S=2: t_triton=2.225 ms, speed_vs_torch=1.059x, \n",
      "BM=128, BK=32, W=8, S=3: t_triton=2.233 ms, speed_vs_torch=1.054x, \n",
      "BM=128, BK=64, W=2, S=2: t_triton=18.260 ms, speed_vs_torch=0.129x, \n",
      "BM=128, BK=64, W=2, S=3: t_triton=18.333 ms, speed_vs_torch=0.128x, \n",
      "BM=128, BK=64, W=4, S=2: t_triton=6.592 ms, speed_vs_torch=0.357x, \n",
      "BM=128, BK=64, W=4, S=3: t_triton=6.587 ms, speed_vs_torch=0.357x, \n",
      "BM=128, BK=64, W=8, S=2: t_triton=5.379 ms, speed_vs_torch=0.438x, \n",
      "BM=128, BK=64, W=8, S=3: t_triton=5.319 ms, speed_vs_torch=0.443x, \n",
      "BM=128, BK=128, W=2, S=2: t_triton=33.980 ms, speed_vs_torch=0.069x, \n",
      "BM=128, BK=128, W=2, S=3: t_triton=34.498 ms, speed_vs_torch=0.068x, \n",
      "BM=128, BK=128, W=4, S=2: t_triton=57.108 ms, speed_vs_torch=0.041x, \n",
      "BM=128, BK=128, W=4, S=3: t_triton=56.955 ms, speed_vs_torch=0.042x, \n",
      "BM=128, BK=128, W=8, S=2: t_triton=6.077 ms, speed_vs_torch=0.389x, \n",
      "BM=128, BK=128, W=8, S=3: t_triton=6.225 ms, speed_vs_torch=0.378x, \n"
     ]
    }
   ],
   "source": [
    "df_c2i = tune_col2img_int32_tiles_for_shape(\n",
    "    N=16, Cin=1, H=256, W=256,\n",
    "    Kh=11, Kw=11,\n",
    "    Sh=1, Sw=1,\n",
    "    Ph=5, Pw=5,\n",
    "    Dh=1, Dw=1,\n",
    "    blocks_M=(32, 64, 128),\n",
    "    blocks_K=(32, 64, 128),\n",
    "    warps=(2, 4, 8),\n",
    "    stages=(2, 3),\n",
    "    iters=200,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c91b33-6ec1-4fdb-b83c-32b8c38f9d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Cin</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>Kh</th>\n",
       "      <th>Kw</th>\n",
       "      <th>M</th>\n",
       "      <th>K</th>\n",
       "      <th>BLOCK_M</th>\n",
       "      <th>BLOCK_N</th>\n",
       "      <th>BLOCK_K</th>\n",
       "      <th>num_warps</th>\n",
       "      <th>num_stages</th>\n",
       "      <th>t_triton_ms</th>\n",
       "      <th>t_torch_ms</th>\n",
       "      <th>speed_vs_torch</th>\n",
       "      <th>bw_triton_GBs</th>\n",
       "      <th>bw_torch_GBs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.659329</td>\n",
       "      <td>2.364605</td>\n",
       "      <td>1.425037</td>\n",
       "      <td>308.380712</td>\n",
       "      <td>216.401904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.680546</td>\n",
       "      <td>2.359115</td>\n",
       "      <td>1.403779</td>\n",
       "      <td>304.487482</td>\n",
       "      <td>216.905575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.684777</td>\n",
       "      <td>2.980211</td>\n",
       "      <td>1.768906</td>\n",
       "      <td>303.722782</td>\n",
       "      <td>171.700947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.699415</td>\n",
       "      <td>2.359619</td>\n",
       "      <td>1.388489</td>\n",
       "      <td>301.106570</td>\n",
       "      <td>216.859196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.711444</td>\n",
       "      <td>2.376568</td>\n",
       "      <td>1.388633</td>\n",
       "      <td>298.990304</td>\n",
       "      <td>215.312651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.763631</td>\n",
       "      <td>2.357735</td>\n",
       "      <td>1.336865</td>\n",
       "      <td>290.142992</td>\n",
       "      <td>217.032448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.773947</td>\n",
       "      <td>2.355675</td>\n",
       "      <td>1.327929</td>\n",
       "      <td>288.455699</td>\n",
       "      <td>217.222263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.020703</td>\n",
       "      <td>2.413804</td>\n",
       "      <td>1.194537</td>\n",
       "      <td>253.231202</td>\n",
       "      <td>211.991140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.070018</td>\n",
       "      <td>2.341170</td>\n",
       "      <td>1.130990</td>\n",
       "      <td>247.198326</td>\n",
       "      <td>218.568101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1048576</td>\n",
       "      <td>121</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.085397</td>\n",
       "      <td>2.425691</td>\n",
       "      <td>1.163179</td>\n",
       "      <td>245.375338</td>\n",
       "      <td>210.952311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     N  Cin    H    W  Kh  Kw        M    K  BLOCK_M  BLOCK_N  BLOCK_K  \\\n",
       "2   16    1  256  256  11  11  1048576  121       32        0       32   \n",
       "3   16    1  256  256  11  11  1048576  121       32        0       32   \n",
       "23  16    1  256  256  11  11  1048576  121       64        0       32   \n",
       "10  16    1  256  256  11  11  1048576  121       32        0       64   \n",
       "22  16    1  256  256  11  11  1048576  121       64        0       32   \n",
       "5   16    1  256  256  11  11  1048576  121       32        0       32   \n",
       "4   16    1  256  256  11  11  1048576  121       32        0       32   \n",
       "9   16    1  256  256  11  11  1048576  121       32        0       64   \n",
       "21  16    1  256  256  11  11  1048576  121       64        0       32   \n",
       "8   16    1  256  256  11  11  1048576  121       32        0       64   \n",
       "\n",
       "    num_warps  num_stages  t_triton_ms  t_torch_ms  speed_vs_torch  \\\n",
       "2           4           2     1.659329    2.364605        1.425037   \n",
       "3           4           3     1.680546    2.359115        1.403779   \n",
       "23          8           3     1.684777    2.980211        1.768906   \n",
       "10          8           2     1.699415    2.359619        1.388489   \n",
       "22          8           2     1.711444    2.376568        1.388633   \n",
       "5           8           3     1.763631    2.357735        1.336865   \n",
       "4           8           2     1.773947    2.355675        1.327929   \n",
       "9           4           3     2.020703    2.413804        1.194537   \n",
       "21          4           3     2.070018    2.341170        1.130990   \n",
       "8           4           2     2.085397    2.425691        1.163179   \n",
       "\n",
       "    bw_triton_GBs  bw_torch_GBs  \n",
       "2      308.380712    216.401904  \n",
       "3      304.487482    216.905575  \n",
       "23     303.722782    171.700947  \n",
       "10     301.106570    216.859196  \n",
       "22     298.990304    215.312651  \n",
       "5      290.142992    217.032448  \n",
       "4      288.455699    217.222263  \n",
       "9      253.231202    211.991140  \n",
       "21     247.198326    218.568101  \n",
       "8      245.375338    210.952311  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c2i.sort_values(\"t_triton_ms\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57d71c89-ee9e-4a86-bfdf-cd411833f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT8_COL2IMG_BEST_BLOCK_M = 32\n",
    "INT8_COL2IMG_BEST_BLOCK_N = 0\n",
    "INT8_COL2IMG_BEST_BLOCK_K = 32\n",
    "INT8_COL2IMG_BEST_WARPS = 4\n",
    "INT8_COL2IMG_BEST_STAGES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5ff74-6ce3-4620-8692-87f621706a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
