{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2544b4-e605-40a5-b5b0-6e9150e9266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd19731-11bd-4717-8cf0-d63c086bed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from conv_gemm.triton_kernels.int8.gemm_int8_kernel import gemm_int8_tc_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d9441b-f60b-4973-87ab-3f824eb054c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemm_int8_tc(\n",
    "    A_q: torch.Tensor,   \n",
    "    B_q: torch.Tensor,  \n",
    "    *,\n",
    "    BLOCK_M: int = 64,\n",
    "    BLOCK_N: int = 64,\n",
    "    BLOCK_K: int = 32,\n",
    "    num_warps: int = 4,\n",
    "    num_stages: int = 2,\n",
    "):\n",
    "    if not A_q.is_contiguous():\n",
    "        A_q = A_q.contiguous()\n",
    "    if not B_q.is_contiguous():\n",
    "        B_q = B_q.contiguous()\n",
    "\n",
    "    M, K1 = A_q.shape\n",
    "    K2, N = B_q.shape\n",
    "    assert K1 == K2, f\"K mismatch: {K1} vs {K2}\"\n",
    "\n",
    "    assert K1 % 4 == 0, f\"K={K1} must be divisible by 4 for INT8 dot\"\n",
    "    assert BLOCK_K % 4 == 0, f\"BLOCK_K={BLOCK_K} must be divisible by 4\"\n",
    "\n",
    "    C_i32 = torch.empty((M, N), dtype=torch.int32, device=A_q.device)\n",
    "\n",
    "    a_m, a_k = A_q.stride()\n",
    "    b_k, b_n = B_q.stride()\n",
    "    c_m, c_n = C_i32.stride()\n",
    "\n",
    "    grid = (\n",
    "        triton.cdiv(M, BLOCK_M),\n",
    "        triton.cdiv(N, BLOCK_N),\n",
    "    )\n",
    "\n",
    "    gemm_int8_tc_kernel[grid](\n",
    "        A_q, B_q, C_i32,\n",
    "        M, N, K1,\n",
    "        a_m, a_k,\n",
    "        b_k, b_n,\n",
    "        c_m, c_n,\n",
    "        BLOCK_M=BLOCK_M,\n",
    "        BLOCK_N=BLOCK_N,\n",
    "        BLOCK_K=BLOCK_K,\n",
    "        num_warps=num_warps,\n",
    "        num_stages=num_stages,\n",
    "    )\n",
    "\n",
    "    return C_i32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cceb33-ae6a-41c3-af13-4b6c12f62f2c",
   "metadata": {},
   "source": [
    "# title search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24134f7-47f2-4d16-b951-2fb19db1f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bench_once_gemm_int8_vs_torch(\n",
    "    M, K, N,\n",
    "    BLOCK_M,\n",
    "    BLOCK_N,\n",
    "    BLOCK_K,\n",
    "    num_warps,\n",
    "    num_stages,\n",
    "    iters=100,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    INT8 Triton GEMM vs torch FP16 matmul\n",
    "    \"\"\"\n",
    "    A_q = torch.randint(-128, 127, (M, K), device=device, dtype=torch.int8)\n",
    "    B_q = torch.randint(-128, 127, (K, N), device=device, dtype=torch.int8)\n",
    "\n",
    "    # FP16 baseline\n",
    "    A_f16 = A_q.to(torch.float16)\n",
    "    B_f16 = B_q.to(torch.float16)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        C_ref = (A_f16 @ B_f16).float() \n",
    "\n",
    "    def _call_triton():\n",
    "        C_i32 = gemm_int8_tc(\n",
    "            A_q, B_q,\n",
    "            BLOCK_M=BLOCK_M,\n",
    "            BLOCK_N=BLOCK_N,\n",
    "            BLOCK_K=BLOCK_K,\n",
    "            num_warps=num_warps,\n",
    "            num_stages=num_stages,\n",
    "        )\n",
    "        return C_i32\n",
    "        \n",
    "    # triton matmul int8\n",
    "    for _ in range(5):\n",
    "        _ = _call_triton()\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        C_i32 = _call_triton()\n",
    "    torch.cuda.synchronize()\n",
    "    t_triton = (time.perf_counter() - t0) / iters\n",
    "\n",
    "    # torch matmul FP16\n",
    "    def _call_torch():\n",
    "        return A_f16 @ B_f16\n",
    "    for _ in range(5):\n",
    "        _ = _call_torch()\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        C_ref2 = _call_torch()\n",
    "    torch.cuda.synchronize()\n",
    "    t_torch = (time.perf_counter() - t0) / iters\n",
    "\n",
    "    # bandwidth\n",
    "    bytes_moved = A_q.numel() + B_q.numel()      \n",
    "    bytes_moved += C_i32.numel() * 4            \n",
    "    bytes_moved = float(bytes_moved)\n",
    "\n",
    "    bw_triton = bytes_moved / t_triton / 1e9\n",
    "    bw_torch  = bytes_moved / t_torch  / 1e9\n",
    "\n",
    "    return {\n",
    "        \"M\": M, \"K\": K, \"N\": N,\n",
    "        \"BLOCK_M\": BLOCK_M,\n",
    "        \"BLOCK_N\": BLOCK_N,\n",
    "        \"BLOCK_K\": BLOCK_K,\n",
    "        \"num_warps\": num_warps,\n",
    "        \"num_stages\": num_stages,\n",
    "        \"t_triton_ms\": t_triton * 1e3,\n",
    "        \"t_torch_ms\": t_torch * 1e3,\n",
    "        \"speed_vs_torch\": t_torch / t_triton,\n",
    "        \"bw_triton_GBs\": bw_triton,\n",
    "        \"bw_torch_GBs\": bw_torch,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e230b854-ec14-467d-a3c6-d55a1937a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def tune_gemm_int8_tiles_for_shape(\n",
    "    M, K, N,\n",
    "    blocks_M=(32, 64, 128),\n",
    "    blocks_N=(32, 64, 128),\n",
    "    blocks_K=(32, 64, 128),\n",
    "    warps=(1, 2, 4, 8),\n",
    "    stages=(2, 3,4),\n",
    "    iters=200,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    records = []\n",
    "    for BM in blocks_M:\n",
    "        for BN in blocks_N:\n",
    "            for BK in blocks_K:\n",
    "                if (K % 4 != 0) or (BK % 4 != 0):\n",
    "                    print(f\"[SKIP] BM={BM}, BN={BN}, BK={BK}: K/BK not multiple of 4\")\n",
    "                    continue\n",
    "\n",
    "                for W in warps:\n",
    "                    for S in stages:\n",
    "                        try:\n",
    "                            rec = bench_once_gemm_int8_vs_torch(\n",
    "                                M, K, N,\n",
    "                                BLOCK_M=BM,\n",
    "                                BLOCK_N=BN,\n",
    "                                BLOCK_K=BK,\n",
    "                                num_warps=W,\n",
    "                                num_stages=S,\n",
    "                                iters=iters,\n",
    "                                device=device,\n",
    "                            )\n",
    "                        except RuntimeError as e:\n",
    "                            print(f\"[SKIP] BM={BM}, BN={BN}, BK={BK}, W={W}, S={S}: {e}\")\n",
    "                            continue\n",
    "\n",
    "                        print(\n",
    "                            f\"BM={BM}, BN={BN}, BK={BK}, W={W}, S={S}: \"\n",
    "                            f\"t_triton={rec['t_triton_ms']:.3f} ms, \"\n",
    "                            f\"speed_vs_torch={rec['speed_vs_torch']:.3f}x, \"\n",
    "                        )\n",
    "                        records.append(rec)\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"No valid tile configs found for this GEMM shape\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c363e02-f7c4-4911-a6da-ed7305f15f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM=32, BN=32, BK=32, W=2, S=2: t_triton=0.241 ms, speed_vs_torch=0.961x, \n",
      "BM=32, BN=32, BK=32, W=2, S=3: t_triton=0.245 ms, speed_vs_torch=0.941x, \n",
      "BM=32, BN=32, BK=32, W=4, S=2: t_triton=0.401 ms, speed_vs_torch=0.563x, \n",
      "BM=32, BN=32, BK=32, W=4, S=3: t_triton=0.410 ms, speed_vs_torch=0.530x, \n",
      "BM=32, BN=32, BK=32, W=8, S=2: t_triton=0.491 ms, speed_vs_torch=0.445x, \n",
      "BM=32, BN=32, BK=32, W=8, S=3: t_triton=0.470 ms, speed_vs_torch=0.462x, \n",
      "BM=32, BN=32, BK=64, W=2, S=2: t_triton=0.219 ms, speed_vs_torch=1.090x, \n",
      "BM=32, BN=32, BK=64, W=2, S=3: t_triton=0.224 ms, speed_vs_torch=1.039x, \n",
      "BM=32, BN=32, BK=64, W=4, S=2: t_triton=0.331 ms, speed_vs_torch=0.730x, \n",
      "BM=32, BN=32, BK=64, W=4, S=3: t_triton=0.327 ms, speed_vs_torch=0.665x, \n",
      "BM=32, BN=32, BK=64, W=8, S=2: t_triton=0.373 ms, speed_vs_torch=0.617x, \n",
      "BM=32, BN=32, BK=64, W=8, S=3: t_triton=0.386 ms, speed_vs_torch=0.561x, \n",
      "BM=32, BN=32, BK=128, W=2, S=2: t_triton=0.213 ms, speed_vs_torch=1.101x, \n",
      "BM=32, BN=32, BK=128, W=2, S=3: t_triton=0.261 ms, speed_vs_torch=0.866x, \n",
      "BM=32, BN=32, BK=128, W=4, S=2: t_triton=0.330 ms, speed_vs_torch=0.662x, \n",
      "BM=32, BN=32, BK=128, W=4, S=3: t_triton=0.344 ms, speed_vs_torch=0.648x, \n",
      "BM=32, BN=32, BK=128, W=8, S=2: t_triton=0.334 ms, speed_vs_torch=0.676x, \n",
      "BM=32, BN=32, BK=128, W=8, S=3: t_triton=0.363 ms, speed_vs_torch=0.608x, \n",
      "BM=32, BN=64, BK=32, W=2, S=2: t_triton=0.181 ms, speed_vs_torch=1.228x, \n",
      "BM=32, BN=64, BK=32, W=2, S=3: t_triton=0.196 ms, speed_vs_torch=1.133x, \n",
      "BM=32, BN=64, BK=32, W=4, S=2: t_triton=0.224 ms, speed_vs_torch=1.074x, \n",
      "BM=32, BN=64, BK=32, W=4, S=3: t_triton=0.233 ms, speed_vs_torch=1.039x, \n",
      "BM=32, BN=64, BK=32, W=8, S=2: t_triton=0.362 ms, speed_vs_torch=0.601x, \n",
      "BM=32, BN=64, BK=32, W=8, S=3: t_triton=0.337 ms, speed_vs_torch=0.673x, \n",
      "BM=32, BN=64, BK=64, W=2, S=2: t_triton=0.169 ms, speed_vs_torch=1.323x, \n",
      "BM=32, BN=64, BK=64, W=2, S=3: t_triton=0.176 ms, speed_vs_torch=1.325x, \n",
      "BM=32, BN=64, BK=64, W=4, S=2: t_triton=0.181 ms, speed_vs_torch=1.290x, \n",
      "BM=32, BN=64, BK=64, W=4, S=3: t_triton=0.185 ms, speed_vs_torch=1.209x, \n",
      "BM=32, BN=64, BK=64, W=8, S=2: t_triton=0.295 ms, speed_vs_torch=0.741x, \n",
      "BM=32, BN=64, BK=64, W=8, S=3: t_triton=0.316 ms, speed_vs_torch=0.684x, \n",
      "BM=32, BN=64, BK=128, W=2, S=2: t_triton=0.172 ms, speed_vs_torch=1.319x, \n",
      "BM=32, BN=64, BK=128, W=2, S=3: t_triton=0.181 ms, speed_vs_torch=1.217x, \n",
      "BM=32, BN=64, BK=128, W=4, S=2: t_triton=0.184 ms, speed_vs_torch=1.286x, \n",
      "BM=32, BN=64, BK=128, W=4, S=3: t_triton=0.191 ms, speed_vs_torch=1.172x, \n",
      "BM=32, BN=64, BK=128, W=8, S=2: t_triton=0.276 ms, speed_vs_torch=0.789x, \n",
      "BM=32, BN=64, BK=128, W=8, S=3: t_triton=0.297 ms, speed_vs_torch=0.780x, \n",
      "BM=32, BN=128, BK=32, W=2, S=2: t_triton=0.162 ms, speed_vs_torch=1.476x, \n",
      "BM=32, BN=128, BK=32, W=2, S=3: t_triton=0.157 ms, speed_vs_torch=1.385x, \n",
      "BM=32, BN=128, BK=32, W=4, S=2: t_triton=0.182 ms, speed_vs_torch=1.245x, \n",
      "BM=32, BN=128, BK=32, W=4, S=3: t_triton=0.174 ms, speed_vs_torch=1.315x, \n",
      "BM=32, BN=128, BK=32, W=8, S=2: t_triton=0.218 ms, speed_vs_torch=1.004x, \n",
      "BM=32, BN=128, BK=32, W=8, S=3: t_triton=0.214 ms, speed_vs_torch=1.093x, \n",
      "BM=32, BN=128, BK=64, W=2, S=2: t_triton=0.156 ms, speed_vs_torch=1.390x, \n",
      "BM=32, BN=128, BK=64, W=2, S=3: t_triton=0.153 ms, speed_vs_torch=1.435x, \n",
      "BM=32, BN=128, BK=64, W=4, S=2: t_triton=0.163 ms, speed_vs_torch=1.403x, \n",
      "BM=32, BN=128, BK=64, W=4, S=3: t_triton=0.161 ms, speed_vs_torch=1.375x, \n",
      "BM=32, BN=128, BK=64, W=8, S=2: t_triton=0.184 ms, speed_vs_torch=1.197x, \n",
      "BM=32, BN=128, BK=64, W=8, S=3: t_triton=0.185 ms, speed_vs_torch=1.241x, \n",
      "BM=32, BN=128, BK=128, W=2, S=2: t_triton=0.166 ms, speed_vs_torch=1.384x, \n",
      "BM=32, BN=128, BK=128, W=2, S=3: t_triton=0.193 ms, speed_vs_torch=1.127x, \n",
      "BM=32, BN=128, BK=128, W=4, S=2: t_triton=0.164 ms, speed_vs_torch=1.407x, \n",
      "BM=32, BN=128, BK=128, W=4, S=3: t_triton=0.167 ms, speed_vs_torch=1.341x, \n",
      "BM=32, BN=128, BK=128, W=8, S=2: t_triton=0.179 ms, speed_vs_torch=1.231x, \n",
      "BM=32, BN=128, BK=128, W=8, S=3: t_triton=0.183 ms, speed_vs_torch=1.261x, \n",
      "BM=64, BN=32, BK=32, W=2, S=2: t_triton=0.190 ms, speed_vs_torch=1.167x, \n",
      "BM=64, BN=32, BK=32, W=2, S=3: t_triton=0.192 ms, speed_vs_torch=1.165x, \n",
      "BM=64, BN=32, BK=32, W=4, S=2: t_triton=0.215 ms, speed_vs_torch=1.037x, \n",
      "BM=64, BN=32, BK=32, W=4, S=3: t_triton=0.210 ms, speed_vs_torch=1.074x, \n",
      "BM=64, BN=32, BK=32, W=8, S=2: t_triton=0.351 ms, speed_vs_torch=0.623x, \n",
      "BM=64, BN=32, BK=32, W=8, S=3: t_triton=0.357 ms, speed_vs_torch=0.619x, \n",
      "BM=64, BN=32, BK=64, W=2, S=2: t_triton=0.173 ms, speed_vs_torch=1.289x, \n",
      "BM=64, BN=32, BK=64, W=2, S=3: t_triton=0.192 ms, speed_vs_torch=1.175x, \n",
      "BM=64, BN=32, BK=64, W=4, S=2: t_triton=0.181 ms, speed_vs_torch=1.242x, \n",
      "BM=64, BN=32, BK=64, W=4, S=3: t_triton=0.200 ms, speed_vs_torch=1.144x, \n",
      "BM=64, BN=32, BK=64, W=8, S=2: t_triton=0.284 ms, speed_vs_torch=0.761x, \n",
      "BM=64, BN=32, BK=64, W=8, S=3: t_triton=0.283 ms, speed_vs_torch=0.777x, \n",
      "BM=64, BN=32, BK=128, W=2, S=2: t_triton=0.197 ms, speed_vs_torch=1.137x, \n",
      "BM=64, BN=32, BK=128, W=2, S=3: t_triton=0.189 ms, speed_vs_torch=1.174x, \n",
      "BM=64, BN=32, BK=128, W=4, S=2: t_triton=0.217 ms, speed_vs_torch=1.018x, \n",
      "BM=64, BN=32, BK=128, W=4, S=3: t_triton=0.224 ms, speed_vs_torch=0.982x, \n",
      "BM=64, BN=32, BK=128, W=8, S=2: t_triton=0.283 ms, speed_vs_torch=0.764x, \n",
      "BM=64, BN=32, BK=128, W=8, S=3: t_triton=0.295 ms, speed_vs_torch=0.741x, \n",
      "BM=64, BN=64, BK=32, W=2, S=2: t_triton=0.119 ms, speed_vs_torch=1.851x, \n",
      "BM=64, BN=64, BK=32, W=2, S=3: t_triton=0.130 ms, speed_vs_torch=1.743x, \n",
      "BM=64, BN=64, BK=32, W=4, S=2: t_triton=0.176 ms, speed_vs_torch=1.302x, \n",
      "BM=64, BN=64, BK=32, W=4, S=3: t_triton=0.169 ms, speed_vs_torch=1.319x, \n",
      "BM=64, BN=64, BK=32, W=8, S=2: t_triton=0.207 ms, speed_vs_torch=1.056x, \n",
      "BM=64, BN=64, BK=32, W=8, S=3: t_triton=0.204 ms, speed_vs_torch=1.091x, \n",
      "BM=64, BN=64, BK=64, W=2, S=2: t_triton=0.113 ms, speed_vs_torch=1.955x, \n",
      "BM=64, BN=64, BK=64, W=2, S=3: t_triton=0.130 ms, speed_vs_torch=1.727x, \n",
      "BM=64, BN=64, BK=64, W=4, S=2: t_triton=0.154 ms, speed_vs_torch=1.537x, \n",
      "BM=64, BN=64, BK=64, W=4, S=3: t_triton=0.152 ms, speed_vs_torch=1.447x, \n",
      "BM=64, BN=64, BK=64, W=8, S=2: t_triton=0.179 ms, speed_vs_torch=1.226x, \n",
      "BM=64, BN=64, BK=64, W=8, S=3: t_triton=0.169 ms, speed_vs_torch=1.354x, \n",
      "BM=64, BN=64, BK=128, W=2, S=2: t_triton=0.128 ms, speed_vs_torch=1.728x, \n",
      "BM=64, BN=64, BK=128, W=2, S=3: t_triton=0.146 ms, speed_vs_torch=1.499x, \n",
      "BM=64, BN=64, BK=128, W=4, S=2: t_triton=0.158 ms, speed_vs_torch=1.450x, \n",
      "BM=64, BN=64, BK=128, W=4, S=3: t_triton=0.163 ms, speed_vs_torch=1.380x, \n",
      "BM=64, BN=64, BK=128, W=8, S=2: t_triton=0.169 ms, speed_vs_torch=1.303x, \n",
      "BM=64, BN=64, BK=128, W=8, S=3: t_triton=0.167 ms, speed_vs_torch=1.378x, \n",
      "BM=64, BN=128, BK=32, W=2, S=2: t_triton=0.129 ms, speed_vs_torch=1.685x, \n",
      "BM=64, BN=128, BK=32, W=2, S=3: t_triton=0.113 ms, speed_vs_torch=1.935x, \n",
      "BM=64, BN=128, BK=32, W=4, S=2: t_triton=0.120 ms, speed_vs_torch=1.844x, \n",
      "BM=64, BN=128, BK=32, W=4, S=3: t_triton=0.114 ms, speed_vs_torch=1.968x, \n",
      "BM=64, BN=128, BK=32, W=8, S=2: t_triton=0.182 ms, speed_vs_torch=1.201x, \n",
      "BM=64, BN=128, BK=32, W=8, S=3: t_triton=0.186 ms, speed_vs_torch=1.228x, \n",
      "BM=64, BN=128, BK=64, W=2, S=2: t_triton=0.119 ms, speed_vs_torch=1.826x, \n",
      "BM=64, BN=128, BK=64, W=2, S=3: t_triton=0.106 ms, speed_vs_torch=2.036x, \n",
      "BM=64, BN=128, BK=64, W=4, S=2: t_triton=0.110 ms, speed_vs_torch=2.010x, \n",
      "BM=64, BN=128, BK=64, W=4, S=3: t_triton=0.107 ms, speed_vs_torch=2.087x, \n",
      "BM=64, BN=128, BK=64, W=8, S=2: t_triton=0.168 ms, speed_vs_torch=1.299x, \n",
      "BM=64, BN=128, BK=64, W=8, S=3: t_triton=0.151 ms, speed_vs_torch=1.503x, \n",
      "BM=64, BN=128, BK=128, W=2, S=2: t_triton=0.126 ms, speed_vs_torch=1.728x, \n",
      "BM=64, BN=128, BK=128, W=2, S=3: t_triton=0.163 ms, speed_vs_torch=1.331x, \n",
      "BM=64, BN=128, BK=128, W=4, S=2: t_triton=0.114 ms, speed_vs_torch=1.954x, \n",
      "BM=64, BN=128, BK=128, W=4, S=3: t_triton=0.111 ms, speed_vs_torch=2.010x, \n",
      "BM=64, BN=128, BK=128, W=8, S=2: t_triton=0.166 ms, speed_vs_torch=1.317x, \n",
      "BM=64, BN=128, BK=128, W=8, S=3: t_triton=0.148 ms, speed_vs_torch=1.521x, \n",
      "BM=128, BN=32, BK=32, W=2, S=2: t_triton=0.135 ms, speed_vs_torch=1.693x, \n",
      "BM=128, BN=32, BK=32, W=2, S=3: t_triton=0.137 ms, speed_vs_torch=1.657x, \n",
      "BM=128, BN=32, BK=32, W=4, S=2: t_triton=0.185 ms, speed_vs_torch=1.237x, \n",
      "BM=128, BN=32, BK=32, W=4, S=3: t_triton=0.184 ms, speed_vs_torch=1.211x, \n",
      "BM=128, BN=32, BK=32, W=8, S=2: t_triton=0.209 ms, speed_vs_torch=1.046x, \n",
      "BM=128, BN=32, BK=32, W=8, S=3: t_triton=0.217 ms, speed_vs_torch=1.029x, \n",
      "BM=128, BN=32, BK=64, W=2, S=2: t_triton=0.120 ms, speed_vs_torch=1.856x, \n",
      "BM=128, BN=32, BK=64, W=2, S=3: t_triton=0.123 ms, speed_vs_torch=1.898x, \n",
      "BM=128, BN=32, BK=64, W=4, S=2: t_triton=0.162 ms, speed_vs_torch=1.412x, \n",
      "BM=128, BN=32, BK=64, W=4, S=3: t_triton=0.175 ms, speed_vs_torch=1.270x, \n",
      "BM=128, BN=32, BK=64, W=8, S=2: t_triton=0.179 ms, speed_vs_torch=1.234x, \n",
      "BM=128, BN=32, BK=64, W=8, S=3: t_triton=0.180 ms, speed_vs_torch=1.286x, \n",
      "BM=128, BN=32, BK=128, W=2, S=2: t_triton=0.136 ms, speed_vs_torch=1.644x, \n",
      "BM=128, BN=32, BK=128, W=2, S=3: t_triton=0.167 ms, speed_vs_torch=1.312x, \n",
      "BM=128, BN=32, BK=128, W=4, S=2: t_triton=0.176 ms, speed_vs_torch=1.300x, \n",
      "BM=128, BN=32, BK=128, W=4, S=3: t_triton=0.188 ms, speed_vs_torch=1.169x, \n",
      "BM=128, BN=32, BK=128, W=8, S=2: t_triton=0.178 ms, speed_vs_torch=1.243x, \n",
      "BM=128, BN=32, BK=128, W=8, S=3: t_triton=0.191 ms, speed_vs_torch=1.192x, \n",
      "BM=128, BN=64, BK=32, W=2, S=2: t_triton=0.142 ms, speed_vs_torch=1.526x, \n",
      "BM=128, BN=64, BK=32, W=2, S=3: t_triton=0.114 ms, speed_vs_torch=1.944x, \n",
      "BM=128, BN=64, BK=32, W=4, S=2: t_triton=0.127 ms, speed_vs_torch=1.775x, \n",
      "BM=128, BN=64, BK=32, W=4, S=3: t_triton=0.121 ms, speed_vs_torch=1.838x, \n",
      "BM=128, BN=64, BK=32, W=8, S=2: t_triton=0.184 ms, speed_vs_torch=1.190x, \n",
      "BM=128, BN=64, BK=32, W=8, S=3: t_triton=0.165 ms, speed_vs_torch=1.369x, \n",
      "BM=128, BN=64, BK=64, W=2, S=2: t_triton=0.126 ms, speed_vs_torch=1.744x, \n",
      "BM=128, BN=64, BK=64, W=2, S=3: t_triton=0.113 ms, speed_vs_torch=2.021x, \n",
      "BM=128, BN=64, BK=64, W=4, S=2: t_triton=0.107 ms, speed_vs_torch=2.123x, \n",
      "BM=128, BN=64, BK=64, W=4, S=3: t_triton=0.119 ms, speed_vs_torch=1.856x, \n",
      "BM=128, BN=64, BK=64, W=8, S=2: t_triton=0.167 ms, speed_vs_torch=1.302x, \n",
      "BM=128, BN=64, BK=64, W=8, S=3: t_triton=0.149 ms, speed_vs_torch=1.529x, \n",
      "BM=128, BN=64, BK=128, W=2, S=2: t_triton=0.195 ms, speed_vs_torch=1.114x, \n",
      "BM=128, BN=64, BK=128, W=2, S=3: t_triton=0.214 ms, speed_vs_torch=1.025x, \n",
      "BM=128, BN=64, BK=128, W=4, S=2: t_triton=0.121 ms, speed_vs_torch=1.917x, \n",
      "BM=128, BN=64, BK=128, W=4, S=3: t_triton=0.129 ms, speed_vs_torch=1.703x, \n",
      "BM=128, BN=64, BK=128, W=8, S=2: t_triton=0.154 ms, speed_vs_torch=1.425x, \n",
      "BM=128, BN=64, BK=128, W=8, S=3: t_triton=0.152 ms, speed_vs_torch=1.505x, \n",
      "BM=128, BN=128, BK=32, W=2, S=2: t_triton=0.393 ms, speed_vs_torch=0.554x, \n",
      "BM=128, BN=128, BK=32, W=2, S=3: t_triton=0.485 ms, speed_vs_torch=0.448x, \n",
      "BM=128, BN=128, BK=32, W=4, S=2: t_triton=0.125 ms, speed_vs_torch=1.749x, \n",
      "BM=128, BN=128, BK=32, W=4, S=3: t_triton=0.113 ms, speed_vs_torch=1.952x, \n",
      "BM=128, BN=128, BK=32, W=8, S=2: t_triton=0.144 ms, speed_vs_torch=1.539x, \n",
      "BM=128, BN=128, BK=32, W=8, S=3: t_triton=0.135 ms, speed_vs_torch=1.623x, \n",
      "BM=128, BN=128, BK=64, W=2, S=2: t_triton=0.521 ms, speed_vs_torch=0.437x, \n",
      "BM=128, BN=128, BK=64, W=2, S=3: t_triton=0.610 ms, speed_vs_torch=0.356x, \n",
      "BM=128, BN=128, BK=64, W=4, S=2: t_triton=0.112 ms, speed_vs_torch=2.048x, \n",
      "BM=128, BN=128, BK=64, W=4, S=3: t_triton=0.101 ms, speed_vs_torch=2.177x, \n",
      "BM=128, BN=128, BK=64, W=8, S=2: t_triton=0.163 ms, speed_vs_torch=1.333x, \n",
      "BM=128, BN=128, BK=64, W=8, S=3: t_triton=0.122 ms, speed_vs_torch=1.843x, \n",
      "BM=128, BN=128, BK=128, W=2, S=2: t_triton=0.602 ms, speed_vs_torch=0.364x, \n",
      "BM=128, BN=128, BK=128, W=2, S=3: t_triton=0.622 ms, speed_vs_torch=0.349x, \n",
      "BM=128, BN=128, BK=128, W=4, S=2: t_triton=0.130 ms, speed_vs_torch=1.684x, \n",
      "BM=128, BN=128, BK=128, W=4, S=3: t_triton=0.171 ms, speed_vs_torch=1.283x, \n",
      "BM=128, BN=128, BK=128, W=8, S=2: t_triton=0.167 ms, speed_vs_torch=1.368x, \n",
      "BM=128, BN=128, BK=128, W=8, S=3: t_triton=0.116 ms, speed_vs_torch=1.894x, \n"
     ]
    }
   ],
   "source": [
    "df_gemm_tiles = tune_gemm_int8_tiles_for_shape(\n",
    "    M=4096, K=1024, N=1024,\n",
    "    blocks_M=(32, 64, 128),\n",
    "    blocks_N=(32, 64, 128),\n",
    "    blocks_K=(32, 64, 128),\n",
    "    warps=(2, 4, 8),\n",
    "    stages=(2, 3),\n",
    "    iters=200,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c29522-a1df-4062-adbc-9edc3a7e4709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>K</th>\n",
       "      <th>N</th>\n",
       "      <th>BLOCK_M</th>\n",
       "      <th>BLOCK_N</th>\n",
       "      <th>BLOCK_K</th>\n",
       "      <th>num_warps</th>\n",
       "      <th>num_stages</th>\n",
       "      <th>t_triton_ms</th>\n",
       "      <th>t_torch_ms</th>\n",
       "      <th>speed_vs_torch</th>\n",
       "      <th>bw_triton_GBs</th>\n",
       "      <th>bw_torch_GBs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101361</td>\n",
       "      <td>0.220684</td>\n",
       "      <td>2.177198</td>\n",
       "      <td>217.243762</td>\n",
       "      <td>99.781338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.106480</td>\n",
       "      <td>0.216821</td>\n",
       "      <td>2.036252</td>\n",
       "      <td>206.799329</td>\n",
       "      <td>101.558822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.106584</td>\n",
       "      <td>0.222467</td>\n",
       "      <td>2.087237</td>\n",
       "      <td>206.597942</td>\n",
       "      <td>98.981529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107135</td>\n",
       "      <td>0.227395</td>\n",
       "      <td>2.122513</td>\n",
       "      <td>205.536362</td>\n",
       "      <td>96.836346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110027</td>\n",
       "      <td>0.221197</td>\n",
       "      <td>2.010384</td>\n",
       "      <td>200.133003</td>\n",
       "      <td>99.549662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111288</td>\n",
       "      <td>0.223643</td>\n",
       "      <td>2.009592</td>\n",
       "      <td>197.866555</td>\n",
       "      <td>98.461052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111548</td>\n",
       "      <td>0.228416</td>\n",
       "      <td>2.047690</td>\n",
       "      <td>197.404218</td>\n",
       "      <td>96.403371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.112947</td>\n",
       "      <td>0.218499</td>\n",
       "      <td>1.934527</td>\n",
       "      <td>194.959849</td>\n",
       "      <td>100.779092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>0.228455</td>\n",
       "      <td>2.021493</td>\n",
       "      <td>194.845785</td>\n",
       "      <td>96.387070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113029</td>\n",
       "      <td>0.220613</td>\n",
       "      <td>1.951824</td>\n",
       "      <td>194.818247</td>\n",
       "      <td>99.813422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M     K     N  BLOCK_M  BLOCK_N  BLOCK_K  num_warps  num_stages  \\\n",
       "153  4096  1024  1024      128      128       64          4           3   \n",
       "97   4096  1024  1024       64      128       64          2           3   \n",
       "99   4096  1024  1024       64      128       64          4           3   \n",
       "134  4096  1024  1024      128       64       64          4           2   \n",
       "98   4096  1024  1024       64      128       64          4           2   \n",
       "105  4096  1024  1024       64      128      128          4           3   \n",
       "152  4096  1024  1024      128      128       64          4           2   \n",
       "91   4096  1024  1024       64      128       32          2           3   \n",
       "133  4096  1024  1024      128       64       64          2           3   \n",
       "147  4096  1024  1024      128      128       32          4           3   \n",
       "\n",
       "     t_triton_ms  t_torch_ms  speed_vs_torch  bw_triton_GBs  bw_torch_GBs  \n",
       "153     0.101361    0.220684        2.177198     217.243762     99.781338  \n",
       "97      0.106480    0.216821        2.036252     206.799329    101.558822  \n",
       "99      0.106584    0.222467        2.087237     206.597942     98.981529  \n",
       "134     0.107135    0.227395        2.122513     205.536362     96.836346  \n",
       "98      0.110027    0.221197        2.010384     200.133003     99.549662  \n",
       "105     0.111288    0.223643        2.009592     197.866555     98.461052  \n",
       "152     0.111548    0.228416        2.047690     197.404218     96.403371  \n",
       "91      0.112947    0.218499        1.934527     194.959849    100.779092  \n",
       "133     0.113013    0.228455        2.021493     194.845785     96.387070  \n",
       "147     0.113029    0.220613        1.951824     194.818247     99.813422  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gemm_tiles.sort_values(\"t_triton_ms\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa596d30-56f6-4fce-ae4e-684416db22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT8_GEMM_BEST_BLOCK_M = 128\n",
    "INT8_GEMM_BEST_BLOCK_N = 128\n",
    "INT8_GEMM_BEST_BLOCK_K = 64\n",
    "INT8_GEMM_BEST_WARPS   = 4\n",
    "INT8_GEMM_BEST_STAGES  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc783a-dfe5-4306-9f8b-b4e9eee2cb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588e49e-84e6-4dd0-b9a0-73010622b059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de16cb-e4b7-4598-9f28-5bfd9c6045b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942eb61-f0a3-4b67-bd66-e82b70f809bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
