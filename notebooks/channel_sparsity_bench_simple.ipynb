{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5a768f",
   "metadata": {},
   "source": [
    "# Channel / Block / Input Sparsity Bench (FP16)\n",
    "?????????? ????????, ??????????? `channel_sparsity_bench.ipynb`: ???? ?????? ???????, sweep ?? keep_ratio ??? channel/block/input sparsity, ????????? ? torch Conv2d, ??????????? ? ???-10 ?? ???????."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a94b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]= /mnt/d/VSCode-Projects/conv2d-img2col-gemm\n"
     ]
    }
   ],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path().resolve().parent))\n",
    "print('sys.path[0]=', sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358161fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=cuda, dtype=torch.float16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "from conv_gemm.baseline_layers.triton_conv2d import TritonConv2d\n",
    "from conv_gemm.configs import kernel_config as kc\n",
    "import conv_gemm.baseline_operators.triton_conv2d_fp16_fn as tri_fn\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = torch.float16 if device == 'cuda' else torch.float32\n",
    "print(f'device={device}, dtype={dtype}')\n",
    "if device != 'cuda':\n",
    "    print('?? CUDA ?????????? ? ?????????? ????? ????????? ? ?? ???????????????.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e20c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ????????? ???????\n",
    "eval_warmup = 10\n",
    "eval_iters = 50\n",
    "\n",
    "\n",
    "def sync_device():\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def benchmark_layer(module: torch.nn.Module, x: torch.Tensor, warmup: int = eval_warmup, iters: int = eval_iters):\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            module(x)\n",
    "    sync_device()\n",
    "    t0 = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(iters):\n",
    "            module(x)\n",
    "    sync_device()\n",
    "    return (time.perf_counter() - t0) * 1e3 / iters\n",
    "\n",
    "def calc_diff(ref: torch.Tensor, test: torch.Tensor):\n",
    "    diff = (ref - test).float()\n",
    "    return {\n",
    "        'mae': diff.abs().mean().item(),\n",
    "        'max': diff.abs().max().item(),\n",
    "        'rel_l2': (torch.norm(diff) / torch.norm(ref)).item(),\n",
    "    }\n",
    "\n",
    "def clone_weights(dst: torch.nn.Module, src: torch.nn.Module):\n",
    "    with torch.no_grad():\n",
    "        dst.weight.copy_(src.weight)\n",
    "        if dst.bias is not None and src.bias is not None:\n",
    "            dst.bias.copy_(src.bias)\n",
    "\n",
    "def apply_block_cfg(cfg):\n",
    "    tri_fn.FP16_GEMM_CFG = kc.KernelConfig(\n",
    "        BLOCK_M=cfg['BLOCK_M'], BLOCK_N=cfg['BLOCK_N'], BLOCK_K=cfg['BLOCK_K'],\n",
    "        NUM_WARPS=cfg['NUM_WARPS'], NUM_STAGES=cfg['NUM_STAGES'],\n",
    "    )\n",
    "    kc.FP16_GEMM_CFG = tri_fn.FP16_GEMM_CFG\n",
    "    importlib.reload(tri_fn)\n",
    "\n",
    "def build_triton(block_cfg):\n",
    "    apply_block_cfg(block_cfg)\n",
    "    layer = TritonConv2d(**params).to(device=device)\n",
    "    clone_weights(layer, torch_conv)\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf13364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_ratios: [1.0, 0.85, 0.75, 0.65, 0.5, 0.35, 0.25]\n"
     ]
    }
   ],
   "source": [
    "# ???? ???????? ???? (????? ???????? ?? ????)\n",
    "params = dict(in_channels=1, out_channels=3, kernel_size=11, stride=1, padding=1, bias=True)\n",
    "B, H, W = 16, 1024, 1024\n",
    "\n",
    "torch.manual_seed(0)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(0)\n",
    "\n",
    "# ????????? torch Conv2d\n",
    "torch_conv = torch.nn.Conv2d(**params).to(device=device, dtype=dtype)\n",
    "\n",
    "# ??????? ?????? ?????? (????? ????????)\n",
    "baseline_block_cfg = dict(BLOCK_M=64, BLOCK_N=64, BLOCK_K=32, NUM_WARPS=4, NUM_STAGES=2)\n",
    "\n",
    "keep_ratios = [1.0, 0.85, 0.75, 0.65, 0.5, 0.35, 0.25]\n",
    "print('keep_ratios:', keep_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497e32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?????? ????? forward-??????? ?? ???? ???????: 1302 (?? 434 ?? ???? ????)\n"
     ]
    }
   ],
   "source": [
    "# ?????? ?????????? ??????? forward\n",
    "calls_per_ratio = 2 + eval_warmup + eval_iters  # torch_out + triton_out + warmup+iters ? benchmark\n",
    "calls_per_sweep = len(keep_ratios) * calls_per_ratio\n",
    "total_calls = 3 * calls_per_sweep  # channel, block, input\n",
    "print(f'?????? ????? forward-??????? ?? ???? ???????: {total_calls} (?? {calls_per_sweep} ?? ???? ????)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[channel 1/7] keep=1.00, time_ms=701.986, mae=8.535e-05, max=1.953e-03, rel_l2=3.846e-04\n",
      "[channel 2/7] keep=0.85, time_ms=701.884, mae=8.524e-05, max=1.953e-03, rel_l2=3.844e-04\n",
      "[channel 3/7] keep=0.75, time_ms=637.952, mae=1.502e-01, max=3.105e+00, rel_l2=5.696e-01\n",
      "[channel 4/7] keep=0.65, time_ms=691.378, mae=1.502e-01, max=3.219e+00, rel_l2=5.694e-01\n"
     ]
    }
   ],
   "source": [
    "# Dense baseline\n",
    "tri_dense = build_triton(baseline_block_cfg) if device == 'cuda' else None\n",
    "\n",
    "\n",
    "def run_channel_sweep(keep_ratios):\n",
    "    rows = []\n",
    "    if tri_dense is None:\n",
    "        raise RuntimeError('Triton ?????????? (??? GPU)')\n",
    "    total = len(keep_ratios)\n",
    "    for idx, ratio in enumerate(keep_ratios, start=1):\n",
    "        tri = build_triton(baseline_block_cfg)\n",
    "        tri.set_channel_sparsity(ratio)\n",
    "        x = torch.randn(B, params['in_channels'], H, W, device=device, dtype=dtype)\n",
    "        with torch.no_grad():\n",
    "            ref = torch_conv(x).float()\n",
    "            out = tri(x).float()\n",
    "        stats = calc_diff(ref, out)\n",
    "        t_ms = benchmark_layer(tri, x.clone().detach())\n",
    "        print(f\"[channel {idx}/{total}] keep={ratio:.2f}, time_ms={t_ms:.3f}, mae={stats['mae']:.3e}, max={stats['max']:.3e}, rel_l2={stats['rel_l2']:.3e}\", flush=True)\n",
    "        rows.append({'mode': 'channel', 'keep_ratio': ratio, 'mae': stats['mae'], 'max': stats['max'],\n",
    "                     'rel_l2': stats['rel_l2'], 'time_ms': t_ms,\n",
    "                     'BLOCK_M': baseline_block_cfg['BLOCK_M'], 'BLOCK_N': baseline_block_cfg['BLOCK_N'],\n",
    "                     'BLOCK_K': baseline_block_cfg['BLOCK_K'], 'NUM_WARPS': baseline_block_cfg['NUM_WARPS'], 'NUM_STAGES': baseline_block_cfg['NUM_STAGES']})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def run_block_sweep(keep_ratios, block_size=4):\n",
    "    rows = []\n",
    "    if tri_dense is None:\n",
    "        raise RuntimeError('Triton ?????????? (??? GPU)')\n",
    "    total = len(keep_ratios)\n",
    "    for idx, ratio in enumerate(keep_ratios, start=1):\n",
    "        tri = build_triton(baseline_block_cfg)\n",
    "        tri.set_block_sparsity(ratio, block_size=block_size)\n",
    "        x = torch.randn(B, params['in_channels'], H, W, device=device, dtype=dtype)\n",
    "        with torch.no_grad():\n",
    "            ref = torch_conv(x).float()\n",
    "            out = tri(x).float()\n",
    "        stats = calc_diff(ref, out)\n",
    "        t_ms = benchmark_layer(tri, x.clone().detach())\n",
    "        print(f\"[block {idx}/{total}] keep={ratio:.2f}, time_ms={t_ms:.3f}, mae={stats['mae']:.3e}, max={stats['max']:.3e}, rel_l2={stats['rel_l2']:.3e}\", flush=True)\n",
    "        rows.append({'mode': f'block-{block_size}', 'keep_ratio': ratio, 'mae': stats['mae'], 'max': stats['max'],\n",
    "                     'rel_l2': stats['rel_l2'], 'time_ms': t_ms,\n",
    "                     'BLOCK_M': baseline_block_cfg['BLOCK_M'], 'BLOCK_N': baseline_block_cfg['BLOCK_N'],\n",
    "                     'BLOCK_K': baseline_block_cfg['BLOCK_K'], 'NUM_WARPS': baseline_block_cfg['NUM_WARPS'], 'NUM_STAGES': baseline_block_cfg['NUM_STAGES']})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def run_input_sweep(keep_ratios):\n",
    "    rows = []\n",
    "    if tri_dense is None:\n",
    "        raise RuntimeError('Triton ?????????? (??? GPU)')\n",
    "    total = len(keep_ratios)\n",
    "    for idx, ratio in enumerate(keep_ratios, start=1):\n",
    "        tri = build_triton(baseline_block_cfg)\n",
    "        tri.set_input_channel_sparsity(ratio)\n",
    "        x = torch.randn(B, params['in_channels'], H, W, device=device, dtype=dtype)\n",
    "        with torch.no_grad():\n",
    "            ref = torch_conv(x).float()\n",
    "            out = tri(x).float()\n",
    "        stats = calc_diff(ref, out)\n",
    "        t_ms = benchmark_layer(tri, x.clone().detach())\n",
    "        print(f\"[input {idx}/{total}] keep={ratio:.2f}, time_ms={t_ms:.3f}, mae={stats['mae']:.3e}, max={stats['max']:.3e}, rel_l2={stats['rel_l2']:.3e}\", flush=True)\n",
    "        rows.append({'mode': 'input', 'keep_ratio': ratio, 'mae': stats['mae'], 'max': stats['max'],\n",
    "                     'rel_l2': stats['rel_l2'], 'time_ms': t_ms,\n",
    "                     'BLOCK_M': baseline_block_cfg['BLOCK_M'], 'BLOCK_N': baseline_block_cfg['BLOCK_N'],\n",
    "                     'BLOCK_K': baseline_block_cfg['BLOCK_K'], 'NUM_WARPS': baseline_block_cfg['NUM_WARPS'], 'NUM_STAGES': baseline_block_cfg['NUM_STAGES']})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "channel_sweep_df = run_channel_sweep(keep_ratios)\n",
    "block_sweep_df = run_block_sweep(keep_ratios, block_size=4)\n",
    "input_sweep_df = run_input_sweep(keep_ratios)\n",
    "\n",
    "channel_sweep_df, block_sweep_df, input_sweep_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('notebooks')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "channel_sweep_df.to_csv(out_dir / 'channel_sparsity_bench_results.csv', index=False)\n",
    "block_sweep_df.to_csv(out_dir / 'block_sparsity_bench_results.csv', index=False)\n",
    "input_sweep_df.to_csv(out_dir / 'input_sparsity_bench_results.csv', index=False)\n",
    "print('saved results to notebooks/*_sparsity_bench_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([\n",
    "    channel_sweep_df.assign(mode_group='channel'),\n",
    "    block_sweep_df.assign(mode_group='block'),\n",
    "    input_sweep_df.assign(mode_group='input')\n",
    "], ignore_index=True)\n",
    "all_df_sorted = all_df.sort_values('time_ms', ascending=True)\n",
    "print('Top-10 fastest configs:')\n",
    "display(all_df_sorted.head(10)[['mode', 'keep_ratio', 'time_ms', 'mae', 'max', 'rel_l2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d41417-ca8c-47fd-933f-0223d09baafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
